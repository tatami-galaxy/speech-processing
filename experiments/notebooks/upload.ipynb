{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f387fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, load_dataset\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"hi\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"hi\", split=\"test\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78160dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '0f018a99663f33afbb7d38aee281fb1afcfd07f9e7acd00383f604e1e17c38d6ed8adf1bd2ccbf927a52c5adefb8ac4b158ce27a7c2ed9581e71202eb302dfb3',\n",
       " 'path': '/users/ujan/.cache/huggingface/datasets/downloads/extracted/c97e32e2de32510be7c273dbcdc82db93cb021f851ff1f0751145082d83effd9/common_voice_hi_26010471.mp3',\n",
       " 'audio': {'path': '/users/ujan/.cache/huggingface/datasets/downloads/extracted/c97e32e2de32510be7c273dbcdc82db93cb021f851ff1f0751145082d83effd9/common_voice_hi_26010471.mp3',\n",
       "  'array': array([-2.13162821e-14,  1.40332190e-13,  2.23820962e-13, ...,\n",
       "          1.03580276e-03,  6.28637266e-04,  3.20890395e-04]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': 'तुम ने टॉम को कहाँ भेज दिया?',\n",
       " 'up_votes': 2,\n",
       " 'down_votes': 1,\n",
       " 'age': '',\n",
       " 'gender': '',\n",
       " 'accent': '',\n",
       " 'locale': 'hi',\n",
       " 'segment': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7de6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import FlaxWhisperForConditionalGeneration\n",
    "from transformers import WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55062a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.94k/1.94k [00:00<00:00, 2.14MB/s]\n",
      "Downloading flax_model.msgpack: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 151M/151M [02:18<00:00, 1.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "#feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "#tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"hindi\", task=\"transcribe\")\n",
    "# We only need to set the task id when the language is specified (i.e. in a multilingual setting)\n",
    "#tokenizer.set_prefix_tokens(language=\"hindi\", task=\"transcribe\")\n",
    "#processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"hindi\", task=\"transcribe\")\n",
    "\n",
    "# model\n",
    "model = FlaxWhisperForConditionalGeneration.from_pretrained(\n",
    "    \"openai/whisper-tiny\", # small\n",
    "    seed=42,\n",
    "    dtype=getattr(jnp, 'float16')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9944d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "#tokenizer.save_pretrained(\"/users/ujan/Downloads/whisper_en_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0a21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperConfig\n",
    "config = WhisperConfig.from_pretrained('openai/whisper-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06220909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-tiny\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 384,\n",
      "  \"decoder_attention_heads\": 6,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 6,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-tiny\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 384,\n",
      "  \"decoder_attention_heads\": 6,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 6,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FlaxWhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n",
    "print(model.config)\n",
    "model.config.update({\"suppress_tokens\": []})\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4587f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')\n",
    "model.save_pretrained('/home/ujan/speech-processing/models/pretrained_models/whisper-large-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371fdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "data_dir = '/home/ujan/Datasets/'\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "text_column = \"transcript\"\n",
    "audio_column = \"audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bb63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_remap(x):\n",
    "\n",
    "    # get audio path\n",
    "    #path_list = x['audio'].split('/')\n",
    "    path = x['audio']\n",
    "\n",
    "    #for i in range(len(path_list)):\n",
    "        #if path_list[i] == 'wav': break\n",
    "\n",
    "    #new_path = '/'.join(path_list[i:])\n",
    "    #new_path = args.data_dir+'/'+new_path\n",
    "    new_path = data_dir+'/'+path\n",
    "    x['audio'] = new_path\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8851c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-985751aa69de9f8c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ujan/.cache/huggingface/datasets/csv/default-985751aa69de9f8c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8773fad116064797a14de5a1df66cac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed1e8f6ab294ed9a861888e9be506f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2347e00e43f40a3be8fbc3c39364db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujan/anaconda3/envs/asr/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:727: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ujan/.cache/huggingface/datasets/csv/default-985751aa69de9f8c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632c99c2b6e84439a5da44d6ce81c7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcf9dc7d8ff4dd880a9009de55cfa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109251 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6132f0173d45413bbb6e4a26e27f0c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "remove special characters from datasets:   0%|          | 0/109251 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data files\n",
    "data_files = {\n",
    "    'test': data_dir+'/final_test_v2a.csv', # final_train.csv\n",
    "}\n",
    "\n",
    "raw_datasets = load_dataset('csv', data_files=data_files)\n",
    "\n",
    "# map to new audio path\n",
    "raw_datasets = raw_datasets.map(path_remap, batched=False)\n",
    "\n",
    "\n",
    "\n",
    "# remove punctuations\n",
    "def remove_special_characters(batch):\n",
    "    batch[text_column] = re.sub(chars_to_ignore_regex, \"\", batch[text_column]).lower() + \" \"\n",
    "    return batch\n",
    "    \n",
    "\n",
    "raw_datasets = raw_datasets.map(\n",
    "    remove_special_characters,\n",
    "    desc=\"remove special characters from datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8c2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': '/home/ujan/Datasets//gale2/wav/train/gale2015_2/CCTV1_LEGALREPORT_CMN_20070403_123701_89.wav',\n",
       " 'transcript': '是不太赞成这种 这种很莽撞的 不负责任的这样的婚姻 ',\n",
       " 'duration': 5.17999999999995}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b7b5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets.cast_column(\n",
    "    audio_column, datasets.features.Audio(sampling_rate=16000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff02d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': {'path': '/home/ujan/Datasets//gale2/wav/train/gale2015_2/CCTV1_LEGALREPORT_CMN_20070403_123701_89.wav',\n",
       "  'array': array([-0.00018311,  0.00170898,  0.0012207 , ..., -0.00646973,\n",
       "         -0.00805664, -0.00961304], dtype=float32),\n",
       "  'sampling_rate': 16000},\n",
       " 'transcript': '是不太赞成这种 这种很莽撞的 不负责任的这样的婚姻 ',\n",
       " 'duration': 5.17999999999995}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d0bde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcript', 'duration'],\n",
       "        num_rows: 109251\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606c8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a436935c6e48468205b1bbf900b30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f7140625cf4239a0ac0dcd09b557c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cf61c1fe72439da969831af857ab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec9852cec67406784d74fe1b63bfac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5993129557448e886ee7ab7f373f96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05224ae0e571459badd54b254023b645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0999876f54931a0bc027be6b53478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47174a83c97f4b47b75eab6865181bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e478a7fe8e4bff93176134f2c13735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab58dc48e5d423aaaf12c260e159192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73daafa9f774c5f88a76bfd2a3811e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222c175298704653925b7ad84ec71c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92bc28802c9489a95ddd3d0928b73bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754d6ab72623468f96e0e96b711516ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00784a742a8a4d02be2e2a8d1f027959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be389cf7e9e14c39ae536459aa4c6971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853396e013464452a2904f43533ef0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c896ecc17d16491191d251c2818b90a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fd76492aee49fe8b59eab04fb2f375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d2587a96f04e30a9136870d9efeaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612b408829124560a5a3b05abf54d49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbd82b5a15f4208ae8fb5e7f0cad92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52af1a0335b7450384e770b7507fab37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8ee69485fe43e5b40a74ac3018a2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3074bc2496024260a69e4cc0b613b259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3456e07db7894d2f952547cffc453c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15852f67e58a4c0785991132d276c2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ab9256bc84cdcb274db49a6ca2bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8b67fc54bf4bd88ac447d80c9b5083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c64bdc413f4c2abd6c8fa4a4b981f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error while uploading 'data/test-00014-of-00032-b9f5e362471b1a0c.parquet' to the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/http/client.py:1076\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         chunk \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(chunk)\u001b[39m:\u001b[39;00m\u001b[39mX\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m chunk \\\n\u001b[1;32m   1075\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1076\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(chunk)\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m encode_chunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_http_vsn \u001b[39m==\u001b[39m \u001b[39m11\u001b[39m:\n\u001b[1;32m   1079\u001b[0m     \u001b[39m# end chunked transfer\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/http/client.py:998\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 998\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49msendall(data)\n\u001b[1;32m    999\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/ssl.py:1237\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39mwhile\u001b[39;00m count \u001b[39m<\u001b[39m amount:\n\u001b[0;32m-> 1237\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(byte_view[count:])\n\u001b[1;32m   1238\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m v\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/ssl.py:1206\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[0;34m(self, data, flags)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1204\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1205\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mwrite(data)\n\u001b[1;32m   1207\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:2396)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='s3.us-east-1.amazonaws.com', port=443): Max retries exceeded with url: /lfs.huggingface.co/repos/b9/f8/b9f87330cbeaa752224d7f926da648885babafba056ba4a11452b247b22bb4cd/c921e028521a723295990c90ad0379ddde30c58b9cc2f01abcf03e1800e3ad76?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA4N7VTDGO27GPWFUO%2F20230622%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230622T101716Z&X-Amz-Expires=86400&X-Amz-Signature=5057f701ceeef8605ff9b3e1b1b595afd755a4f04fe0c7b5e8bdfb51d66e0275&X-Amz-SignedHeaders=host&partNumber=9&uploadId=1WnwAq7TbJJMb5PramZwQ2b8iSUp6xiK.NL.LFDFcJ8srUQc02_kVKfAcDDlGmSuhnJOi1Ev2fGuR9OaPJQJc8T8rJEiF9RTZZIV7_X4kb7SaRMIsXGPlCbnjOe7RR_E&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2396)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:341\u001b[0m, in \u001b[0;36mupload_lfs_files.<locals>._wrapped_lfs_upload\u001b[0;34m(batch_action)\u001b[0m\n\u001b[1;32m    340\u001b[0m     operation \u001b[39m=\u001b[39m oid2addop[batch_action[\u001b[39m\"\u001b[39m\u001b[39moid\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m--> 341\u001b[0m     lfs_upload(operation\u001b[39m=\u001b[39;49moperation, lfs_batch_action\u001b[39m=\u001b[39;49mbatch_action, token\u001b[39m=\u001b[39;49mtoken)\n\u001b[1;32m    342\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/lfs.py:223\u001b[0m, in \u001b[0;36mlfs_upload\u001b[0;34m(operation, lfs_batch_action, token)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    221\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMalformed response from LFS batch endpoint: `chunk_size` should be an integer. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mchunk_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         )\n\u001b[0;32m--> 223\u001b[0m     _upload_multi_part(operation\u001b[39m=\u001b[39;49moperation, header\u001b[39m=\u001b[39;49mheader, chunk_size\u001b[39m=\u001b[39;49mchunk_size, upload_url\u001b[39m=\u001b[39;49mupload_action[\u001b[39m\"\u001b[39;49m\u001b[39mhref\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/lfs.py:319\u001b[0m, in \u001b[0;36m_upload_multi_part\u001b[0;34m(operation, header, chunk_size, upload_url)\u001b[0m\n\u001b[1;32m    314\u001b[0m     use_hf_transfer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    316\u001b[0m response_headers \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m     _upload_parts_hf_transfer(operation\u001b[39m=\u001b[39moperation, sorted_parts_urls\u001b[39m=\u001b[39msorted_parts_urls, chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m use_hf_transfer\n\u001b[0;32m--> 319\u001b[0m     \u001b[39melse\u001b[39;00m _upload_parts_iteratively(operation\u001b[39m=\u001b[39;49moperation, sorted_parts_urls\u001b[39m=\u001b[39;49msorted_parts_urls, chunk_size\u001b[39m=\u001b[39;49mchunk_size)\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m \u001b[39m# 3. Send completion request\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/lfs.py:375\u001b[0m, in \u001b[0;36m_upload_parts_iteratively\u001b[0;34m(operation, sorted_parts_urls, chunk_size)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mwith\u001b[39;00m SliceFileObj(\n\u001b[1;32m    371\u001b[0m     fileobj,\n\u001b[1;32m    372\u001b[0m     seek_from\u001b[39m=\u001b[39mchunk_size \u001b[39m*\u001b[39m part_idx,\n\u001b[1;32m    373\u001b[0m     read_limit\u001b[39m=\u001b[39mchunk_size,\n\u001b[1;32m    374\u001b[0m ) \u001b[39mas\u001b[39;00m fileobj_slice:\n\u001b[0;32m--> 375\u001b[0m     part_upload_res \u001b[39m=\u001b[39m http_backoff(\u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, part_upload_url, data\u001b[39m=\u001b[39;49mfileobj_slice)\n\u001b[1;32m    376\u001b[0m     hf_raise_for_status(part_upload_res)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:212\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/requests/adapters.py:563\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    562\u001b[0m     \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    565\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='s3.us-east-1.amazonaws.com', port=443): Max retries exceeded with url: /lfs.huggingface.co/repos/b9/f8/b9f87330cbeaa752224d7f926da648885babafba056ba4a11452b247b22bb4cd/c921e028521a723295990c90ad0379ddde30c58b9cc2f01abcf03e1800e3ad76?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA4N7VTDGO27GPWFUO%2F20230622%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230622T101716Z&X-Amz-Expires=86400&X-Amz-Signature=5057f701ceeef8605ff9b3e1b1b595afd755a4f04fe0c7b5e8bdfb51d66e0275&X-Amz-SignedHeaders=host&partNumber=9&uploadId=1WnwAq7TbJJMb5PramZwQ2b8iSUp6xiK.NL.LFDFcJ8srUQc02_kVKfAcDDlGmSuhnJOi1Ev2fGuR9OaPJQJc8T8rJEiF9RTZZIV7_X4kb7SaRMIsXGPlCbnjOe7RR_E&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2396)')))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_datasets\u001b[39m.\u001b[39;49mpush_to_hub(\u001b[39m\"\u001b[39;49m\u001b[39mUjan/asr_testset_zh_16k\u001b[39;49m\u001b[39m\"\u001b[39;49m, private\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/datasets/dataset_dict.py:1548\u001b[0m, in \u001b[0;36mDatasetDict.push_to_hub\u001b[0;34m(self, repo_id, private, token, branch, max_shard_size, num_shards, shard_size, embed_external_files)\u001b[0m\n\u001b[1;32m   1546\u001b[0m logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPushing split \u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m to the Hub.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1547\u001b[0m \u001b[39m# The split=key needs to be removed before merging\u001b[39;00m\n\u001b[0;32m-> 1548\u001b[0m repo_id, split, uploaded_size, dataset_nbytes, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[split]\u001b[39m.\u001b[39;49m_push_parquet_shards_to_hub(\n\u001b[1;32m   1549\u001b[0m     repo_id,\n\u001b[1;32m   1550\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m   1551\u001b[0m     private\u001b[39m=\u001b[39;49mprivate,\n\u001b[1;32m   1552\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1553\u001b[0m     branch\u001b[39m=\u001b[39;49mbranch,\n\u001b[1;32m   1554\u001b[0m     max_shard_size\u001b[39m=\u001b[39;49mmax_shard_size,\n\u001b[1;32m   1555\u001b[0m     num_shards\u001b[39m=\u001b[39;49mnum_shards\u001b[39m.\u001b[39;49mget(split),\n\u001b[1;32m   1556\u001b[0m     embed_external_files\u001b[39m=\u001b[39;49membed_external_files,\n\u001b[1;32m   1557\u001b[0m )\n\u001b[1;32m   1558\u001b[0m total_uploaded_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m uploaded_size\n\u001b[1;32m   1559\u001b[0m total_dataset_nbytes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dataset_nbytes\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/datasets/arrow_dataset.py:4815\u001b[0m, in \u001b[0;36mDataset._push_parquet_shards_to_hub\u001b[0;34m(self, repo_id, split, private, token, branch, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   4813\u001b[0m         shard\u001b[39m.\u001b[39mto_parquet(buffer)\n\u001b[1;32m   4814\u001b[0m         uploaded_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39mtell()\n\u001b[0;32m-> 4815\u001b[0m         _retry(\n\u001b[1;32m   4816\u001b[0m             api\u001b[39m.\u001b[39;49mupload_file,\n\u001b[1;32m   4817\u001b[0m             func_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m   4818\u001b[0m                 path_or_fileobj\u001b[39m=\u001b[39;49mbuffer\u001b[39m.\u001b[39;49mgetvalue(),\n\u001b[1;32m   4819\u001b[0m                 path_in_repo\u001b[39m=\u001b[39;49mshard_path_in_repo,\n\u001b[1;32m   4820\u001b[0m                 repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   4821\u001b[0m                 token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   4822\u001b[0m                 repo_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   4823\u001b[0m                 revision\u001b[39m=\u001b[39;49mbranch,\n\u001b[1;32m   4824\u001b[0m             ),\n\u001b[1;32m   4825\u001b[0m             exceptions\u001b[39m=\u001b[39;49mHTTPError,\n\u001b[1;32m   4826\u001b[0m             status_codes\u001b[39m=\u001b[39;49m[\u001b[39m504\u001b[39;49m],\n\u001b[1;32m   4827\u001b[0m             base_wait_time\u001b[39m=\u001b[39;49m\u001b[39m2.0\u001b[39;49m,\n\u001b[1;32m   4828\u001b[0m             max_retries\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m   4829\u001b[0m             max_wait_time\u001b[39m=\u001b[39;49m\u001b[39m20.0\u001b[39;49m,\n\u001b[1;32m   4830\u001b[0m         )\n\u001b[1;32m   4831\u001b[0m     shards_path_in_repo\u001b[39m.\u001b[39mappend(shard_path_in_repo)\n\u001b[1;32m   4833\u001b[0m \u001b[39m# Cleanup to remove unused files\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/datasets/utils/file_utils.py:281\u001b[0m, in \u001b[0;36m_retry\u001b[0;34m(func, func_args, func_kwargs, exceptions, status_codes, max_retries, base_wait_time, max_wait_time)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m    282\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    283\u001b[0m         \u001b[39mif\u001b[39;00m retry \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_retries \u001b[39mor\u001b[39;00m (status_codes \u001b[39mand\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m status_codes):\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2998\u001b[0m, in \u001b[0;36mHfApi.upload_file\u001b[0;34m(self, path_or_fileobj, path_in_repo, repo_id, token, repo_type, revision, commit_message, commit_description, create_pr, parent_commit)\u001b[0m\n\u001b[1;32m   2990\u001b[0m commit_message \u001b[39m=\u001b[39m (\n\u001b[1;32m   2991\u001b[0m     commit_message \u001b[39mif\u001b[39;00m commit_message \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpload \u001b[39m\u001b[39m{\u001b[39;00mpath_in_repo\u001b[39m}\u001b[39;00m\u001b[39m with huggingface_hub\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2992\u001b[0m )\n\u001b[1;32m   2993\u001b[0m operation \u001b[39m=\u001b[39m CommitOperationAdd(\n\u001b[1;32m   2994\u001b[0m     path_or_fileobj\u001b[39m=\u001b[39mpath_or_fileobj,\n\u001b[1;32m   2995\u001b[0m     path_in_repo\u001b[39m=\u001b[39mpath_in_repo,\n\u001b[1;32m   2996\u001b[0m )\n\u001b[0;32m-> 2998\u001b[0m commit_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_commit(\n\u001b[1;32m   2999\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   3000\u001b[0m     repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m   3001\u001b[0m     operations\u001b[39m=\u001b[39;49m[operation],\n\u001b[1;32m   3002\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[1;32m   3003\u001b[0m     commit_description\u001b[39m=\u001b[39;49mcommit_description,\n\u001b[1;32m   3004\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   3005\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   3006\u001b[0m     create_pr\u001b[39m=\u001b[39;49mcreate_pr,\n\u001b[1;32m   3007\u001b[0m     parent_commit\u001b[39m=\u001b[39;49mparent_commit,\n\u001b[1;32m   3008\u001b[0m )\n\u001b[1;32m   3010\u001b[0m \u001b[39mif\u001b[39;00m commit_info\u001b[39m.\u001b[39mpr_url \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3011\u001b[0m     revision \u001b[39m=\u001b[39m quote(_parse_revision_from_pr_url(commit_info\u001b[39m.\u001b[39mpr_url), safe\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2516\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit)\u001b[0m\n\u001b[1;32m   2513\u001b[0m     e\u001b[39m.\u001b[39mappend_to_message(_CREATE_COMMIT_NO_REPO_ERROR_MESSAGE)\n\u001b[1;32m   2514\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 2516\u001b[0m upload_lfs_files(\n\u001b[1;32m   2517\u001b[0m     additions\u001b[39m=\u001b[39;49m[addition \u001b[39mfor\u001b[39;49;00m addition \u001b[39min\u001b[39;49;00m additions \u001b[39mif\u001b[39;49;00m upload_modes[addition\u001b[39m.\u001b[39;49mpath_in_repo] \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlfs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2518\u001b[0m     repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m   2519\u001b[0m     repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[1;32m   2520\u001b[0m     token\u001b[39m=\u001b[39;49mtoken \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m   2521\u001b[0m     endpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint,\n\u001b[1;32m   2522\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m   2523\u001b[0m )\n\u001b[1;32m   2524\u001b[0m commit_payload \u001b[39m=\u001b[39m prepare_commit_payload(\n\u001b[1;32m   2525\u001b[0m     operations\u001b[39m=\u001b[39moperations,\n\u001b[1;32m   2526\u001b[0m     upload_modes\u001b[39m=\u001b[39mupload_modes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     parent_commit\u001b[39m=\u001b[39mparent_commit,\n\u001b[1;32m   2530\u001b[0m )\n\u001b[1;32m   2531\u001b[0m commit_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/\u001b[39m\u001b[39m{\u001b[39;00mrepo_type\u001b[39m}\u001b[39;00m\u001b[39ms/\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m/commit/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:353\u001b[0m, in \u001b[0;36mupload_lfs_files\u001b[0;34m(additions, repo_type, repo_id, token, endpoint, num_threads)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    351\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploading \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(filtered_actions)\u001b[39m}\u001b[39;00m\u001b[39m LFS files to the Hub using up to \u001b[39m\u001b[39m{\u001b[39;00mnum_threads\u001b[39m}\u001b[39;00m\u001b[39m threads concurrently\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m     )\n\u001b[0;32m--> 353\u001b[0m     thread_map(\n\u001b[1;32m    354\u001b[0m         _wrapped_lfs_upload,\n\u001b[1;32m    355\u001b[0m         filtered_actions,\n\u001b[1;32m    356\u001b[0m         desc\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUpload \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mlen\u001b[39;49m(filtered_actions)\u001b[39m}\u001b[39;49;00m\u001b[39m LFS files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    357\u001b[0m         max_workers\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m    358\u001b[0m         tqdm_class\u001b[39m=\u001b[39;49mhf_tqdm,\n\u001b[1;32m    359\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/tqdm/contrib/concurrent.py:94\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 94\u001b[0m \u001b[39mreturn\u001b[39;00m _executor_map(ThreadPoolExecutor, fn, \u001b[39m*\u001b[39;49miterables, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtqdm_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/tqdm/contrib/concurrent.py:76\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     map_args\u001b[39m.\u001b[39mupdate(chunksize\u001b[39m=\u001b[39mchunksize)\n\u001b[1;32m     75\u001b[0m \u001b[39mwith\u001b[39;00m PoolExecutor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpool_kwargs) \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(tqdm_class(ex\u001b[39m.\u001b[39;49mmap(fn, \u001b[39m*\u001b[39;49miterables, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmap_args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    622\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult(timeout)\n\u001b[1;32m    320\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/asr/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:343\u001b[0m, in \u001b[0;36mupload_lfs_files.<locals>._wrapped_lfs_upload\u001b[0;34m(batch_action)\u001b[0m\n\u001b[1;32m    341\u001b[0m     lfs_upload(operation\u001b[39m=\u001b[39moperation, lfs_batch_action\u001b[39m=\u001b[39mbatch_action, token\u001b[39m=\u001b[39mtoken)\n\u001b[1;32m    342\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError while uploading \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moperation\u001b[39m.\u001b[39mpath_in_repo\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to the Hub.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error while uploading 'data/test-00014-of-00032-b9f5e362471b1a0c.parquet' to the Hub."
     ]
    }
   ],
   "source": [
    "raw_datasets.push_to_hub(\"Ujan/asr_testset_zh_16k\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8263d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dba24d60b6106a525e22e48a87e1b86de85e85410d41403c99e9fde77685272c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
