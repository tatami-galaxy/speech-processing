{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd662fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers.utils.fx import symbolic_trace\n",
    "from transformers import AutoConfig, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.fx as fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'openai/whisper-small'\n",
    "data_dir = 'mozilla-foundation/common_voice_11_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fa02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from mozilla-foundation/common_voice_11_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1448: UserWarning: disabled check : \n",
      "                attn_weights.size() == (bsz * self.num_heads, tgt_len, src_len) \n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1453: UserWarning: disabled check :\n",
      "                attn_output.size() == (bsz * self.num_heads, tgt_len, self.head_dim)\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1458: UserWarning: if passing in a tuple for encoder_outputs, wrap it in a BaseModelOutput when return_dict=True\n",
      "                before passing through model. As :\n",
      "                    encoder_outputs = BaseModelOutput(\n",
      "                    last_hidden_state=encoder_outputs[0],\n",
      "                    hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
      "                    attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
      "            )\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1467: UserWarning: clamping disabled in WhisperEncoderLayer.forward\n",
      "  warnings.warn('clamping disabled in WhisperEncoderLayer.forward')\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1468: UserWarning: disabled check : \n",
      "                if head_mask/cross_attn_head_mask has a correct number of layers specified\n",
      "            in WhisperDecoder.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1473: UserWarning: disabled check : \n",
      "                attention_mask.size() == (bsz, 1, tgt_len, src_len))\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1478: UserWarning: disabled check : \n",
      "                layer_head_mask.size() != (self.num_heads,)\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1483: UserWarning: prefix tuning disabled in WhisperAttention.forward\n",
      "  warnings.warn('prefix tuning disabled in WhisperAttention.forward')\n",
      "Reading metadata...: 10581it [00:00, 11665.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "print('loading dataset from {}'.format(data_dir))\n",
    "\n",
    "raw_datasets = load_dataset(data_dir, \"zh-CN\", split=\"test\", streaming=True)\n",
    "text_column_name = 'sentence'\n",
    "\n",
    "\n",
    "# model, tokenizer, feature extractor, processor\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "model_config.update({\"forced_decoder_ids\": [], \"suppress_tokens\": []})\n",
    "\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #use_fast=model_args.use_fast_tokenizer,\n",
    "    #revision=model_args.model_revision,\n",
    "    #use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "tokenizer.set_prefix_tokens(language='chinese', task='transcribe')\n",
    "\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    config=model_config,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "if model.config.decoder_start_token_id is None:\n",
    "    raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
    "    \n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path)\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='chinese', task='transcribe')\n",
    "\n",
    "\n",
    "dataset = raw_datasets\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "\n",
    "\n",
    "inputs = processor(\n",
    "    sample['audio'][\"array\"],\n",
    "    sampling_rate=feature_extractor.sampling_rate,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\")\n",
    "                \n",
    "input_features = inputs.input_features\n",
    "attention_mask = inputs.attention_mask\n",
    "decoder_input_ids = torch.tensor([model.config.decoder_start_token_id]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7a8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265c4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496383a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_concrete_args={\n",
    "                'output_hidden_states': False,\n",
    "                'output_attentions': False,\n",
    "                'head_mask': None,\n",
    "                'return_dict': True,\n",
    "              }\n",
    "\n",
    "decoder_concrete_args={\n",
    "                'output_hidden_states': False,\n",
    "                'output_attentions': False,\n",
    "                'return_dict': True,\n",
    "                'use_cache': True,\n",
    "                'decoder_inputs_embeds': None,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c669c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_traced : torch.fx.GraphModule = symbolic_trace(encoder, concrete_args=encoder_concrete_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056376e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, input_features, attention_mask = None, head_mask_1 = None, output_attentions_1 = None, output_hidden_states_1 = None, return_dict_1 = None):\n",
      "    _assert_is_none = torch.fx._symbolic_trace._assert_is_none(head_mask_1, 'head_mask has been specialized to have value None but got another value');  head_mask_1 = None\n",
      "    eq = output_attentions_1 == False;  output_attentions_1 = None\n",
      "    _assert = torch._assert(eq, 'output_attentions has been specialized to have value False but got another value');  eq = None\n",
      "    eq_1 = output_hidden_states_1 == False;  output_hidden_states_1 = None\n",
      "    _assert_1 = torch._assert(eq_1, 'output_hidden_states has been specialized to have value False but got another value');  eq_1 = None\n",
      "    eq_2 = return_dict_1 == True;  return_dict_1 = None\n",
      "    _assert_2 = torch._assert(eq_2, 'return_dict has been specialized to have value True but got another value');  eq_2 = None\n",
      "    conv1 = self.conv1(input_features);  input_features = None\n",
      "    gelu = torch._C._nn.gelu(conv1);  conv1 = None\n",
      "    conv2 = self.conv2(gelu);  gelu = None\n",
      "    gelu_1 = torch._C._nn.gelu(conv2);  conv2 = None\n",
      "    permute = gelu_1.permute(0, 2, 1);  gelu_1 = None\n",
      "    embed_positions_weight = self.embed_positions.weight\n",
      "    add = permute + embed_positions_weight;  permute = embed_positions_weight = None\n",
      "    dropout = torch.nn.functional.dropout(add, p = 0.0, training = False, inplace = False);  add = None\n",
      "    layers_0_self_attn_layer_norm = getattr(self.layers, \"0\").self_attn_layer_norm(dropout)\n",
      "    size = layers_0_self_attn_layer_norm.size()\n",
      "    getitem = size[0]\n",
      "    getitem_1 = size[1]\n",
      "    getitem_2 = size[2];  size = None\n",
      "    layers_0_self_attn_q_proj = getattr(self.layers, \"0\").self_attn.q_proj(layers_0_self_attn_layer_norm)\n",
      "    mul = layers_0_self_attn_q_proj * 0.125;  layers_0_self_attn_q_proj = None\n",
      "    layers_0_self_attn_k_proj = getattr(self.layers, \"0\").self_attn.k_proj(layers_0_self_attn_layer_norm)\n",
      "    view = layers_0_self_attn_k_proj.view(getitem, -1, 12, 64);  layers_0_self_attn_k_proj = None\n",
      "    transpose = view.transpose(1, 2);  view = None\n",
      "    contiguous = transpose.contiguous();  transpose = None\n",
      "    layers_0_self_attn_v_proj = getattr(self.layers, \"0\").self_attn.v_proj(layers_0_self_attn_layer_norm);  layers_0_self_attn_layer_norm = None\n",
      "    view_1 = layers_0_self_attn_v_proj.view(getitem, -1, 12, 64);  layers_0_self_attn_v_proj = None\n",
      "    transpose_1 = view_1.transpose(1, 2);  view_1 = None\n",
      "    contiguous_1 = transpose_1.contiguous();  transpose_1 = None\n",
      "    mul_1 = getitem * 12\n",
      "    view_2 = mul.view(getitem, getitem_1, 12, 64);  mul = None\n",
      "    transpose_2 = view_2.transpose(1, 2);  view_2 = None\n",
      "    contiguous_2 = transpose_2.contiguous();  transpose_2 = None\n",
      "    view_3 = contiguous_2.view(mul_1, -1, 64);  contiguous_2 = None\n",
      "    reshape = contiguous.reshape(mul_1, -1, 64);  contiguous = None\n",
      "    reshape_1 = contiguous_1.reshape(mul_1, -1, 64);  contiguous_1 = mul_1 = None\n",
      "    size_1 = reshape.size(1)\n",
      "    transpose_3 = reshape.transpose(1, 2);  reshape = None\n",
      "    bmm = torch.bmm(view_3, transpose_3);  view_3 = transpose_3 = None\n",
      "    softmax = torch.nn.functional.softmax(bmm, dim = -1, _stacklevel = 3, dtype = None);  bmm = None\n",
      "    dropout_1 = torch.nn.functional.dropout(softmax, p = 0.0, training = False, inplace = False);  softmax = None\n",
      "    bmm_1 = torch.bmm(dropout_1, reshape_1);  dropout_1 = reshape_1 = None\n",
      "    view_4 = bmm_1.view(getitem, 12, getitem_1, 64);  bmm_1 = None\n",
      "    transpose_4 = view_4.transpose(1, 2);  view_4 = None\n",
      "    reshape_2 = transpose_4.reshape(getitem, getitem_1, 768);  transpose_4 = getitem = getitem_1 = None\n",
      "    layers_0_self_attn_out_proj = getattr(self.layers, \"0\").self_attn.out_proj(reshape_2);  reshape_2 = None\n",
      "    dropout_2 = torch.nn.functional.dropout(layers_0_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_0_self_attn_out_proj = None\n",
      "    add_1 = dropout + dropout_2;  dropout = dropout_2 = None\n",
      "    layers_0_final_layer_norm = getattr(self.layers, \"0\").final_layer_norm(add_1)\n",
      "    layers_0_fc1 = getattr(self.layers, \"0\").fc1(layers_0_final_layer_norm);  layers_0_final_layer_norm = None\n",
      "    gelu_2 = torch._C._nn.gelu(layers_0_fc1);  layers_0_fc1 = None\n",
      "    dropout_3 = torch.nn.functional.dropout(gelu_2, p = 0.0, training = False, inplace = False);  gelu_2 = None\n",
      "    layers_0_fc2 = getattr(self.layers, \"0\").fc2(dropout_3);  dropout_3 = None\n",
      "    dropout_4 = torch.nn.functional.dropout(layers_0_fc2, p = 0.0, training = False, inplace = False);  layers_0_fc2 = None\n",
      "    add_2 = add_1 + dropout_4;  add_1 = dropout_4 = None\n",
      "    layers_1_self_attn_layer_norm = getattr(self.layers, \"1\").self_attn_layer_norm(add_2)\n",
      "    size_2 = layers_1_self_attn_layer_norm.size()\n",
      "    getitem_3 = size_2[0]\n",
      "    getitem_4 = size_2[1]\n",
      "    getitem_5 = size_2[2];  size_2 = None\n",
      "    layers_1_self_attn_q_proj = getattr(self.layers, \"1\").self_attn.q_proj(layers_1_self_attn_layer_norm)\n",
      "    mul_2 = layers_1_self_attn_q_proj * 0.125;  layers_1_self_attn_q_proj = None\n",
      "    layers_1_self_attn_k_proj = getattr(self.layers, \"1\").self_attn.k_proj(layers_1_self_attn_layer_norm)\n",
      "    view_5 = layers_1_self_attn_k_proj.view(getitem_3, -1, 12, 64);  layers_1_self_attn_k_proj = None\n",
      "    transpose_5 = view_5.transpose(1, 2);  view_5 = None\n",
      "    contiguous_3 = transpose_5.contiguous();  transpose_5 = None\n",
      "    layers_1_self_attn_v_proj = getattr(self.layers, \"1\").self_attn.v_proj(layers_1_self_attn_layer_norm);  layers_1_self_attn_layer_norm = None\n",
      "    view_6 = layers_1_self_attn_v_proj.view(getitem_3, -1, 12, 64);  layers_1_self_attn_v_proj = None\n",
      "    transpose_6 = view_6.transpose(1, 2);  view_6 = None\n",
      "    contiguous_4 = transpose_6.contiguous();  transpose_6 = None\n",
      "    mul_3 = getitem_3 * 12\n",
      "    view_7 = mul_2.view(getitem_3, getitem_4, 12, 64);  mul_2 = None\n",
      "    transpose_7 = view_7.transpose(1, 2);  view_7 = None\n",
      "    contiguous_5 = transpose_7.contiguous();  transpose_7 = None\n",
      "    view_8 = contiguous_5.view(mul_3, -1, 64);  contiguous_5 = None\n",
      "    reshape_3 = contiguous_3.reshape(mul_3, -1, 64);  contiguous_3 = None\n",
      "    reshape_4 = contiguous_4.reshape(mul_3, -1, 64);  contiguous_4 = mul_3 = None\n",
      "    size_3 = reshape_3.size(1)\n",
      "    transpose_8 = reshape_3.transpose(1, 2);  reshape_3 = None\n",
      "    bmm_2 = torch.bmm(view_8, transpose_8);  view_8 = transpose_8 = None\n",
      "    softmax_1 = torch.nn.functional.softmax(bmm_2, dim = -1, _stacklevel = 3, dtype = None);  bmm_2 = None\n",
      "    dropout_5 = torch.nn.functional.dropout(softmax_1, p = 0.0, training = False, inplace = False);  softmax_1 = None\n",
      "    bmm_3 = torch.bmm(dropout_5, reshape_4);  dropout_5 = reshape_4 = None\n",
      "    view_9 = bmm_3.view(getitem_3, 12, getitem_4, 64);  bmm_3 = None\n",
      "    transpose_9 = view_9.transpose(1, 2);  view_9 = None\n",
      "    reshape_5 = transpose_9.reshape(getitem_3, getitem_4, 768);  transpose_9 = getitem_3 = getitem_4 = None\n",
      "    layers_1_self_attn_out_proj = getattr(self.layers, \"1\").self_attn.out_proj(reshape_5);  reshape_5 = None\n",
      "    dropout_6 = torch.nn.functional.dropout(layers_1_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_1_self_attn_out_proj = None\n",
      "    add_3 = add_2 + dropout_6;  add_2 = dropout_6 = None\n",
      "    layers_1_final_layer_norm = getattr(self.layers, \"1\").final_layer_norm(add_3)\n",
      "    layers_1_fc1 = getattr(self.layers, \"1\").fc1(layers_1_final_layer_norm);  layers_1_final_layer_norm = None\n",
      "    gelu_3 = torch._C._nn.gelu(layers_1_fc1);  layers_1_fc1 = None\n",
      "    dropout_7 = torch.nn.functional.dropout(gelu_3, p = 0.0, training = False, inplace = False);  gelu_3 = None\n",
      "    layers_1_fc2 = getattr(self.layers, \"1\").fc2(dropout_7);  dropout_7 = None\n",
      "    dropout_8 = torch.nn.functional.dropout(layers_1_fc2, p = 0.0, training = False, inplace = False);  layers_1_fc2 = None\n",
      "    add_4 = add_3 + dropout_8;  add_3 = dropout_8 = None\n",
      "    layers_2_self_attn_layer_norm = getattr(self.layers, \"2\").self_attn_layer_norm(add_4)\n",
      "    size_4 = layers_2_self_attn_layer_norm.size()\n",
      "    getitem_6 = size_4[0]\n",
      "    getitem_7 = size_4[1]\n",
      "    getitem_8 = size_4[2];  size_4 = None\n",
      "    layers_2_self_attn_q_proj = getattr(self.layers, \"2\").self_attn.q_proj(layers_2_self_attn_layer_norm)\n",
      "    mul_4 = layers_2_self_attn_q_proj * 0.125;  layers_2_self_attn_q_proj = None\n",
      "    layers_2_self_attn_k_proj = getattr(self.layers, \"2\").self_attn.k_proj(layers_2_self_attn_layer_norm)\n",
      "    view_10 = layers_2_self_attn_k_proj.view(getitem_6, -1, 12, 64);  layers_2_self_attn_k_proj = None\n",
      "    transpose_10 = view_10.transpose(1, 2);  view_10 = None\n",
      "    contiguous_6 = transpose_10.contiguous();  transpose_10 = None\n",
      "    layers_2_self_attn_v_proj = getattr(self.layers, \"2\").self_attn.v_proj(layers_2_self_attn_layer_norm);  layers_2_self_attn_layer_norm = None\n",
      "    view_11 = layers_2_self_attn_v_proj.view(getitem_6, -1, 12, 64);  layers_2_self_attn_v_proj = None\n",
      "    transpose_11 = view_11.transpose(1, 2);  view_11 = None\n",
      "    contiguous_7 = transpose_11.contiguous();  transpose_11 = None\n",
      "    mul_5 = getitem_6 * 12\n",
      "    view_12 = mul_4.view(getitem_6, getitem_7, 12, 64);  mul_4 = None\n",
      "    transpose_12 = view_12.transpose(1, 2);  view_12 = None\n",
      "    contiguous_8 = transpose_12.contiguous();  transpose_12 = None\n",
      "    view_13 = contiguous_8.view(mul_5, -1, 64);  contiguous_8 = None\n",
      "    reshape_6 = contiguous_6.reshape(mul_5, -1, 64);  contiguous_6 = None\n",
      "    reshape_7 = contiguous_7.reshape(mul_5, -1, 64);  contiguous_7 = mul_5 = None\n",
      "    size_5 = reshape_6.size(1)\n",
      "    transpose_13 = reshape_6.transpose(1, 2);  reshape_6 = None\n",
      "    bmm_4 = torch.bmm(view_13, transpose_13);  view_13 = transpose_13 = None\n",
      "    softmax_2 = torch.nn.functional.softmax(bmm_4, dim = -1, _stacklevel = 3, dtype = None);  bmm_4 = None\n",
      "    dropout_9 = torch.nn.functional.dropout(softmax_2, p = 0.0, training = False, inplace = False);  softmax_2 = None\n",
      "    bmm_5 = torch.bmm(dropout_9, reshape_7);  dropout_9 = reshape_7 = None\n",
      "    view_14 = bmm_5.view(getitem_6, 12, getitem_7, 64);  bmm_5 = None\n",
      "    transpose_14 = view_14.transpose(1, 2);  view_14 = None\n",
      "    reshape_8 = transpose_14.reshape(getitem_6, getitem_7, 768);  transpose_14 = getitem_6 = getitem_7 = None\n",
      "    layers_2_self_attn_out_proj = getattr(self.layers, \"2\").self_attn.out_proj(reshape_8);  reshape_8 = None\n",
      "    dropout_10 = torch.nn.functional.dropout(layers_2_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_2_self_attn_out_proj = None\n",
      "    add_5 = add_4 + dropout_10;  add_4 = dropout_10 = None\n",
      "    layers_2_final_layer_norm = getattr(self.layers, \"2\").final_layer_norm(add_5)\n",
      "    layers_2_fc1 = getattr(self.layers, \"2\").fc1(layers_2_final_layer_norm);  layers_2_final_layer_norm = None\n",
      "    gelu_4 = torch._C._nn.gelu(layers_2_fc1);  layers_2_fc1 = None\n",
      "    dropout_11 = torch.nn.functional.dropout(gelu_4, p = 0.0, training = False, inplace = False);  gelu_4 = None\n",
      "    layers_2_fc2 = getattr(self.layers, \"2\").fc2(dropout_11);  dropout_11 = None\n",
      "    dropout_12 = torch.nn.functional.dropout(layers_2_fc2, p = 0.0, training = False, inplace = False);  layers_2_fc2 = None\n",
      "    add_6 = add_5 + dropout_12;  add_5 = dropout_12 = None\n",
      "    layers_3_self_attn_layer_norm = getattr(self.layers, \"3\").self_attn_layer_norm(add_6)\n",
      "    size_6 = layers_3_self_attn_layer_norm.size()\n",
      "    getitem_9 = size_6[0]\n",
      "    getitem_10 = size_6[1]\n",
      "    getitem_11 = size_6[2];  size_6 = None\n",
      "    layers_3_self_attn_q_proj = getattr(self.layers, \"3\").self_attn.q_proj(layers_3_self_attn_layer_norm)\n",
      "    mul_6 = layers_3_self_attn_q_proj * 0.125;  layers_3_self_attn_q_proj = None\n",
      "    layers_3_self_attn_k_proj = getattr(self.layers, \"3\").self_attn.k_proj(layers_3_self_attn_layer_norm)\n",
      "    view_15 = layers_3_self_attn_k_proj.view(getitem_9, -1, 12, 64);  layers_3_self_attn_k_proj = None\n",
      "    transpose_15 = view_15.transpose(1, 2);  view_15 = None\n",
      "    contiguous_9 = transpose_15.contiguous();  transpose_15 = None\n",
      "    layers_3_self_attn_v_proj = getattr(self.layers, \"3\").self_attn.v_proj(layers_3_self_attn_layer_norm);  layers_3_self_attn_layer_norm = None\n",
      "    view_16 = layers_3_self_attn_v_proj.view(getitem_9, -1, 12, 64);  layers_3_self_attn_v_proj = None\n",
      "    transpose_16 = view_16.transpose(1, 2);  view_16 = None\n",
      "    contiguous_10 = transpose_16.contiguous();  transpose_16 = None\n",
      "    mul_7 = getitem_9 * 12\n",
      "    view_17 = mul_6.view(getitem_9, getitem_10, 12, 64);  mul_6 = None\n",
      "    transpose_17 = view_17.transpose(1, 2);  view_17 = None\n",
      "    contiguous_11 = transpose_17.contiguous();  transpose_17 = None\n",
      "    view_18 = contiguous_11.view(mul_7, -1, 64);  contiguous_11 = None\n",
      "    reshape_9 = contiguous_9.reshape(mul_7, -1, 64);  contiguous_9 = None\n",
      "    reshape_10 = contiguous_10.reshape(mul_7, -1, 64);  contiguous_10 = mul_7 = None\n",
      "    size_7 = reshape_9.size(1)\n",
      "    transpose_18 = reshape_9.transpose(1, 2);  reshape_9 = None\n",
      "    bmm_6 = torch.bmm(view_18, transpose_18);  view_18 = transpose_18 = None\n",
      "    softmax_3 = torch.nn.functional.softmax(bmm_6, dim = -1, _stacklevel = 3, dtype = None);  bmm_6 = None\n",
      "    dropout_13 = torch.nn.functional.dropout(softmax_3, p = 0.0, training = False, inplace = False);  softmax_3 = None\n",
      "    bmm_7 = torch.bmm(dropout_13, reshape_10);  dropout_13 = reshape_10 = None\n",
      "    view_19 = bmm_7.view(getitem_9, 12, getitem_10, 64);  bmm_7 = None\n",
      "    transpose_19 = view_19.transpose(1, 2);  view_19 = None\n",
      "    reshape_11 = transpose_19.reshape(getitem_9, getitem_10, 768);  transpose_19 = getitem_9 = getitem_10 = None\n",
      "    layers_3_self_attn_out_proj = getattr(self.layers, \"3\").self_attn.out_proj(reshape_11);  reshape_11 = None\n",
      "    dropout_14 = torch.nn.functional.dropout(layers_3_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_3_self_attn_out_proj = None\n",
      "    add_7 = add_6 + dropout_14;  add_6 = dropout_14 = None\n",
      "    layers_3_final_layer_norm = getattr(self.layers, \"3\").final_layer_norm(add_7)\n",
      "    layers_3_fc1 = getattr(self.layers, \"3\").fc1(layers_3_final_layer_norm);  layers_3_final_layer_norm = None\n",
      "    gelu_5 = torch._C._nn.gelu(layers_3_fc1);  layers_3_fc1 = None\n",
      "    dropout_15 = torch.nn.functional.dropout(gelu_5, p = 0.0, training = False, inplace = False);  gelu_5 = None\n",
      "    layers_3_fc2 = getattr(self.layers, \"3\").fc2(dropout_15);  dropout_15 = None\n",
      "    dropout_16 = torch.nn.functional.dropout(layers_3_fc2, p = 0.0, training = False, inplace = False);  layers_3_fc2 = None\n",
      "    add_8 = add_7 + dropout_16;  add_7 = dropout_16 = None\n",
      "    layers_4_self_attn_layer_norm = getattr(self.layers, \"4\").self_attn_layer_norm(add_8)\n",
      "    size_8 = layers_4_self_attn_layer_norm.size()\n",
      "    getitem_12 = size_8[0]\n",
      "    getitem_13 = size_8[1]\n",
      "    getitem_14 = size_8[2];  size_8 = None\n",
      "    layers_4_self_attn_q_proj = getattr(self.layers, \"4\").self_attn.q_proj(layers_4_self_attn_layer_norm)\n",
      "    mul_8 = layers_4_self_attn_q_proj * 0.125;  layers_4_self_attn_q_proj = None\n",
      "    layers_4_self_attn_k_proj = getattr(self.layers, \"4\").self_attn.k_proj(layers_4_self_attn_layer_norm)\n",
      "    view_20 = layers_4_self_attn_k_proj.view(getitem_12, -1, 12, 64);  layers_4_self_attn_k_proj = None\n",
      "    transpose_20 = view_20.transpose(1, 2);  view_20 = None\n",
      "    contiguous_12 = transpose_20.contiguous();  transpose_20 = None\n",
      "    layers_4_self_attn_v_proj = getattr(self.layers, \"4\").self_attn.v_proj(layers_4_self_attn_layer_norm);  layers_4_self_attn_layer_norm = None\n",
      "    view_21 = layers_4_self_attn_v_proj.view(getitem_12, -1, 12, 64);  layers_4_self_attn_v_proj = None\n",
      "    transpose_21 = view_21.transpose(1, 2);  view_21 = None\n",
      "    contiguous_13 = transpose_21.contiguous();  transpose_21 = None\n",
      "    mul_9 = getitem_12 * 12\n",
      "    view_22 = mul_8.view(getitem_12, getitem_13, 12, 64);  mul_8 = None\n",
      "    transpose_22 = view_22.transpose(1, 2);  view_22 = None\n",
      "    contiguous_14 = transpose_22.contiguous();  transpose_22 = None\n",
      "    view_23 = contiguous_14.view(mul_9, -1, 64);  contiguous_14 = None\n",
      "    reshape_12 = contiguous_12.reshape(mul_9, -1, 64);  contiguous_12 = None\n",
      "    reshape_13 = contiguous_13.reshape(mul_9, -1, 64);  contiguous_13 = mul_9 = None\n",
      "    size_9 = reshape_12.size(1)\n",
      "    transpose_23 = reshape_12.transpose(1, 2);  reshape_12 = None\n",
      "    bmm_8 = torch.bmm(view_23, transpose_23);  view_23 = transpose_23 = None\n",
      "    softmax_4 = torch.nn.functional.softmax(bmm_8, dim = -1, _stacklevel = 3, dtype = None);  bmm_8 = None\n",
      "    dropout_17 = torch.nn.functional.dropout(softmax_4, p = 0.0, training = False, inplace = False);  softmax_4 = None\n",
      "    bmm_9 = torch.bmm(dropout_17, reshape_13);  dropout_17 = reshape_13 = None\n",
      "    view_24 = bmm_9.view(getitem_12, 12, getitem_13, 64);  bmm_9 = None\n",
      "    transpose_24 = view_24.transpose(1, 2);  view_24 = None\n",
      "    reshape_14 = transpose_24.reshape(getitem_12, getitem_13, 768);  transpose_24 = getitem_12 = getitem_13 = None\n",
      "    layers_4_self_attn_out_proj = getattr(self.layers, \"4\").self_attn.out_proj(reshape_14);  reshape_14 = None\n",
      "    dropout_18 = torch.nn.functional.dropout(layers_4_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_4_self_attn_out_proj = None\n",
      "    add_9 = add_8 + dropout_18;  add_8 = dropout_18 = None\n",
      "    layers_4_final_layer_norm = getattr(self.layers, \"4\").final_layer_norm(add_9)\n",
      "    layers_4_fc1 = getattr(self.layers, \"4\").fc1(layers_4_final_layer_norm);  layers_4_final_layer_norm = None\n",
      "    gelu_6 = torch._C._nn.gelu(layers_4_fc1);  layers_4_fc1 = None\n",
      "    dropout_19 = torch.nn.functional.dropout(gelu_6, p = 0.0, training = False, inplace = False);  gelu_6 = None\n",
      "    layers_4_fc2 = getattr(self.layers, \"4\").fc2(dropout_19);  dropout_19 = None\n",
      "    dropout_20 = torch.nn.functional.dropout(layers_4_fc2, p = 0.0, training = False, inplace = False);  layers_4_fc2 = None\n",
      "    add_10 = add_9 + dropout_20;  add_9 = dropout_20 = None\n",
      "    layers_5_self_attn_layer_norm = getattr(self.layers, \"5\").self_attn_layer_norm(add_10)\n",
      "    size_10 = layers_5_self_attn_layer_norm.size()\n",
      "    getitem_15 = size_10[0]\n",
      "    getitem_16 = size_10[1]\n",
      "    getitem_17 = size_10[2];  size_10 = None\n",
      "    layers_5_self_attn_q_proj = getattr(self.layers, \"5\").self_attn.q_proj(layers_5_self_attn_layer_norm)\n",
      "    mul_10 = layers_5_self_attn_q_proj * 0.125;  layers_5_self_attn_q_proj = None\n",
      "    layers_5_self_attn_k_proj = getattr(self.layers, \"5\").self_attn.k_proj(layers_5_self_attn_layer_norm)\n",
      "    view_25 = layers_5_self_attn_k_proj.view(getitem_15, -1, 12, 64);  layers_5_self_attn_k_proj = None\n",
      "    transpose_25 = view_25.transpose(1, 2);  view_25 = None\n",
      "    contiguous_15 = transpose_25.contiguous();  transpose_25 = None\n",
      "    layers_5_self_attn_v_proj = getattr(self.layers, \"5\").self_attn.v_proj(layers_5_self_attn_layer_norm);  layers_5_self_attn_layer_norm = None\n",
      "    view_26 = layers_5_self_attn_v_proj.view(getitem_15, -1, 12, 64);  layers_5_self_attn_v_proj = None\n",
      "    transpose_26 = view_26.transpose(1, 2);  view_26 = None\n",
      "    contiguous_16 = transpose_26.contiguous();  transpose_26 = None\n",
      "    mul_11 = getitem_15 * 12\n",
      "    view_27 = mul_10.view(getitem_15, getitem_16, 12, 64);  mul_10 = None\n",
      "    transpose_27 = view_27.transpose(1, 2);  view_27 = None\n",
      "    contiguous_17 = transpose_27.contiguous();  transpose_27 = None\n",
      "    view_28 = contiguous_17.view(mul_11, -1, 64);  contiguous_17 = None\n",
      "    reshape_15 = contiguous_15.reshape(mul_11, -1, 64);  contiguous_15 = None\n",
      "    reshape_16 = contiguous_16.reshape(mul_11, -1, 64);  contiguous_16 = mul_11 = None\n",
      "    size_11 = reshape_15.size(1)\n",
      "    transpose_28 = reshape_15.transpose(1, 2);  reshape_15 = None\n",
      "    bmm_10 = torch.bmm(view_28, transpose_28);  view_28 = transpose_28 = None\n",
      "    softmax_5 = torch.nn.functional.softmax(bmm_10, dim = -1, _stacklevel = 3, dtype = None);  bmm_10 = None\n",
      "    dropout_21 = torch.nn.functional.dropout(softmax_5, p = 0.0, training = False, inplace = False);  softmax_5 = None\n",
      "    bmm_11 = torch.bmm(dropout_21, reshape_16);  dropout_21 = reshape_16 = None\n",
      "    view_29 = bmm_11.view(getitem_15, 12, getitem_16, 64);  bmm_11 = None\n",
      "    transpose_29 = view_29.transpose(1, 2);  view_29 = None\n",
      "    reshape_17 = transpose_29.reshape(getitem_15, getitem_16, 768);  transpose_29 = getitem_15 = getitem_16 = None\n",
      "    layers_5_self_attn_out_proj = getattr(self.layers, \"5\").self_attn.out_proj(reshape_17);  reshape_17 = None\n",
      "    dropout_22 = torch.nn.functional.dropout(layers_5_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_5_self_attn_out_proj = None\n",
      "    add_11 = add_10 + dropout_22;  add_10 = dropout_22 = None\n",
      "    layers_5_final_layer_norm = getattr(self.layers, \"5\").final_layer_norm(add_11)\n",
      "    layers_5_fc1 = getattr(self.layers, \"5\").fc1(layers_5_final_layer_norm);  layers_5_final_layer_norm = None\n",
      "    gelu_7 = torch._C._nn.gelu(layers_5_fc1);  layers_5_fc1 = None\n",
      "    dropout_23 = torch.nn.functional.dropout(gelu_7, p = 0.0, training = False, inplace = False);  gelu_7 = None\n",
      "    layers_5_fc2 = getattr(self.layers, \"5\").fc2(dropout_23);  dropout_23 = None\n",
      "    dropout_24 = torch.nn.functional.dropout(layers_5_fc2, p = 0.0, training = False, inplace = False);  layers_5_fc2 = None\n",
      "    add_12 = add_11 + dropout_24;  add_11 = dropout_24 = None\n",
      "    layers_6_self_attn_layer_norm = getattr(self.layers, \"6\").self_attn_layer_norm(add_12)\n",
      "    size_12 = layers_6_self_attn_layer_norm.size()\n",
      "    getitem_18 = size_12[0]\n",
      "    getitem_19 = size_12[1]\n",
      "    getitem_20 = size_12[2];  size_12 = None\n",
      "    layers_6_self_attn_q_proj = getattr(self.layers, \"6\").self_attn.q_proj(layers_6_self_attn_layer_norm)\n",
      "    mul_12 = layers_6_self_attn_q_proj * 0.125;  layers_6_self_attn_q_proj = None\n",
      "    layers_6_self_attn_k_proj = getattr(self.layers, \"6\").self_attn.k_proj(layers_6_self_attn_layer_norm)\n",
      "    view_30 = layers_6_self_attn_k_proj.view(getitem_18, -1, 12, 64);  layers_6_self_attn_k_proj = None\n",
      "    transpose_30 = view_30.transpose(1, 2);  view_30 = None\n",
      "    contiguous_18 = transpose_30.contiguous();  transpose_30 = None\n",
      "    layers_6_self_attn_v_proj = getattr(self.layers, \"6\").self_attn.v_proj(layers_6_self_attn_layer_norm);  layers_6_self_attn_layer_norm = None\n",
      "    view_31 = layers_6_self_attn_v_proj.view(getitem_18, -1, 12, 64);  layers_6_self_attn_v_proj = None\n",
      "    transpose_31 = view_31.transpose(1, 2);  view_31 = None\n",
      "    contiguous_19 = transpose_31.contiguous();  transpose_31 = None\n",
      "    mul_13 = getitem_18 * 12\n",
      "    view_32 = mul_12.view(getitem_18, getitem_19, 12, 64);  mul_12 = None\n",
      "    transpose_32 = view_32.transpose(1, 2);  view_32 = None\n",
      "    contiguous_20 = transpose_32.contiguous();  transpose_32 = None\n",
      "    view_33 = contiguous_20.view(mul_13, -1, 64);  contiguous_20 = None\n",
      "    reshape_18 = contiguous_18.reshape(mul_13, -1, 64);  contiguous_18 = None\n",
      "    reshape_19 = contiguous_19.reshape(mul_13, -1, 64);  contiguous_19 = mul_13 = None\n",
      "    size_13 = reshape_18.size(1)\n",
      "    transpose_33 = reshape_18.transpose(1, 2);  reshape_18 = None\n",
      "    bmm_12 = torch.bmm(view_33, transpose_33);  view_33 = transpose_33 = None\n",
      "    softmax_6 = torch.nn.functional.softmax(bmm_12, dim = -1, _stacklevel = 3, dtype = None);  bmm_12 = None\n",
      "    dropout_25 = torch.nn.functional.dropout(softmax_6, p = 0.0, training = False, inplace = False);  softmax_6 = None\n",
      "    bmm_13 = torch.bmm(dropout_25, reshape_19);  dropout_25 = reshape_19 = None\n",
      "    view_34 = bmm_13.view(getitem_18, 12, getitem_19, 64);  bmm_13 = None\n",
      "    transpose_34 = view_34.transpose(1, 2);  view_34 = None\n",
      "    reshape_20 = transpose_34.reshape(getitem_18, getitem_19, 768);  transpose_34 = getitem_18 = getitem_19 = None\n",
      "    layers_6_self_attn_out_proj = getattr(self.layers, \"6\").self_attn.out_proj(reshape_20);  reshape_20 = None\n",
      "    dropout_26 = torch.nn.functional.dropout(layers_6_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_6_self_attn_out_proj = None\n",
      "    add_13 = add_12 + dropout_26;  add_12 = dropout_26 = None\n",
      "    layers_6_final_layer_norm = getattr(self.layers, \"6\").final_layer_norm(add_13)\n",
      "    layers_6_fc1 = getattr(self.layers, \"6\").fc1(layers_6_final_layer_norm);  layers_6_final_layer_norm = None\n",
      "    gelu_8 = torch._C._nn.gelu(layers_6_fc1);  layers_6_fc1 = None\n",
      "    dropout_27 = torch.nn.functional.dropout(gelu_8, p = 0.0, training = False, inplace = False);  gelu_8 = None\n",
      "    layers_6_fc2 = getattr(self.layers, \"6\").fc2(dropout_27);  dropout_27 = None\n",
      "    dropout_28 = torch.nn.functional.dropout(layers_6_fc2, p = 0.0, training = False, inplace = False);  layers_6_fc2 = None\n",
      "    add_14 = add_13 + dropout_28;  add_13 = dropout_28 = None\n",
      "    layers_7_self_attn_layer_norm = getattr(self.layers, \"7\").self_attn_layer_norm(add_14)\n",
      "    size_14 = layers_7_self_attn_layer_norm.size()\n",
      "    getitem_21 = size_14[0]\n",
      "    getitem_22 = size_14[1]\n",
      "    getitem_23 = size_14[2];  size_14 = None\n",
      "    layers_7_self_attn_q_proj = getattr(self.layers, \"7\").self_attn.q_proj(layers_7_self_attn_layer_norm)\n",
      "    mul_14 = layers_7_self_attn_q_proj * 0.125;  layers_7_self_attn_q_proj = None\n",
      "    layers_7_self_attn_k_proj = getattr(self.layers, \"7\").self_attn.k_proj(layers_7_self_attn_layer_norm)\n",
      "    view_35 = layers_7_self_attn_k_proj.view(getitem_21, -1, 12, 64);  layers_7_self_attn_k_proj = None\n",
      "    transpose_35 = view_35.transpose(1, 2);  view_35 = None\n",
      "    contiguous_21 = transpose_35.contiguous();  transpose_35 = None\n",
      "    layers_7_self_attn_v_proj = getattr(self.layers, \"7\").self_attn.v_proj(layers_7_self_attn_layer_norm);  layers_7_self_attn_layer_norm = None\n",
      "    view_36 = layers_7_self_attn_v_proj.view(getitem_21, -1, 12, 64);  layers_7_self_attn_v_proj = None\n",
      "    transpose_36 = view_36.transpose(1, 2);  view_36 = None\n",
      "    contiguous_22 = transpose_36.contiguous();  transpose_36 = None\n",
      "    mul_15 = getitem_21 * 12\n",
      "    view_37 = mul_14.view(getitem_21, getitem_22, 12, 64);  mul_14 = None\n",
      "    transpose_37 = view_37.transpose(1, 2);  view_37 = None\n",
      "    contiguous_23 = transpose_37.contiguous();  transpose_37 = None\n",
      "    view_38 = contiguous_23.view(mul_15, -1, 64);  contiguous_23 = None\n",
      "    reshape_21 = contiguous_21.reshape(mul_15, -1, 64);  contiguous_21 = None\n",
      "    reshape_22 = contiguous_22.reshape(mul_15, -1, 64);  contiguous_22 = mul_15 = None\n",
      "    size_15 = reshape_21.size(1)\n",
      "    transpose_38 = reshape_21.transpose(1, 2);  reshape_21 = None\n",
      "    bmm_14 = torch.bmm(view_38, transpose_38);  view_38 = transpose_38 = None\n",
      "    softmax_7 = torch.nn.functional.softmax(bmm_14, dim = -1, _stacklevel = 3, dtype = None);  bmm_14 = None\n",
      "    dropout_29 = torch.nn.functional.dropout(softmax_7, p = 0.0, training = False, inplace = False);  softmax_7 = None\n",
      "    bmm_15 = torch.bmm(dropout_29, reshape_22);  dropout_29 = reshape_22 = None\n",
      "    view_39 = bmm_15.view(getitem_21, 12, getitem_22, 64);  bmm_15 = None\n",
      "    transpose_39 = view_39.transpose(1, 2);  view_39 = None\n",
      "    reshape_23 = transpose_39.reshape(getitem_21, getitem_22, 768);  transpose_39 = getitem_21 = getitem_22 = None\n",
      "    layers_7_self_attn_out_proj = getattr(self.layers, \"7\").self_attn.out_proj(reshape_23);  reshape_23 = None\n",
      "    dropout_30 = torch.nn.functional.dropout(layers_7_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_7_self_attn_out_proj = None\n",
      "    add_15 = add_14 + dropout_30;  add_14 = dropout_30 = None\n",
      "    layers_7_final_layer_norm = getattr(self.layers, \"7\").final_layer_norm(add_15)\n",
      "    layers_7_fc1 = getattr(self.layers, \"7\").fc1(layers_7_final_layer_norm);  layers_7_final_layer_norm = None\n",
      "    gelu_9 = torch._C._nn.gelu(layers_7_fc1);  layers_7_fc1 = None\n",
      "    dropout_31 = torch.nn.functional.dropout(gelu_9, p = 0.0, training = False, inplace = False);  gelu_9 = None\n",
      "    layers_7_fc2 = getattr(self.layers, \"7\").fc2(dropout_31);  dropout_31 = None\n",
      "    dropout_32 = torch.nn.functional.dropout(layers_7_fc2, p = 0.0, training = False, inplace = False);  layers_7_fc2 = None\n",
      "    add_16 = add_15 + dropout_32;  add_15 = dropout_32 = None\n",
      "    layers_8_self_attn_layer_norm = getattr(self.layers, \"8\").self_attn_layer_norm(add_16)\n",
      "    size_16 = layers_8_self_attn_layer_norm.size()\n",
      "    getitem_24 = size_16[0]\n",
      "    getitem_25 = size_16[1]\n",
      "    getitem_26 = size_16[2];  size_16 = None\n",
      "    layers_8_self_attn_q_proj = getattr(self.layers, \"8\").self_attn.q_proj(layers_8_self_attn_layer_norm)\n",
      "    mul_16 = layers_8_self_attn_q_proj * 0.125;  layers_8_self_attn_q_proj = None\n",
      "    layers_8_self_attn_k_proj = getattr(self.layers, \"8\").self_attn.k_proj(layers_8_self_attn_layer_norm)\n",
      "    view_40 = layers_8_self_attn_k_proj.view(getitem_24, -1, 12, 64);  layers_8_self_attn_k_proj = None\n",
      "    transpose_40 = view_40.transpose(1, 2);  view_40 = None\n",
      "    contiguous_24 = transpose_40.contiguous();  transpose_40 = None\n",
      "    layers_8_self_attn_v_proj = getattr(self.layers, \"8\").self_attn.v_proj(layers_8_self_attn_layer_norm);  layers_8_self_attn_layer_norm = None\n",
      "    view_41 = layers_8_self_attn_v_proj.view(getitem_24, -1, 12, 64);  layers_8_self_attn_v_proj = None\n",
      "    transpose_41 = view_41.transpose(1, 2);  view_41 = None\n",
      "    contiguous_25 = transpose_41.contiguous();  transpose_41 = None\n",
      "    mul_17 = getitem_24 * 12\n",
      "    view_42 = mul_16.view(getitem_24, getitem_25, 12, 64);  mul_16 = None\n",
      "    transpose_42 = view_42.transpose(1, 2);  view_42 = None\n",
      "    contiguous_26 = transpose_42.contiguous();  transpose_42 = None\n",
      "    view_43 = contiguous_26.view(mul_17, -1, 64);  contiguous_26 = None\n",
      "    reshape_24 = contiguous_24.reshape(mul_17, -1, 64);  contiguous_24 = None\n",
      "    reshape_25 = contiguous_25.reshape(mul_17, -1, 64);  contiguous_25 = mul_17 = None\n",
      "    size_17 = reshape_24.size(1)\n",
      "    transpose_43 = reshape_24.transpose(1, 2);  reshape_24 = None\n",
      "    bmm_16 = torch.bmm(view_43, transpose_43);  view_43 = transpose_43 = None\n",
      "    softmax_8 = torch.nn.functional.softmax(bmm_16, dim = -1, _stacklevel = 3, dtype = None);  bmm_16 = None\n",
      "    dropout_33 = torch.nn.functional.dropout(softmax_8, p = 0.0, training = False, inplace = False);  softmax_8 = None\n",
      "    bmm_17 = torch.bmm(dropout_33, reshape_25);  dropout_33 = reshape_25 = None\n",
      "    view_44 = bmm_17.view(getitem_24, 12, getitem_25, 64);  bmm_17 = None\n",
      "    transpose_44 = view_44.transpose(1, 2);  view_44 = None\n",
      "    reshape_26 = transpose_44.reshape(getitem_24, getitem_25, 768);  transpose_44 = getitem_24 = getitem_25 = None\n",
      "    layers_8_self_attn_out_proj = getattr(self.layers, \"8\").self_attn.out_proj(reshape_26);  reshape_26 = None\n",
      "    dropout_34 = torch.nn.functional.dropout(layers_8_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_8_self_attn_out_proj = None\n",
      "    add_17 = add_16 + dropout_34;  add_16 = dropout_34 = None\n",
      "    layers_8_final_layer_norm = getattr(self.layers, \"8\").final_layer_norm(add_17)\n",
      "    layers_8_fc1 = getattr(self.layers, \"8\").fc1(layers_8_final_layer_norm);  layers_8_final_layer_norm = None\n",
      "    gelu_10 = torch._C._nn.gelu(layers_8_fc1);  layers_8_fc1 = None\n",
      "    dropout_35 = torch.nn.functional.dropout(gelu_10, p = 0.0, training = False, inplace = False);  gelu_10 = None\n",
      "    layers_8_fc2 = getattr(self.layers, \"8\").fc2(dropout_35);  dropout_35 = None\n",
      "    dropout_36 = torch.nn.functional.dropout(layers_8_fc2, p = 0.0, training = False, inplace = False);  layers_8_fc2 = None\n",
      "    add_18 = add_17 + dropout_36;  add_17 = dropout_36 = None\n",
      "    layers_9_self_attn_layer_norm = getattr(self.layers, \"9\").self_attn_layer_norm(add_18)\n",
      "    size_18 = layers_9_self_attn_layer_norm.size()\n",
      "    getitem_27 = size_18[0]\n",
      "    getitem_28 = size_18[1]\n",
      "    getitem_29 = size_18[2];  size_18 = None\n",
      "    layers_9_self_attn_q_proj = getattr(self.layers, \"9\").self_attn.q_proj(layers_9_self_attn_layer_norm)\n",
      "    mul_18 = layers_9_self_attn_q_proj * 0.125;  layers_9_self_attn_q_proj = None\n",
      "    layers_9_self_attn_k_proj = getattr(self.layers, \"9\").self_attn.k_proj(layers_9_self_attn_layer_norm)\n",
      "    view_45 = layers_9_self_attn_k_proj.view(getitem_27, -1, 12, 64);  layers_9_self_attn_k_proj = None\n",
      "    transpose_45 = view_45.transpose(1, 2);  view_45 = None\n",
      "    contiguous_27 = transpose_45.contiguous();  transpose_45 = None\n",
      "    layers_9_self_attn_v_proj = getattr(self.layers, \"9\").self_attn.v_proj(layers_9_self_attn_layer_norm);  layers_9_self_attn_layer_norm = None\n",
      "    view_46 = layers_9_self_attn_v_proj.view(getitem_27, -1, 12, 64);  layers_9_self_attn_v_proj = None\n",
      "    transpose_46 = view_46.transpose(1, 2);  view_46 = None\n",
      "    contiguous_28 = transpose_46.contiguous();  transpose_46 = None\n",
      "    mul_19 = getitem_27 * 12\n",
      "    view_47 = mul_18.view(getitem_27, getitem_28, 12, 64);  mul_18 = None\n",
      "    transpose_47 = view_47.transpose(1, 2);  view_47 = None\n",
      "    contiguous_29 = transpose_47.contiguous();  transpose_47 = None\n",
      "    view_48 = contiguous_29.view(mul_19, -1, 64);  contiguous_29 = None\n",
      "    reshape_27 = contiguous_27.reshape(mul_19, -1, 64);  contiguous_27 = None\n",
      "    reshape_28 = contiguous_28.reshape(mul_19, -1, 64);  contiguous_28 = mul_19 = None\n",
      "    size_19 = reshape_27.size(1)\n",
      "    transpose_48 = reshape_27.transpose(1, 2);  reshape_27 = None\n",
      "    bmm_18 = torch.bmm(view_48, transpose_48);  view_48 = transpose_48 = None\n",
      "    softmax_9 = torch.nn.functional.softmax(bmm_18, dim = -1, _stacklevel = 3, dtype = None);  bmm_18 = None\n",
      "    dropout_37 = torch.nn.functional.dropout(softmax_9, p = 0.0, training = False, inplace = False);  softmax_9 = None\n",
      "    bmm_19 = torch.bmm(dropout_37, reshape_28);  dropout_37 = reshape_28 = None\n",
      "    view_49 = bmm_19.view(getitem_27, 12, getitem_28, 64);  bmm_19 = None\n",
      "    transpose_49 = view_49.transpose(1, 2);  view_49 = None\n",
      "    reshape_29 = transpose_49.reshape(getitem_27, getitem_28, 768);  transpose_49 = getitem_27 = getitem_28 = None\n",
      "    layers_9_self_attn_out_proj = getattr(self.layers, \"9\").self_attn.out_proj(reshape_29);  reshape_29 = None\n",
      "    dropout_38 = torch.nn.functional.dropout(layers_9_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_9_self_attn_out_proj = None\n",
      "    add_19 = add_18 + dropout_38;  add_18 = dropout_38 = None\n",
      "    layers_9_final_layer_norm = getattr(self.layers, \"9\").final_layer_norm(add_19)\n",
      "    layers_9_fc1 = getattr(self.layers, \"9\").fc1(layers_9_final_layer_norm);  layers_9_final_layer_norm = None\n",
      "    gelu_11 = torch._C._nn.gelu(layers_9_fc1);  layers_9_fc1 = None\n",
      "    dropout_39 = torch.nn.functional.dropout(gelu_11, p = 0.0, training = False, inplace = False);  gelu_11 = None\n",
      "    layers_9_fc2 = getattr(self.layers, \"9\").fc2(dropout_39);  dropout_39 = None\n",
      "    dropout_40 = torch.nn.functional.dropout(layers_9_fc2, p = 0.0, training = False, inplace = False);  layers_9_fc2 = None\n",
      "    add_20 = add_19 + dropout_40;  add_19 = dropout_40 = None\n",
      "    layers_10_self_attn_layer_norm = getattr(self.layers, \"10\").self_attn_layer_norm(add_20)\n",
      "    size_20 = layers_10_self_attn_layer_norm.size()\n",
      "    getitem_30 = size_20[0]\n",
      "    getitem_31 = size_20[1]\n",
      "    getitem_32 = size_20[2];  size_20 = None\n",
      "    layers_10_self_attn_q_proj = getattr(self.layers, \"10\").self_attn.q_proj(layers_10_self_attn_layer_norm)\n",
      "    mul_20 = layers_10_self_attn_q_proj * 0.125;  layers_10_self_attn_q_proj = None\n",
      "    layers_10_self_attn_k_proj = getattr(self.layers, \"10\").self_attn.k_proj(layers_10_self_attn_layer_norm)\n",
      "    view_50 = layers_10_self_attn_k_proj.view(getitem_30, -1, 12, 64);  layers_10_self_attn_k_proj = None\n",
      "    transpose_50 = view_50.transpose(1, 2);  view_50 = None\n",
      "    contiguous_30 = transpose_50.contiguous();  transpose_50 = None\n",
      "    layers_10_self_attn_v_proj = getattr(self.layers, \"10\").self_attn.v_proj(layers_10_self_attn_layer_norm);  layers_10_self_attn_layer_norm = None\n",
      "    view_51 = layers_10_self_attn_v_proj.view(getitem_30, -1, 12, 64);  layers_10_self_attn_v_proj = None\n",
      "    transpose_51 = view_51.transpose(1, 2);  view_51 = None\n",
      "    contiguous_31 = transpose_51.contiguous();  transpose_51 = None\n",
      "    mul_21 = getitem_30 * 12\n",
      "    view_52 = mul_20.view(getitem_30, getitem_31, 12, 64);  mul_20 = None\n",
      "    transpose_52 = view_52.transpose(1, 2);  view_52 = None\n",
      "    contiguous_32 = transpose_52.contiguous();  transpose_52 = None\n",
      "    view_53 = contiguous_32.view(mul_21, -1, 64);  contiguous_32 = None\n",
      "    reshape_30 = contiguous_30.reshape(mul_21, -1, 64);  contiguous_30 = None\n",
      "    reshape_31 = contiguous_31.reshape(mul_21, -1, 64);  contiguous_31 = mul_21 = None\n",
      "    size_21 = reshape_30.size(1)\n",
      "    transpose_53 = reshape_30.transpose(1, 2);  reshape_30 = None\n",
      "    bmm_20 = torch.bmm(view_53, transpose_53);  view_53 = transpose_53 = None\n",
      "    softmax_10 = torch.nn.functional.softmax(bmm_20, dim = -1, _stacklevel = 3, dtype = None);  bmm_20 = None\n",
      "    dropout_41 = torch.nn.functional.dropout(softmax_10, p = 0.0, training = False, inplace = False);  softmax_10 = None\n",
      "    bmm_21 = torch.bmm(dropout_41, reshape_31);  dropout_41 = reshape_31 = None\n",
      "    view_54 = bmm_21.view(getitem_30, 12, getitem_31, 64);  bmm_21 = None\n",
      "    transpose_54 = view_54.transpose(1, 2);  view_54 = None\n",
      "    reshape_32 = transpose_54.reshape(getitem_30, getitem_31, 768);  transpose_54 = getitem_30 = getitem_31 = None\n",
      "    layers_10_self_attn_out_proj = getattr(self.layers, \"10\").self_attn.out_proj(reshape_32);  reshape_32 = None\n",
      "    dropout_42 = torch.nn.functional.dropout(layers_10_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_10_self_attn_out_proj = None\n",
      "    add_21 = add_20 + dropout_42;  add_20 = dropout_42 = None\n",
      "    layers_10_final_layer_norm = getattr(self.layers, \"10\").final_layer_norm(add_21)\n",
      "    layers_10_fc1 = getattr(self.layers, \"10\").fc1(layers_10_final_layer_norm);  layers_10_final_layer_norm = None\n",
      "    gelu_12 = torch._C._nn.gelu(layers_10_fc1);  layers_10_fc1 = None\n",
      "    dropout_43 = torch.nn.functional.dropout(gelu_12, p = 0.0, training = False, inplace = False);  gelu_12 = None\n",
      "    layers_10_fc2 = getattr(self.layers, \"10\").fc2(dropout_43);  dropout_43 = None\n",
      "    dropout_44 = torch.nn.functional.dropout(layers_10_fc2, p = 0.0, training = False, inplace = False);  layers_10_fc2 = None\n",
      "    add_22 = add_21 + dropout_44;  add_21 = dropout_44 = None\n",
      "    layers_11_self_attn_layer_norm = getattr(self.layers, \"11\").self_attn_layer_norm(add_22)\n",
      "    size_22 = layers_11_self_attn_layer_norm.size()\n",
      "    getitem_33 = size_22[0]\n",
      "    getitem_34 = size_22[1]\n",
      "    getitem_35 = size_22[2];  size_22 = None\n",
      "    layers_11_self_attn_q_proj = getattr(self.layers, \"11\").self_attn.q_proj(layers_11_self_attn_layer_norm)\n",
      "    mul_22 = layers_11_self_attn_q_proj * 0.125;  layers_11_self_attn_q_proj = None\n",
      "    layers_11_self_attn_k_proj = getattr(self.layers, \"11\").self_attn.k_proj(layers_11_self_attn_layer_norm)\n",
      "    view_55 = layers_11_self_attn_k_proj.view(getitem_33, -1, 12, 64);  layers_11_self_attn_k_proj = None\n",
      "    transpose_55 = view_55.transpose(1, 2);  view_55 = None\n",
      "    contiguous_33 = transpose_55.contiguous();  transpose_55 = None\n",
      "    layers_11_self_attn_v_proj = getattr(self.layers, \"11\").self_attn.v_proj(layers_11_self_attn_layer_norm);  layers_11_self_attn_layer_norm = None\n",
      "    view_56 = layers_11_self_attn_v_proj.view(getitem_33, -1, 12, 64);  layers_11_self_attn_v_proj = None\n",
      "    transpose_56 = view_56.transpose(1, 2);  view_56 = None\n",
      "    contiguous_34 = transpose_56.contiguous();  transpose_56 = None\n",
      "    mul_23 = getitem_33 * 12\n",
      "    view_57 = mul_22.view(getitem_33, getitem_34, 12, 64);  mul_22 = None\n",
      "    transpose_57 = view_57.transpose(1, 2);  view_57 = None\n",
      "    contiguous_35 = transpose_57.contiguous();  transpose_57 = None\n",
      "    view_58 = contiguous_35.view(mul_23, -1, 64);  contiguous_35 = None\n",
      "    reshape_33 = contiguous_33.reshape(mul_23, -1, 64);  contiguous_33 = None\n",
      "    reshape_34 = contiguous_34.reshape(mul_23, -1, 64);  contiguous_34 = mul_23 = None\n",
      "    size_23 = reshape_33.size(1)\n",
      "    transpose_58 = reshape_33.transpose(1, 2);  reshape_33 = None\n",
      "    bmm_22 = torch.bmm(view_58, transpose_58);  view_58 = transpose_58 = None\n",
      "    softmax_11 = torch.nn.functional.softmax(bmm_22, dim = -1, _stacklevel = 3, dtype = None);  bmm_22 = None\n",
      "    dropout_45 = torch.nn.functional.dropout(softmax_11, p = 0.0, training = False, inplace = False);  softmax_11 = None\n",
      "    bmm_23 = torch.bmm(dropout_45, reshape_34);  dropout_45 = reshape_34 = None\n",
      "    view_59 = bmm_23.view(getitem_33, 12, getitem_34, 64);  bmm_23 = None\n",
      "    transpose_59 = view_59.transpose(1, 2);  view_59 = None\n",
      "    reshape_35 = transpose_59.reshape(getitem_33, getitem_34, 768);  transpose_59 = getitem_33 = getitem_34 = None\n",
      "    layers_11_self_attn_out_proj = getattr(self.layers, \"11\").self_attn.out_proj(reshape_35);  reshape_35 = None\n",
      "    dropout_46 = torch.nn.functional.dropout(layers_11_self_attn_out_proj, p = 0.0, training = False, inplace = False);  layers_11_self_attn_out_proj = None\n",
      "    add_23 = add_22 + dropout_46;  add_22 = dropout_46 = None\n",
      "    layers_11_final_layer_norm = getattr(self.layers, \"11\").final_layer_norm(add_23)\n",
      "    layers_11_fc1 = getattr(self.layers, \"11\").fc1(layers_11_final_layer_norm);  layers_11_final_layer_norm = None\n",
      "    gelu_13 = torch._C._nn.gelu(layers_11_fc1);  layers_11_fc1 = None\n",
      "    dropout_47 = torch.nn.functional.dropout(gelu_13, p = 0.0, training = False, inplace = False);  gelu_13 = None\n",
      "    layers_11_fc2 = getattr(self.layers, \"11\").fc2(dropout_47);  dropout_47 = None\n",
      "    dropout_48 = torch.nn.functional.dropout(layers_11_fc2, p = 0.0, training = False, inplace = False);  layers_11_fc2 = None\n",
      "    add_24 = add_23 + dropout_48;  add_23 = dropout_48 = None\n",
      "    layer_norm = self.layer_norm(add_24);  add_24 = None\n",
      "    return {'last_hidden_state': layer_norm}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(symbolic_traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48955666",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_traced : torch.fx.GraphModule = symbolic_trace(model, concrete_args=decoder_concrete_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98bdb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.fx._symbolic_trace.wrap(\"transformers_models_whisper_modeling_whisper__prepare_decoder_attention_mask\")\n",
      "\n",
      "def forward(self, input_features : typing_Union[torch.FloatTensor,NoneType] = None, attention_mask : typing_Union[torch.LongTensor,NoneType] = None, decoder_input_ids : typing_Union[torch.LongTensor,NoneType] = None, decoder_attention_mask : typing_Union[torch.LongTensor,NoneType] = None, head_mask : typing_Union[torch.Tensor,NoneType] = None, decoder_head_mask : typing_Union[torch.Tensor,NoneType] = None, cross_attn_head_mask : typing_Union[torch.Tensor,NoneType] = None, encoder_outputs : typing_Union[typing_Tuple[typing_Tuple[torch.FloatTensor]],NoneType] = None, past_key_values : typing_Union[typing_Tuple[typing_Tuple[torch.FloatTensor]],NoneType] = None, decoder_inputs_embeds_1 = None, labels : typing_Union[torch.LongTensor,NoneType] = None, use_cache_1 = None, output_attentions_1 = None, output_hidden_states_1 = None, return_dict_1 = None) -> typing_Union[typing_Tuple[torch.Tensor],transformers_modeling_outputs_Seq2SeqLMOutput]:\n",
      "    _assert_is_none = torch.fx._symbolic_trace._assert_is_none(decoder_inputs_embeds_1, 'decoder_inputs_embeds has been specialized to have value None but got another value');  decoder_inputs_embeds_1 = None\n",
      "    eq = use_cache_1 == True;  use_cache_1 = None\n",
      "    _assert = torch._assert(eq, 'use_cache has been specialized to have value True but got another value');  eq = None\n",
      "    eq_1 = output_attentions_1 == False;  output_attentions_1 = None\n",
      "    _assert_1 = torch._assert(eq_1, 'output_attentions has been specialized to have value False but got another value');  eq_1 = None\n",
      "    eq_2 = output_hidden_states_1 == False;  output_hidden_states_1 = None\n",
      "    _assert_2 = torch._assert(eq_2, 'output_hidden_states has been specialized to have value False but got another value');  eq_2 = None\n",
      "    eq_3 = return_dict_1 == True;  return_dict_1 = None\n",
      "    _assert_3 = torch._assert(eq_3, 'return_dict has been specialized to have value True but got another value');  eq_3 = None\n",
      "    getitem = encoder_outputs[0]\n",
      "    size = decoder_input_ids.size()\n",
      "    getitem_1 = size[-1]\n",
      "    view = decoder_input_ids.view(-1, getitem_1);  decoder_input_ids = getitem_1 = None\n",
      "    getitem_2 = past_key_values[0]\n",
      "    getitem_3 = getitem_2[0];  getitem_2 = None\n",
      "    getattr_1 = getitem_3.shape;  getitem_3 = None\n",
      "    getitem_4 = getattr_1[2];  getattr_1 = None\n",
      "    model_decoder_embed_tokens = self.model.decoder.embed_tokens(view)\n",
      "    _prepare_decoder_attention_mask = transformers_models_whisper_modeling_whisper__prepare_decoder_attention_mask(decoder_attention_mask, size, model_decoder_embed_tokens, getitem_4);  decoder_attention_mask = size = None\n",
      "    model_decoder_embed_positions_weight = self.model.decoder.embed_positions.weight\n",
      "    getattr_2 = view.shape;  view = None\n",
      "    getitem_5 = getattr_2[1];  getattr_2 = None\n",
      "    add = getitem_4 + getitem_5;  getitem_5 = None\n",
      "    getitem_6 = model_decoder_embed_positions_weight[slice(getitem_4, add, None)];  model_decoder_embed_positions_weight = getitem_4 = add = None\n",
      "    add_1 = model_decoder_embed_tokens + getitem_6;  model_decoder_embed_tokens = getitem_6 = None\n",
      "    dropout = torch.nn.functional.dropout(add_1, p = 0.0, training = False, inplace = False);  add_1 = None\n",
      "    getitem_7 = past_key_values[0]\n",
      "    getitem_8 = decoder_head_mask[0]\n",
      "    getitem_9 = cross_attn_head_mask[0]\n",
      "    model_decoder_layers_0_self_attn_layer_norm = getattr(self.model.decoder.layers, \"0\").self_attn_layer_norm(dropout)\n",
      "    getitem_10 = getitem_7[slice(None, 2, None)]\n",
      "    size_1 = model_decoder_layers_0_self_attn_layer_norm.size()\n",
      "    getitem_11 = size_1[0]\n",
      "    getitem_12 = size_1[1]\n",
      "    getitem_13 = size_1[2];  size_1 = None\n",
      "    model_decoder_layers_0_self_attn_q_proj = getattr(self.model.decoder.layers, \"0\").self_attn.q_proj(model_decoder_layers_0_self_attn_layer_norm)\n",
      "    mul = model_decoder_layers_0_self_attn_q_proj * 0.125;  model_decoder_layers_0_self_attn_q_proj = None\n",
      "    model_decoder_layers_0_self_attn_k_proj = getattr(self.model.decoder.layers, \"0\").self_attn.k_proj(model_decoder_layers_0_self_attn_layer_norm)\n",
      "    view_1 = model_decoder_layers_0_self_attn_k_proj.view(getitem_11, -1, 12, 64);  model_decoder_layers_0_self_attn_k_proj = None\n",
      "    transpose = view_1.transpose(1, 2);  view_1 = None\n",
      "    contiguous = transpose.contiguous();  transpose = None\n",
      "    model_decoder_layers_0_self_attn_v_proj = getattr(self.model.decoder.layers, \"0\").self_attn.v_proj(model_decoder_layers_0_self_attn_layer_norm);  model_decoder_layers_0_self_attn_layer_norm = None\n",
      "    view_2 = model_decoder_layers_0_self_attn_v_proj.view(getitem_11, -1, 12, 64);  model_decoder_layers_0_self_attn_v_proj = None\n",
      "    transpose_1 = view_2.transpose(1, 2);  view_2 = None\n",
      "    contiguous_1 = transpose_1.contiguous();  transpose_1 = None\n",
      "    getitem_14 = getitem_10[0]\n",
      "    cat = torch.cat([getitem_14, contiguous], dim = 2);  getitem_14 = contiguous = None\n",
      "    getitem_15 = getitem_10[1];  getitem_10 = None\n",
      "    cat_1 = torch.cat([getitem_15, contiguous_1], dim = 2);  getitem_15 = contiguous_1 = None\n",
      "    mul_1 = getitem_11 * 12\n",
      "    view_3 = mul.view(getitem_11, getitem_12, 12, 64);  mul = None\n",
      "    transpose_2 = view_3.transpose(1, 2);  view_3 = None\n",
      "    contiguous_2 = transpose_2.contiguous();  transpose_2 = None\n",
      "    view_4 = contiguous_2.view(mul_1, -1, 64);  contiguous_2 = None\n",
      "    reshape = cat.reshape(mul_1, -1, 64)\n",
      "    reshape_1 = cat_1.reshape(mul_1, -1, 64);  mul_1 = None\n",
      "    size_2 = reshape.size(1)\n",
      "    transpose_3 = reshape.transpose(1, 2);  reshape = None\n",
      "    bmm = torch.bmm(view_4, transpose_3);  view_4 = transpose_3 = None\n",
      "    view_5 = bmm.view(getitem_11, 12, getitem_12, size_2);  bmm = None\n",
      "    add_2 = view_5 + _prepare_decoder_attention_mask;  view_5 = None\n",
      "    mul_2 = getitem_11 * 12\n",
      "    view_6 = add_2.view(mul_2, getitem_12, size_2);  add_2 = mul_2 = None\n",
      "    softmax = torch.nn.functional.softmax(view_6, dim = -1, _stacklevel = 3, dtype = None);  view_6 = None\n",
      "    view_7 = getitem_8.view(1, -1, 1, 1);  getitem_8 = None\n",
      "    view_8 = softmax.view(getitem_11, 12, getitem_12, size_2);  softmax = None\n",
      "    mul_3 = view_7 * view_8;  view_7 = view_8 = None\n",
      "    mul_4 = getitem_11 * 12\n",
      "    view_9 = mul_3.view(mul_4, getitem_12, size_2);  mul_3 = mul_4 = size_2 = None\n",
      "    dropout_1 = torch.nn.functional.dropout(view_9, p = 0.0, training = False, inplace = False);  view_9 = None\n",
      "    bmm_1 = torch.bmm(dropout_1, reshape_1);  dropout_1 = reshape_1 = None\n",
      "    view_10 = bmm_1.view(getitem_11, 12, getitem_12, 64);  bmm_1 = None\n",
      "    transpose_4 = view_10.transpose(1, 2);  view_10 = None\n",
      "    reshape_2 = transpose_4.reshape(getitem_11, getitem_12, 768);  transpose_4 = getitem_11 = getitem_12 = None\n",
      "    model_decoder_layers_0_self_attn_out_proj = getattr(self.model.decoder.layers, \"0\").self_attn.out_proj(reshape_2);  reshape_2 = None\n",
      "    dropout_2 = torch.nn.functional.dropout(model_decoder_layers_0_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_0_self_attn_out_proj = None\n",
      "    add_3 = dropout + dropout_2;  dropout = dropout_2 = None\n",
      "    model_decoder_layers_0_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"0\").encoder_attn_layer_norm(add_3)\n",
      "    getitem_16 = getitem_7[slice(-2, None, None)];  getitem_7 = None\n",
      "    size_3 = model_decoder_layers_0_encoder_attn_layer_norm.size()\n",
      "    getitem_17 = size_3[0]\n",
      "    getitem_18 = size_3[1]\n",
      "    getitem_19 = size_3[2];  size_3 = None\n",
      "    model_decoder_layers_0_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"0\").encoder_attn.q_proj(model_decoder_layers_0_encoder_attn_layer_norm);  model_decoder_layers_0_encoder_attn_layer_norm = None\n",
      "    mul_5 = model_decoder_layers_0_encoder_attn_q_proj * 0.125;  model_decoder_layers_0_encoder_attn_q_proj = None\n",
      "    getitem_20 = getitem_16[0]\n",
      "    getitem_21 = getitem_16[1];  getitem_16 = None\n",
      "    mul_6 = getitem_17 * 12\n",
      "    view_11 = mul_5.view(getitem_17, getitem_18, 12, 64);  mul_5 = None\n",
      "    transpose_5 = view_11.transpose(1, 2);  view_11 = None\n",
      "    contiguous_3 = transpose_5.contiguous();  transpose_5 = None\n",
      "    view_12 = contiguous_3.view(mul_6, -1, 64);  contiguous_3 = None\n",
      "    reshape_3 = getitem_20.reshape(mul_6, -1, 64)\n",
      "    reshape_4 = getitem_21.reshape(mul_6, -1, 64);  mul_6 = None\n",
      "    size_4 = reshape_3.size(1)\n",
      "    transpose_6 = reshape_3.transpose(1, 2);  reshape_3 = None\n",
      "    bmm_2 = torch.bmm(view_12, transpose_6);  view_12 = transpose_6 = None\n",
      "    softmax_1 = torch.nn.functional.softmax(bmm_2, dim = -1, _stacklevel = 3, dtype = None);  bmm_2 = None\n",
      "    view_13 = getitem_9.view(1, -1, 1, 1);  getitem_9 = None\n",
      "    view_14 = softmax_1.view(getitem_17, 12, getitem_18, size_4);  softmax_1 = None\n",
      "    mul_7 = view_13 * view_14;  view_13 = view_14 = None\n",
      "    mul_8 = getitem_17 * 12\n",
      "    view_15 = mul_7.view(mul_8, getitem_18, size_4);  mul_7 = mul_8 = size_4 = None\n",
      "    dropout_3 = torch.nn.functional.dropout(view_15, p = 0.0, training = False, inplace = False);  view_15 = None\n",
      "    bmm_3 = torch.bmm(dropout_3, reshape_4);  dropout_3 = reshape_4 = None\n",
      "    view_16 = bmm_3.view(getitem_17, 12, getitem_18, 64);  bmm_3 = None\n",
      "    transpose_7 = view_16.transpose(1, 2);  view_16 = None\n",
      "    reshape_5 = transpose_7.reshape(getitem_17, getitem_18, 768);  transpose_7 = getitem_17 = getitem_18 = None\n",
      "    model_decoder_layers_0_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"0\").encoder_attn.out_proj(reshape_5);  reshape_5 = None\n",
      "    dropout_4 = torch.nn.functional.dropout(model_decoder_layers_0_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_0_encoder_attn_out_proj = None\n",
      "    add_4 = add_3 + dropout_4;  add_3 = dropout_4 = None\n",
      "    model_decoder_layers_0_final_layer_norm = getattr(self.model.decoder.layers, \"0\").final_layer_norm(add_4)\n",
      "    model_decoder_layers_0_fc1 = getattr(self.model.decoder.layers, \"0\").fc1(model_decoder_layers_0_final_layer_norm);  model_decoder_layers_0_final_layer_norm = None\n",
      "    gelu = torch._C._nn.gelu(model_decoder_layers_0_fc1);  model_decoder_layers_0_fc1 = None\n",
      "    dropout_5 = torch.nn.functional.dropout(gelu, p = 0.0, training = False, inplace = False);  gelu = None\n",
      "    model_decoder_layers_0_fc2 = getattr(self.model.decoder.layers, \"0\").fc2(dropout_5);  dropout_5 = None\n",
      "    dropout_6 = torch.nn.functional.dropout(model_decoder_layers_0_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_0_fc2 = None\n",
      "    add_5 = add_4 + dropout_6;  add_4 = dropout_6 = None\n",
      "    getitem_22 = past_key_values[1]\n",
      "    getitem_23 = decoder_head_mask[1]\n",
      "    getitem_24 = cross_attn_head_mask[1]\n",
      "    model_decoder_layers_1_self_attn_layer_norm = getattr(self.model.decoder.layers, \"1\").self_attn_layer_norm(add_5)\n",
      "    getitem_25 = getitem_22[slice(None, 2, None)]\n",
      "    size_5 = model_decoder_layers_1_self_attn_layer_norm.size()\n",
      "    getitem_26 = size_5[0]\n",
      "    getitem_27 = size_5[1]\n",
      "    getitem_28 = size_5[2];  size_5 = None\n",
      "    model_decoder_layers_1_self_attn_q_proj = getattr(self.model.decoder.layers, \"1\").self_attn.q_proj(model_decoder_layers_1_self_attn_layer_norm)\n",
      "    mul_9 = model_decoder_layers_1_self_attn_q_proj * 0.125;  model_decoder_layers_1_self_attn_q_proj = None\n",
      "    model_decoder_layers_1_self_attn_k_proj = getattr(self.model.decoder.layers, \"1\").self_attn.k_proj(model_decoder_layers_1_self_attn_layer_norm)\n",
      "    view_17 = model_decoder_layers_1_self_attn_k_proj.view(getitem_26, -1, 12, 64);  model_decoder_layers_1_self_attn_k_proj = None\n",
      "    transpose_8 = view_17.transpose(1, 2);  view_17 = None\n",
      "    contiguous_4 = transpose_8.contiguous();  transpose_8 = None\n",
      "    model_decoder_layers_1_self_attn_v_proj = getattr(self.model.decoder.layers, \"1\").self_attn.v_proj(model_decoder_layers_1_self_attn_layer_norm);  model_decoder_layers_1_self_attn_layer_norm = None\n",
      "    view_18 = model_decoder_layers_1_self_attn_v_proj.view(getitem_26, -1, 12, 64);  model_decoder_layers_1_self_attn_v_proj = None\n",
      "    transpose_9 = view_18.transpose(1, 2);  view_18 = None\n",
      "    contiguous_5 = transpose_9.contiguous();  transpose_9 = None\n",
      "    getitem_29 = getitem_25[0]\n",
      "    cat_2 = torch.cat([getitem_29, contiguous_4], dim = 2);  getitem_29 = contiguous_4 = None\n",
      "    getitem_30 = getitem_25[1];  getitem_25 = None\n",
      "    cat_3 = torch.cat([getitem_30, contiguous_5], dim = 2);  getitem_30 = contiguous_5 = None\n",
      "    mul_10 = getitem_26 * 12\n",
      "    view_19 = mul_9.view(getitem_26, getitem_27, 12, 64);  mul_9 = None\n",
      "    transpose_10 = view_19.transpose(1, 2);  view_19 = None\n",
      "    contiguous_6 = transpose_10.contiguous();  transpose_10 = None\n",
      "    view_20 = contiguous_6.view(mul_10, -1, 64);  contiguous_6 = None\n",
      "    reshape_6 = cat_2.reshape(mul_10, -1, 64)\n",
      "    reshape_7 = cat_3.reshape(mul_10, -1, 64);  mul_10 = None\n",
      "    size_6 = reshape_6.size(1)\n",
      "    transpose_11 = reshape_6.transpose(1, 2);  reshape_6 = None\n",
      "    bmm_4 = torch.bmm(view_20, transpose_11);  view_20 = transpose_11 = None\n",
      "    view_21 = bmm_4.view(getitem_26, 12, getitem_27, size_6);  bmm_4 = None\n",
      "    add_6 = view_21 + _prepare_decoder_attention_mask;  view_21 = None\n",
      "    mul_11 = getitem_26 * 12\n",
      "    view_22 = add_6.view(mul_11, getitem_27, size_6);  add_6 = mul_11 = None\n",
      "    softmax_2 = torch.nn.functional.softmax(view_22, dim = -1, _stacklevel = 3, dtype = None);  view_22 = None\n",
      "    view_23 = getitem_23.view(1, -1, 1, 1);  getitem_23 = None\n",
      "    view_24 = softmax_2.view(getitem_26, 12, getitem_27, size_6);  softmax_2 = None\n",
      "    mul_12 = view_23 * view_24;  view_23 = view_24 = None\n",
      "    mul_13 = getitem_26 * 12\n",
      "    view_25 = mul_12.view(mul_13, getitem_27, size_6);  mul_12 = mul_13 = size_6 = None\n",
      "    dropout_7 = torch.nn.functional.dropout(view_25, p = 0.0, training = False, inplace = False);  view_25 = None\n",
      "    bmm_5 = torch.bmm(dropout_7, reshape_7);  dropout_7 = reshape_7 = None\n",
      "    view_26 = bmm_5.view(getitem_26, 12, getitem_27, 64);  bmm_5 = None\n",
      "    transpose_12 = view_26.transpose(1, 2);  view_26 = None\n",
      "    reshape_8 = transpose_12.reshape(getitem_26, getitem_27, 768);  transpose_12 = getitem_26 = getitem_27 = None\n",
      "    model_decoder_layers_1_self_attn_out_proj = getattr(self.model.decoder.layers, \"1\").self_attn.out_proj(reshape_8);  reshape_8 = None\n",
      "    dropout_8 = torch.nn.functional.dropout(model_decoder_layers_1_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_1_self_attn_out_proj = None\n",
      "    add_7 = add_5 + dropout_8;  add_5 = dropout_8 = None\n",
      "    model_decoder_layers_1_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"1\").encoder_attn_layer_norm(add_7)\n",
      "    getitem_31 = getitem_22[slice(-2, None, None)];  getitem_22 = None\n",
      "    size_7 = model_decoder_layers_1_encoder_attn_layer_norm.size()\n",
      "    getitem_32 = size_7[0]\n",
      "    getitem_33 = size_7[1]\n",
      "    getitem_34 = size_7[2];  size_7 = None\n",
      "    model_decoder_layers_1_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"1\").encoder_attn.q_proj(model_decoder_layers_1_encoder_attn_layer_norm);  model_decoder_layers_1_encoder_attn_layer_norm = None\n",
      "    mul_14 = model_decoder_layers_1_encoder_attn_q_proj * 0.125;  model_decoder_layers_1_encoder_attn_q_proj = None\n",
      "    getitem_35 = getitem_31[0]\n",
      "    getitem_36 = getitem_31[1];  getitem_31 = None\n",
      "    mul_15 = getitem_32 * 12\n",
      "    view_27 = mul_14.view(getitem_32, getitem_33, 12, 64);  mul_14 = None\n",
      "    transpose_13 = view_27.transpose(1, 2);  view_27 = None\n",
      "    contiguous_7 = transpose_13.contiguous();  transpose_13 = None\n",
      "    view_28 = contiguous_7.view(mul_15, -1, 64);  contiguous_7 = None\n",
      "    reshape_9 = getitem_35.reshape(mul_15, -1, 64)\n",
      "    reshape_10 = getitem_36.reshape(mul_15, -1, 64);  mul_15 = None\n",
      "    size_8 = reshape_9.size(1)\n",
      "    transpose_14 = reshape_9.transpose(1, 2);  reshape_9 = None\n",
      "    bmm_6 = torch.bmm(view_28, transpose_14);  view_28 = transpose_14 = None\n",
      "    softmax_3 = torch.nn.functional.softmax(bmm_6, dim = -1, _stacklevel = 3, dtype = None);  bmm_6 = None\n",
      "    view_29 = getitem_24.view(1, -1, 1, 1);  getitem_24 = None\n",
      "    view_30 = softmax_3.view(getitem_32, 12, getitem_33, size_8);  softmax_3 = None\n",
      "    mul_16 = view_29 * view_30;  view_29 = view_30 = None\n",
      "    mul_17 = getitem_32 * 12\n",
      "    view_31 = mul_16.view(mul_17, getitem_33, size_8);  mul_16 = mul_17 = size_8 = None\n",
      "    dropout_9 = torch.nn.functional.dropout(view_31, p = 0.0, training = False, inplace = False);  view_31 = None\n",
      "    bmm_7 = torch.bmm(dropout_9, reshape_10);  dropout_9 = reshape_10 = None\n",
      "    view_32 = bmm_7.view(getitem_32, 12, getitem_33, 64);  bmm_7 = None\n",
      "    transpose_15 = view_32.transpose(1, 2);  view_32 = None\n",
      "    reshape_11 = transpose_15.reshape(getitem_32, getitem_33, 768);  transpose_15 = getitem_32 = getitem_33 = None\n",
      "    model_decoder_layers_1_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"1\").encoder_attn.out_proj(reshape_11);  reshape_11 = None\n",
      "    dropout_10 = torch.nn.functional.dropout(model_decoder_layers_1_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_1_encoder_attn_out_proj = None\n",
      "    add_8 = add_7 + dropout_10;  add_7 = dropout_10 = None\n",
      "    model_decoder_layers_1_final_layer_norm = getattr(self.model.decoder.layers, \"1\").final_layer_norm(add_8)\n",
      "    model_decoder_layers_1_fc1 = getattr(self.model.decoder.layers, \"1\").fc1(model_decoder_layers_1_final_layer_norm);  model_decoder_layers_1_final_layer_norm = None\n",
      "    gelu_1 = torch._C._nn.gelu(model_decoder_layers_1_fc1);  model_decoder_layers_1_fc1 = None\n",
      "    dropout_11 = torch.nn.functional.dropout(gelu_1, p = 0.0, training = False, inplace = False);  gelu_1 = None\n",
      "    model_decoder_layers_1_fc2 = getattr(self.model.decoder.layers, \"1\").fc2(dropout_11);  dropout_11 = None\n",
      "    dropout_12 = torch.nn.functional.dropout(model_decoder_layers_1_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_1_fc2 = None\n",
      "    add_9 = add_8 + dropout_12;  add_8 = dropout_12 = None\n",
      "    getitem_37 = past_key_values[2]\n",
      "    getitem_38 = decoder_head_mask[2]\n",
      "    getitem_39 = cross_attn_head_mask[2]\n",
      "    model_decoder_layers_2_self_attn_layer_norm = getattr(self.model.decoder.layers, \"2\").self_attn_layer_norm(add_9)\n",
      "    getitem_40 = getitem_37[slice(None, 2, None)]\n",
      "    size_9 = model_decoder_layers_2_self_attn_layer_norm.size()\n",
      "    getitem_41 = size_9[0]\n",
      "    getitem_42 = size_9[1]\n",
      "    getitem_43 = size_9[2];  size_9 = None\n",
      "    model_decoder_layers_2_self_attn_q_proj = getattr(self.model.decoder.layers, \"2\").self_attn.q_proj(model_decoder_layers_2_self_attn_layer_norm)\n",
      "    mul_18 = model_decoder_layers_2_self_attn_q_proj * 0.125;  model_decoder_layers_2_self_attn_q_proj = None\n",
      "    model_decoder_layers_2_self_attn_k_proj = getattr(self.model.decoder.layers, \"2\").self_attn.k_proj(model_decoder_layers_2_self_attn_layer_norm)\n",
      "    view_33 = model_decoder_layers_2_self_attn_k_proj.view(getitem_41, -1, 12, 64);  model_decoder_layers_2_self_attn_k_proj = None\n",
      "    transpose_16 = view_33.transpose(1, 2);  view_33 = None\n",
      "    contiguous_8 = transpose_16.contiguous();  transpose_16 = None\n",
      "    model_decoder_layers_2_self_attn_v_proj = getattr(self.model.decoder.layers, \"2\").self_attn.v_proj(model_decoder_layers_2_self_attn_layer_norm);  model_decoder_layers_2_self_attn_layer_norm = None\n",
      "    view_34 = model_decoder_layers_2_self_attn_v_proj.view(getitem_41, -1, 12, 64);  model_decoder_layers_2_self_attn_v_proj = None\n",
      "    transpose_17 = view_34.transpose(1, 2);  view_34 = None\n",
      "    contiguous_9 = transpose_17.contiguous();  transpose_17 = None\n",
      "    getitem_44 = getitem_40[0]\n",
      "    cat_4 = torch.cat([getitem_44, contiguous_8], dim = 2);  getitem_44 = contiguous_8 = None\n",
      "    getitem_45 = getitem_40[1];  getitem_40 = None\n",
      "    cat_5 = torch.cat([getitem_45, contiguous_9], dim = 2);  getitem_45 = contiguous_9 = None\n",
      "    mul_19 = getitem_41 * 12\n",
      "    view_35 = mul_18.view(getitem_41, getitem_42, 12, 64);  mul_18 = None\n",
      "    transpose_18 = view_35.transpose(1, 2);  view_35 = None\n",
      "    contiguous_10 = transpose_18.contiguous();  transpose_18 = None\n",
      "    view_36 = contiguous_10.view(mul_19, -1, 64);  contiguous_10 = None\n",
      "    reshape_12 = cat_4.reshape(mul_19, -1, 64)\n",
      "    reshape_13 = cat_5.reshape(mul_19, -1, 64);  mul_19 = None\n",
      "    size_10 = reshape_12.size(1)\n",
      "    transpose_19 = reshape_12.transpose(1, 2);  reshape_12 = None\n",
      "    bmm_8 = torch.bmm(view_36, transpose_19);  view_36 = transpose_19 = None\n",
      "    view_37 = bmm_8.view(getitem_41, 12, getitem_42, size_10);  bmm_8 = None\n",
      "    add_10 = view_37 + _prepare_decoder_attention_mask;  view_37 = None\n",
      "    mul_20 = getitem_41 * 12\n",
      "    view_38 = add_10.view(mul_20, getitem_42, size_10);  add_10 = mul_20 = None\n",
      "    softmax_4 = torch.nn.functional.softmax(view_38, dim = -1, _stacklevel = 3, dtype = None);  view_38 = None\n",
      "    view_39 = getitem_38.view(1, -1, 1, 1);  getitem_38 = None\n",
      "    view_40 = softmax_4.view(getitem_41, 12, getitem_42, size_10);  softmax_4 = None\n",
      "    mul_21 = view_39 * view_40;  view_39 = view_40 = None\n",
      "    mul_22 = getitem_41 * 12\n",
      "    view_41 = mul_21.view(mul_22, getitem_42, size_10);  mul_21 = mul_22 = size_10 = None\n",
      "    dropout_13 = torch.nn.functional.dropout(view_41, p = 0.0, training = False, inplace = False);  view_41 = None\n",
      "    bmm_9 = torch.bmm(dropout_13, reshape_13);  dropout_13 = reshape_13 = None\n",
      "    view_42 = bmm_9.view(getitem_41, 12, getitem_42, 64);  bmm_9 = None\n",
      "    transpose_20 = view_42.transpose(1, 2);  view_42 = None\n",
      "    reshape_14 = transpose_20.reshape(getitem_41, getitem_42, 768);  transpose_20 = getitem_41 = getitem_42 = None\n",
      "    model_decoder_layers_2_self_attn_out_proj = getattr(self.model.decoder.layers, \"2\").self_attn.out_proj(reshape_14);  reshape_14 = None\n",
      "    dropout_14 = torch.nn.functional.dropout(model_decoder_layers_2_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_2_self_attn_out_proj = None\n",
      "    add_11 = add_9 + dropout_14;  add_9 = dropout_14 = None\n",
      "    model_decoder_layers_2_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"2\").encoder_attn_layer_norm(add_11)\n",
      "    getitem_46 = getitem_37[slice(-2, None, None)];  getitem_37 = None\n",
      "    size_11 = model_decoder_layers_2_encoder_attn_layer_norm.size()\n",
      "    getitem_47 = size_11[0]\n",
      "    getitem_48 = size_11[1]\n",
      "    getitem_49 = size_11[2];  size_11 = None\n",
      "    model_decoder_layers_2_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"2\").encoder_attn.q_proj(model_decoder_layers_2_encoder_attn_layer_norm);  model_decoder_layers_2_encoder_attn_layer_norm = None\n",
      "    mul_23 = model_decoder_layers_2_encoder_attn_q_proj * 0.125;  model_decoder_layers_2_encoder_attn_q_proj = None\n",
      "    getitem_50 = getitem_46[0]\n",
      "    getitem_51 = getitem_46[1];  getitem_46 = None\n",
      "    mul_24 = getitem_47 * 12\n",
      "    view_43 = mul_23.view(getitem_47, getitem_48, 12, 64);  mul_23 = None\n",
      "    transpose_21 = view_43.transpose(1, 2);  view_43 = None\n",
      "    contiguous_11 = transpose_21.contiguous();  transpose_21 = None\n",
      "    view_44 = contiguous_11.view(mul_24, -1, 64);  contiguous_11 = None\n",
      "    reshape_15 = getitem_50.reshape(mul_24, -1, 64)\n",
      "    reshape_16 = getitem_51.reshape(mul_24, -1, 64);  mul_24 = None\n",
      "    size_12 = reshape_15.size(1)\n",
      "    transpose_22 = reshape_15.transpose(1, 2);  reshape_15 = None\n",
      "    bmm_10 = torch.bmm(view_44, transpose_22);  view_44 = transpose_22 = None\n",
      "    softmax_5 = torch.nn.functional.softmax(bmm_10, dim = -1, _stacklevel = 3, dtype = None);  bmm_10 = None\n",
      "    view_45 = getitem_39.view(1, -1, 1, 1);  getitem_39 = None\n",
      "    view_46 = softmax_5.view(getitem_47, 12, getitem_48, size_12);  softmax_5 = None\n",
      "    mul_25 = view_45 * view_46;  view_45 = view_46 = None\n",
      "    mul_26 = getitem_47 * 12\n",
      "    view_47 = mul_25.view(mul_26, getitem_48, size_12);  mul_25 = mul_26 = size_12 = None\n",
      "    dropout_15 = torch.nn.functional.dropout(view_47, p = 0.0, training = False, inplace = False);  view_47 = None\n",
      "    bmm_11 = torch.bmm(dropout_15, reshape_16);  dropout_15 = reshape_16 = None\n",
      "    view_48 = bmm_11.view(getitem_47, 12, getitem_48, 64);  bmm_11 = None\n",
      "    transpose_23 = view_48.transpose(1, 2);  view_48 = None\n",
      "    reshape_17 = transpose_23.reshape(getitem_47, getitem_48, 768);  transpose_23 = getitem_47 = getitem_48 = None\n",
      "    model_decoder_layers_2_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"2\").encoder_attn.out_proj(reshape_17);  reshape_17 = None\n",
      "    dropout_16 = torch.nn.functional.dropout(model_decoder_layers_2_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_2_encoder_attn_out_proj = None\n",
      "    add_12 = add_11 + dropout_16;  add_11 = dropout_16 = None\n",
      "    model_decoder_layers_2_final_layer_norm = getattr(self.model.decoder.layers, \"2\").final_layer_norm(add_12)\n",
      "    model_decoder_layers_2_fc1 = getattr(self.model.decoder.layers, \"2\").fc1(model_decoder_layers_2_final_layer_norm);  model_decoder_layers_2_final_layer_norm = None\n",
      "    gelu_2 = torch._C._nn.gelu(model_decoder_layers_2_fc1);  model_decoder_layers_2_fc1 = None\n",
      "    dropout_17 = torch.nn.functional.dropout(gelu_2, p = 0.0, training = False, inplace = False);  gelu_2 = None\n",
      "    model_decoder_layers_2_fc2 = getattr(self.model.decoder.layers, \"2\").fc2(dropout_17);  dropout_17 = None\n",
      "    dropout_18 = torch.nn.functional.dropout(model_decoder_layers_2_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_2_fc2 = None\n",
      "    add_13 = add_12 + dropout_18;  add_12 = dropout_18 = None\n",
      "    getitem_52 = past_key_values[3]\n",
      "    getitem_53 = decoder_head_mask[3]\n",
      "    getitem_54 = cross_attn_head_mask[3]\n",
      "    model_decoder_layers_3_self_attn_layer_norm = getattr(self.model.decoder.layers, \"3\").self_attn_layer_norm(add_13)\n",
      "    getitem_55 = getitem_52[slice(None, 2, None)]\n",
      "    size_13 = model_decoder_layers_3_self_attn_layer_norm.size()\n",
      "    getitem_56 = size_13[0]\n",
      "    getitem_57 = size_13[1]\n",
      "    getitem_58 = size_13[2];  size_13 = None\n",
      "    model_decoder_layers_3_self_attn_q_proj = getattr(self.model.decoder.layers, \"3\").self_attn.q_proj(model_decoder_layers_3_self_attn_layer_norm)\n",
      "    mul_27 = model_decoder_layers_3_self_attn_q_proj * 0.125;  model_decoder_layers_3_self_attn_q_proj = None\n",
      "    model_decoder_layers_3_self_attn_k_proj = getattr(self.model.decoder.layers, \"3\").self_attn.k_proj(model_decoder_layers_3_self_attn_layer_norm)\n",
      "    view_49 = model_decoder_layers_3_self_attn_k_proj.view(getitem_56, -1, 12, 64);  model_decoder_layers_3_self_attn_k_proj = None\n",
      "    transpose_24 = view_49.transpose(1, 2);  view_49 = None\n",
      "    contiguous_12 = transpose_24.contiguous();  transpose_24 = None\n",
      "    model_decoder_layers_3_self_attn_v_proj = getattr(self.model.decoder.layers, \"3\").self_attn.v_proj(model_decoder_layers_3_self_attn_layer_norm);  model_decoder_layers_3_self_attn_layer_norm = None\n",
      "    view_50 = model_decoder_layers_3_self_attn_v_proj.view(getitem_56, -1, 12, 64);  model_decoder_layers_3_self_attn_v_proj = None\n",
      "    transpose_25 = view_50.transpose(1, 2);  view_50 = None\n",
      "    contiguous_13 = transpose_25.contiguous();  transpose_25 = None\n",
      "    getitem_59 = getitem_55[0]\n",
      "    cat_6 = torch.cat([getitem_59, contiguous_12], dim = 2);  getitem_59 = contiguous_12 = None\n",
      "    getitem_60 = getitem_55[1];  getitem_55 = None\n",
      "    cat_7 = torch.cat([getitem_60, contiguous_13], dim = 2);  getitem_60 = contiguous_13 = None\n",
      "    mul_28 = getitem_56 * 12\n",
      "    view_51 = mul_27.view(getitem_56, getitem_57, 12, 64);  mul_27 = None\n",
      "    transpose_26 = view_51.transpose(1, 2);  view_51 = None\n",
      "    contiguous_14 = transpose_26.contiguous();  transpose_26 = None\n",
      "    view_52 = contiguous_14.view(mul_28, -1, 64);  contiguous_14 = None\n",
      "    reshape_18 = cat_6.reshape(mul_28, -1, 64)\n",
      "    reshape_19 = cat_7.reshape(mul_28, -1, 64);  mul_28 = None\n",
      "    size_14 = reshape_18.size(1)\n",
      "    transpose_27 = reshape_18.transpose(1, 2);  reshape_18 = None\n",
      "    bmm_12 = torch.bmm(view_52, transpose_27);  view_52 = transpose_27 = None\n",
      "    view_53 = bmm_12.view(getitem_56, 12, getitem_57, size_14);  bmm_12 = None\n",
      "    add_14 = view_53 + _prepare_decoder_attention_mask;  view_53 = None\n",
      "    mul_29 = getitem_56 * 12\n",
      "    view_54 = add_14.view(mul_29, getitem_57, size_14);  add_14 = mul_29 = None\n",
      "    softmax_6 = torch.nn.functional.softmax(view_54, dim = -1, _stacklevel = 3, dtype = None);  view_54 = None\n",
      "    view_55 = getitem_53.view(1, -1, 1, 1);  getitem_53 = None\n",
      "    view_56 = softmax_6.view(getitem_56, 12, getitem_57, size_14);  softmax_6 = None\n",
      "    mul_30 = view_55 * view_56;  view_55 = view_56 = None\n",
      "    mul_31 = getitem_56 * 12\n",
      "    view_57 = mul_30.view(mul_31, getitem_57, size_14);  mul_30 = mul_31 = size_14 = None\n",
      "    dropout_19 = torch.nn.functional.dropout(view_57, p = 0.0, training = False, inplace = False);  view_57 = None\n",
      "    bmm_13 = torch.bmm(dropout_19, reshape_19);  dropout_19 = reshape_19 = None\n",
      "    view_58 = bmm_13.view(getitem_56, 12, getitem_57, 64);  bmm_13 = None\n",
      "    transpose_28 = view_58.transpose(1, 2);  view_58 = None\n",
      "    reshape_20 = transpose_28.reshape(getitem_56, getitem_57, 768);  transpose_28 = getitem_56 = getitem_57 = None\n",
      "    model_decoder_layers_3_self_attn_out_proj = getattr(self.model.decoder.layers, \"3\").self_attn.out_proj(reshape_20);  reshape_20 = None\n",
      "    dropout_20 = torch.nn.functional.dropout(model_decoder_layers_3_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_3_self_attn_out_proj = None\n",
      "    add_15 = add_13 + dropout_20;  add_13 = dropout_20 = None\n",
      "    model_decoder_layers_3_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"3\").encoder_attn_layer_norm(add_15)\n",
      "    getitem_61 = getitem_52[slice(-2, None, None)];  getitem_52 = None\n",
      "    size_15 = model_decoder_layers_3_encoder_attn_layer_norm.size()\n",
      "    getitem_62 = size_15[0]\n",
      "    getitem_63 = size_15[1]\n",
      "    getitem_64 = size_15[2];  size_15 = None\n",
      "    model_decoder_layers_3_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"3\").encoder_attn.q_proj(model_decoder_layers_3_encoder_attn_layer_norm);  model_decoder_layers_3_encoder_attn_layer_norm = None\n",
      "    mul_32 = model_decoder_layers_3_encoder_attn_q_proj * 0.125;  model_decoder_layers_3_encoder_attn_q_proj = None\n",
      "    getitem_65 = getitem_61[0]\n",
      "    getitem_66 = getitem_61[1];  getitem_61 = None\n",
      "    mul_33 = getitem_62 * 12\n",
      "    view_59 = mul_32.view(getitem_62, getitem_63, 12, 64);  mul_32 = None\n",
      "    transpose_29 = view_59.transpose(1, 2);  view_59 = None\n",
      "    contiguous_15 = transpose_29.contiguous();  transpose_29 = None\n",
      "    view_60 = contiguous_15.view(mul_33, -1, 64);  contiguous_15 = None\n",
      "    reshape_21 = getitem_65.reshape(mul_33, -1, 64)\n",
      "    reshape_22 = getitem_66.reshape(mul_33, -1, 64);  mul_33 = None\n",
      "    size_16 = reshape_21.size(1)\n",
      "    transpose_30 = reshape_21.transpose(1, 2);  reshape_21 = None\n",
      "    bmm_14 = torch.bmm(view_60, transpose_30);  view_60 = transpose_30 = None\n",
      "    softmax_7 = torch.nn.functional.softmax(bmm_14, dim = -1, _stacklevel = 3, dtype = None);  bmm_14 = None\n",
      "    view_61 = getitem_54.view(1, -1, 1, 1);  getitem_54 = None\n",
      "    view_62 = softmax_7.view(getitem_62, 12, getitem_63, size_16);  softmax_7 = None\n",
      "    mul_34 = view_61 * view_62;  view_61 = view_62 = None\n",
      "    mul_35 = getitem_62 * 12\n",
      "    view_63 = mul_34.view(mul_35, getitem_63, size_16);  mul_34 = mul_35 = size_16 = None\n",
      "    dropout_21 = torch.nn.functional.dropout(view_63, p = 0.0, training = False, inplace = False);  view_63 = None\n",
      "    bmm_15 = torch.bmm(dropout_21, reshape_22);  dropout_21 = reshape_22 = None\n",
      "    view_64 = bmm_15.view(getitem_62, 12, getitem_63, 64);  bmm_15 = None\n",
      "    transpose_31 = view_64.transpose(1, 2);  view_64 = None\n",
      "    reshape_23 = transpose_31.reshape(getitem_62, getitem_63, 768);  transpose_31 = getitem_62 = getitem_63 = None\n",
      "    model_decoder_layers_3_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"3\").encoder_attn.out_proj(reshape_23);  reshape_23 = None\n",
      "    dropout_22 = torch.nn.functional.dropout(model_decoder_layers_3_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_3_encoder_attn_out_proj = None\n",
      "    add_16 = add_15 + dropout_22;  add_15 = dropout_22 = None\n",
      "    model_decoder_layers_3_final_layer_norm = getattr(self.model.decoder.layers, \"3\").final_layer_norm(add_16)\n",
      "    model_decoder_layers_3_fc1 = getattr(self.model.decoder.layers, \"3\").fc1(model_decoder_layers_3_final_layer_norm);  model_decoder_layers_3_final_layer_norm = None\n",
      "    gelu_3 = torch._C._nn.gelu(model_decoder_layers_3_fc1);  model_decoder_layers_3_fc1 = None\n",
      "    dropout_23 = torch.nn.functional.dropout(gelu_3, p = 0.0, training = False, inplace = False);  gelu_3 = None\n",
      "    model_decoder_layers_3_fc2 = getattr(self.model.decoder.layers, \"3\").fc2(dropout_23);  dropout_23 = None\n",
      "    dropout_24 = torch.nn.functional.dropout(model_decoder_layers_3_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_3_fc2 = None\n",
      "    add_17 = add_16 + dropout_24;  add_16 = dropout_24 = None\n",
      "    getitem_67 = past_key_values[4]\n",
      "    getitem_68 = decoder_head_mask[4]\n",
      "    getitem_69 = cross_attn_head_mask[4]\n",
      "    model_decoder_layers_4_self_attn_layer_norm = getattr(self.model.decoder.layers, \"4\").self_attn_layer_norm(add_17)\n",
      "    getitem_70 = getitem_67[slice(None, 2, None)]\n",
      "    size_17 = model_decoder_layers_4_self_attn_layer_norm.size()\n",
      "    getitem_71 = size_17[0]\n",
      "    getitem_72 = size_17[1]\n",
      "    getitem_73 = size_17[2];  size_17 = None\n",
      "    model_decoder_layers_4_self_attn_q_proj = getattr(self.model.decoder.layers, \"4\").self_attn.q_proj(model_decoder_layers_4_self_attn_layer_norm)\n",
      "    mul_36 = model_decoder_layers_4_self_attn_q_proj * 0.125;  model_decoder_layers_4_self_attn_q_proj = None\n",
      "    model_decoder_layers_4_self_attn_k_proj = getattr(self.model.decoder.layers, \"4\").self_attn.k_proj(model_decoder_layers_4_self_attn_layer_norm)\n",
      "    view_65 = model_decoder_layers_4_self_attn_k_proj.view(getitem_71, -1, 12, 64);  model_decoder_layers_4_self_attn_k_proj = None\n",
      "    transpose_32 = view_65.transpose(1, 2);  view_65 = None\n",
      "    contiguous_16 = transpose_32.contiguous();  transpose_32 = None\n",
      "    model_decoder_layers_4_self_attn_v_proj = getattr(self.model.decoder.layers, \"4\").self_attn.v_proj(model_decoder_layers_4_self_attn_layer_norm);  model_decoder_layers_4_self_attn_layer_norm = None\n",
      "    view_66 = model_decoder_layers_4_self_attn_v_proj.view(getitem_71, -1, 12, 64);  model_decoder_layers_4_self_attn_v_proj = None\n",
      "    transpose_33 = view_66.transpose(1, 2);  view_66 = None\n",
      "    contiguous_17 = transpose_33.contiguous();  transpose_33 = None\n",
      "    getitem_74 = getitem_70[0]\n",
      "    cat_8 = torch.cat([getitem_74, contiguous_16], dim = 2);  getitem_74 = contiguous_16 = None\n",
      "    getitem_75 = getitem_70[1];  getitem_70 = None\n",
      "    cat_9 = torch.cat([getitem_75, contiguous_17], dim = 2);  getitem_75 = contiguous_17 = None\n",
      "    mul_37 = getitem_71 * 12\n",
      "    view_67 = mul_36.view(getitem_71, getitem_72, 12, 64);  mul_36 = None\n",
      "    transpose_34 = view_67.transpose(1, 2);  view_67 = None\n",
      "    contiguous_18 = transpose_34.contiguous();  transpose_34 = None\n",
      "    view_68 = contiguous_18.view(mul_37, -1, 64);  contiguous_18 = None\n",
      "    reshape_24 = cat_8.reshape(mul_37, -1, 64)\n",
      "    reshape_25 = cat_9.reshape(mul_37, -1, 64);  mul_37 = None\n",
      "    size_18 = reshape_24.size(1)\n",
      "    transpose_35 = reshape_24.transpose(1, 2);  reshape_24 = None\n",
      "    bmm_16 = torch.bmm(view_68, transpose_35);  view_68 = transpose_35 = None\n",
      "    view_69 = bmm_16.view(getitem_71, 12, getitem_72, size_18);  bmm_16 = None\n",
      "    add_18 = view_69 + _prepare_decoder_attention_mask;  view_69 = None\n",
      "    mul_38 = getitem_71 * 12\n",
      "    view_70 = add_18.view(mul_38, getitem_72, size_18);  add_18 = mul_38 = None\n",
      "    softmax_8 = torch.nn.functional.softmax(view_70, dim = -1, _stacklevel = 3, dtype = None);  view_70 = None\n",
      "    view_71 = getitem_68.view(1, -1, 1, 1);  getitem_68 = None\n",
      "    view_72 = softmax_8.view(getitem_71, 12, getitem_72, size_18);  softmax_8 = None\n",
      "    mul_39 = view_71 * view_72;  view_71 = view_72 = None\n",
      "    mul_40 = getitem_71 * 12\n",
      "    view_73 = mul_39.view(mul_40, getitem_72, size_18);  mul_39 = mul_40 = size_18 = None\n",
      "    dropout_25 = torch.nn.functional.dropout(view_73, p = 0.0, training = False, inplace = False);  view_73 = None\n",
      "    bmm_17 = torch.bmm(dropout_25, reshape_25);  dropout_25 = reshape_25 = None\n",
      "    view_74 = bmm_17.view(getitem_71, 12, getitem_72, 64);  bmm_17 = None\n",
      "    transpose_36 = view_74.transpose(1, 2);  view_74 = None\n",
      "    reshape_26 = transpose_36.reshape(getitem_71, getitem_72, 768);  transpose_36 = getitem_71 = getitem_72 = None\n",
      "    model_decoder_layers_4_self_attn_out_proj = getattr(self.model.decoder.layers, \"4\").self_attn.out_proj(reshape_26);  reshape_26 = None\n",
      "    dropout_26 = torch.nn.functional.dropout(model_decoder_layers_4_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_4_self_attn_out_proj = None\n",
      "    add_19 = add_17 + dropout_26;  add_17 = dropout_26 = None\n",
      "    model_decoder_layers_4_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"4\").encoder_attn_layer_norm(add_19)\n",
      "    getitem_76 = getitem_67[slice(-2, None, None)];  getitem_67 = None\n",
      "    size_19 = model_decoder_layers_4_encoder_attn_layer_norm.size()\n",
      "    getitem_77 = size_19[0]\n",
      "    getitem_78 = size_19[1]\n",
      "    getitem_79 = size_19[2];  size_19 = None\n",
      "    model_decoder_layers_4_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"4\").encoder_attn.q_proj(model_decoder_layers_4_encoder_attn_layer_norm);  model_decoder_layers_4_encoder_attn_layer_norm = None\n",
      "    mul_41 = model_decoder_layers_4_encoder_attn_q_proj * 0.125;  model_decoder_layers_4_encoder_attn_q_proj = None\n",
      "    getitem_80 = getitem_76[0]\n",
      "    getitem_81 = getitem_76[1];  getitem_76 = None\n",
      "    mul_42 = getitem_77 * 12\n",
      "    view_75 = mul_41.view(getitem_77, getitem_78, 12, 64);  mul_41 = None\n",
      "    transpose_37 = view_75.transpose(1, 2);  view_75 = None\n",
      "    contiguous_19 = transpose_37.contiguous();  transpose_37 = None\n",
      "    view_76 = contiguous_19.view(mul_42, -1, 64);  contiguous_19 = None\n",
      "    reshape_27 = getitem_80.reshape(mul_42, -1, 64)\n",
      "    reshape_28 = getitem_81.reshape(mul_42, -1, 64);  mul_42 = None\n",
      "    size_20 = reshape_27.size(1)\n",
      "    transpose_38 = reshape_27.transpose(1, 2);  reshape_27 = None\n",
      "    bmm_18 = torch.bmm(view_76, transpose_38);  view_76 = transpose_38 = None\n",
      "    softmax_9 = torch.nn.functional.softmax(bmm_18, dim = -1, _stacklevel = 3, dtype = None);  bmm_18 = None\n",
      "    view_77 = getitem_69.view(1, -1, 1, 1);  getitem_69 = None\n",
      "    view_78 = softmax_9.view(getitem_77, 12, getitem_78, size_20);  softmax_9 = None\n",
      "    mul_43 = view_77 * view_78;  view_77 = view_78 = None\n",
      "    mul_44 = getitem_77 * 12\n",
      "    view_79 = mul_43.view(mul_44, getitem_78, size_20);  mul_43 = mul_44 = size_20 = None\n",
      "    dropout_27 = torch.nn.functional.dropout(view_79, p = 0.0, training = False, inplace = False);  view_79 = None\n",
      "    bmm_19 = torch.bmm(dropout_27, reshape_28);  dropout_27 = reshape_28 = None\n",
      "    view_80 = bmm_19.view(getitem_77, 12, getitem_78, 64);  bmm_19 = None\n",
      "    transpose_39 = view_80.transpose(1, 2);  view_80 = None\n",
      "    reshape_29 = transpose_39.reshape(getitem_77, getitem_78, 768);  transpose_39 = getitem_77 = getitem_78 = None\n",
      "    model_decoder_layers_4_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"4\").encoder_attn.out_proj(reshape_29);  reshape_29 = None\n",
      "    dropout_28 = torch.nn.functional.dropout(model_decoder_layers_4_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_4_encoder_attn_out_proj = None\n",
      "    add_20 = add_19 + dropout_28;  add_19 = dropout_28 = None\n",
      "    model_decoder_layers_4_final_layer_norm = getattr(self.model.decoder.layers, \"4\").final_layer_norm(add_20)\n",
      "    model_decoder_layers_4_fc1 = getattr(self.model.decoder.layers, \"4\").fc1(model_decoder_layers_4_final_layer_norm);  model_decoder_layers_4_final_layer_norm = None\n",
      "    gelu_4 = torch._C._nn.gelu(model_decoder_layers_4_fc1);  model_decoder_layers_4_fc1 = None\n",
      "    dropout_29 = torch.nn.functional.dropout(gelu_4, p = 0.0, training = False, inplace = False);  gelu_4 = None\n",
      "    model_decoder_layers_4_fc2 = getattr(self.model.decoder.layers, \"4\").fc2(dropout_29);  dropout_29 = None\n",
      "    dropout_30 = torch.nn.functional.dropout(model_decoder_layers_4_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_4_fc2 = None\n",
      "    add_21 = add_20 + dropout_30;  add_20 = dropout_30 = None\n",
      "    getitem_82 = past_key_values[5]\n",
      "    getitem_83 = decoder_head_mask[5]\n",
      "    getitem_84 = cross_attn_head_mask[5]\n",
      "    model_decoder_layers_5_self_attn_layer_norm = getattr(self.model.decoder.layers, \"5\").self_attn_layer_norm(add_21)\n",
      "    getitem_85 = getitem_82[slice(None, 2, None)]\n",
      "    size_21 = model_decoder_layers_5_self_attn_layer_norm.size()\n",
      "    getitem_86 = size_21[0]\n",
      "    getitem_87 = size_21[1]\n",
      "    getitem_88 = size_21[2];  size_21 = None\n",
      "    model_decoder_layers_5_self_attn_q_proj = getattr(self.model.decoder.layers, \"5\").self_attn.q_proj(model_decoder_layers_5_self_attn_layer_norm)\n",
      "    mul_45 = model_decoder_layers_5_self_attn_q_proj * 0.125;  model_decoder_layers_5_self_attn_q_proj = None\n",
      "    model_decoder_layers_5_self_attn_k_proj = getattr(self.model.decoder.layers, \"5\").self_attn.k_proj(model_decoder_layers_5_self_attn_layer_norm)\n",
      "    view_81 = model_decoder_layers_5_self_attn_k_proj.view(getitem_86, -1, 12, 64);  model_decoder_layers_5_self_attn_k_proj = None\n",
      "    transpose_40 = view_81.transpose(1, 2);  view_81 = None\n",
      "    contiguous_20 = transpose_40.contiguous();  transpose_40 = None\n",
      "    model_decoder_layers_5_self_attn_v_proj = getattr(self.model.decoder.layers, \"5\").self_attn.v_proj(model_decoder_layers_5_self_attn_layer_norm);  model_decoder_layers_5_self_attn_layer_norm = None\n",
      "    view_82 = model_decoder_layers_5_self_attn_v_proj.view(getitem_86, -1, 12, 64);  model_decoder_layers_5_self_attn_v_proj = None\n",
      "    transpose_41 = view_82.transpose(1, 2);  view_82 = None\n",
      "    contiguous_21 = transpose_41.contiguous();  transpose_41 = None\n",
      "    getitem_89 = getitem_85[0]\n",
      "    cat_10 = torch.cat([getitem_89, contiguous_20], dim = 2);  getitem_89 = contiguous_20 = None\n",
      "    getitem_90 = getitem_85[1];  getitem_85 = None\n",
      "    cat_11 = torch.cat([getitem_90, contiguous_21], dim = 2);  getitem_90 = contiguous_21 = None\n",
      "    mul_46 = getitem_86 * 12\n",
      "    view_83 = mul_45.view(getitem_86, getitem_87, 12, 64);  mul_45 = None\n",
      "    transpose_42 = view_83.transpose(1, 2);  view_83 = None\n",
      "    contiguous_22 = transpose_42.contiguous();  transpose_42 = None\n",
      "    view_84 = contiguous_22.view(mul_46, -1, 64);  contiguous_22 = None\n",
      "    reshape_30 = cat_10.reshape(mul_46, -1, 64)\n",
      "    reshape_31 = cat_11.reshape(mul_46, -1, 64);  mul_46 = None\n",
      "    size_22 = reshape_30.size(1)\n",
      "    transpose_43 = reshape_30.transpose(1, 2);  reshape_30 = None\n",
      "    bmm_20 = torch.bmm(view_84, transpose_43);  view_84 = transpose_43 = None\n",
      "    view_85 = bmm_20.view(getitem_86, 12, getitem_87, size_22);  bmm_20 = None\n",
      "    add_22 = view_85 + _prepare_decoder_attention_mask;  view_85 = None\n",
      "    mul_47 = getitem_86 * 12\n",
      "    view_86 = add_22.view(mul_47, getitem_87, size_22);  add_22 = mul_47 = None\n",
      "    softmax_10 = torch.nn.functional.softmax(view_86, dim = -1, _stacklevel = 3, dtype = None);  view_86 = None\n",
      "    view_87 = getitem_83.view(1, -1, 1, 1);  getitem_83 = None\n",
      "    view_88 = softmax_10.view(getitem_86, 12, getitem_87, size_22);  softmax_10 = None\n",
      "    mul_48 = view_87 * view_88;  view_87 = view_88 = None\n",
      "    mul_49 = getitem_86 * 12\n",
      "    view_89 = mul_48.view(mul_49, getitem_87, size_22);  mul_48 = mul_49 = size_22 = None\n",
      "    dropout_31 = torch.nn.functional.dropout(view_89, p = 0.0, training = False, inplace = False);  view_89 = None\n",
      "    bmm_21 = torch.bmm(dropout_31, reshape_31);  dropout_31 = reshape_31 = None\n",
      "    view_90 = bmm_21.view(getitem_86, 12, getitem_87, 64);  bmm_21 = None\n",
      "    transpose_44 = view_90.transpose(1, 2);  view_90 = None\n",
      "    reshape_32 = transpose_44.reshape(getitem_86, getitem_87, 768);  transpose_44 = getitem_86 = getitem_87 = None\n",
      "    model_decoder_layers_5_self_attn_out_proj = getattr(self.model.decoder.layers, \"5\").self_attn.out_proj(reshape_32);  reshape_32 = None\n",
      "    dropout_32 = torch.nn.functional.dropout(model_decoder_layers_5_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_5_self_attn_out_proj = None\n",
      "    add_23 = add_21 + dropout_32;  add_21 = dropout_32 = None\n",
      "    model_decoder_layers_5_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"5\").encoder_attn_layer_norm(add_23)\n",
      "    getitem_91 = getitem_82[slice(-2, None, None)];  getitem_82 = None\n",
      "    size_23 = model_decoder_layers_5_encoder_attn_layer_norm.size()\n",
      "    getitem_92 = size_23[0]\n",
      "    getitem_93 = size_23[1]\n",
      "    getitem_94 = size_23[2];  size_23 = None\n",
      "    model_decoder_layers_5_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"5\").encoder_attn.q_proj(model_decoder_layers_5_encoder_attn_layer_norm);  model_decoder_layers_5_encoder_attn_layer_norm = None\n",
      "    mul_50 = model_decoder_layers_5_encoder_attn_q_proj * 0.125;  model_decoder_layers_5_encoder_attn_q_proj = None\n",
      "    getitem_95 = getitem_91[0]\n",
      "    getitem_96 = getitem_91[1];  getitem_91 = None\n",
      "    mul_51 = getitem_92 * 12\n",
      "    view_91 = mul_50.view(getitem_92, getitem_93, 12, 64);  mul_50 = None\n",
      "    transpose_45 = view_91.transpose(1, 2);  view_91 = None\n",
      "    contiguous_23 = transpose_45.contiguous();  transpose_45 = None\n",
      "    view_92 = contiguous_23.view(mul_51, -1, 64);  contiguous_23 = None\n",
      "    reshape_33 = getitem_95.reshape(mul_51, -1, 64)\n",
      "    reshape_34 = getitem_96.reshape(mul_51, -1, 64);  mul_51 = None\n",
      "    size_24 = reshape_33.size(1)\n",
      "    transpose_46 = reshape_33.transpose(1, 2);  reshape_33 = None\n",
      "    bmm_22 = torch.bmm(view_92, transpose_46);  view_92 = transpose_46 = None\n",
      "    softmax_11 = torch.nn.functional.softmax(bmm_22, dim = -1, _stacklevel = 3, dtype = None);  bmm_22 = None\n",
      "    view_93 = getitem_84.view(1, -1, 1, 1);  getitem_84 = None\n",
      "    view_94 = softmax_11.view(getitem_92, 12, getitem_93, size_24);  softmax_11 = None\n",
      "    mul_52 = view_93 * view_94;  view_93 = view_94 = None\n",
      "    mul_53 = getitem_92 * 12\n",
      "    view_95 = mul_52.view(mul_53, getitem_93, size_24);  mul_52 = mul_53 = size_24 = None\n",
      "    dropout_33 = torch.nn.functional.dropout(view_95, p = 0.0, training = False, inplace = False);  view_95 = None\n",
      "    bmm_23 = torch.bmm(dropout_33, reshape_34);  dropout_33 = reshape_34 = None\n",
      "    view_96 = bmm_23.view(getitem_92, 12, getitem_93, 64);  bmm_23 = None\n",
      "    transpose_47 = view_96.transpose(1, 2);  view_96 = None\n",
      "    reshape_35 = transpose_47.reshape(getitem_92, getitem_93, 768);  transpose_47 = getitem_92 = getitem_93 = None\n",
      "    model_decoder_layers_5_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"5\").encoder_attn.out_proj(reshape_35);  reshape_35 = None\n",
      "    dropout_34 = torch.nn.functional.dropout(model_decoder_layers_5_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_5_encoder_attn_out_proj = None\n",
      "    add_24 = add_23 + dropout_34;  add_23 = dropout_34 = None\n",
      "    model_decoder_layers_5_final_layer_norm = getattr(self.model.decoder.layers, \"5\").final_layer_norm(add_24)\n",
      "    model_decoder_layers_5_fc1 = getattr(self.model.decoder.layers, \"5\").fc1(model_decoder_layers_5_final_layer_norm);  model_decoder_layers_5_final_layer_norm = None\n",
      "    gelu_5 = torch._C._nn.gelu(model_decoder_layers_5_fc1);  model_decoder_layers_5_fc1 = None\n",
      "    dropout_35 = torch.nn.functional.dropout(gelu_5, p = 0.0, training = False, inplace = False);  gelu_5 = None\n",
      "    model_decoder_layers_5_fc2 = getattr(self.model.decoder.layers, \"5\").fc2(dropout_35);  dropout_35 = None\n",
      "    dropout_36 = torch.nn.functional.dropout(model_decoder_layers_5_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_5_fc2 = None\n",
      "    add_25 = add_24 + dropout_36;  add_24 = dropout_36 = None\n",
      "    getitem_97 = past_key_values[6]\n",
      "    getitem_98 = decoder_head_mask[6]\n",
      "    getitem_99 = cross_attn_head_mask[6]\n",
      "    model_decoder_layers_6_self_attn_layer_norm = getattr(self.model.decoder.layers, \"6\").self_attn_layer_norm(add_25)\n",
      "    getitem_100 = getitem_97[slice(None, 2, None)]\n",
      "    size_25 = model_decoder_layers_6_self_attn_layer_norm.size()\n",
      "    getitem_101 = size_25[0]\n",
      "    getitem_102 = size_25[1]\n",
      "    getitem_103 = size_25[2];  size_25 = None\n",
      "    model_decoder_layers_6_self_attn_q_proj = getattr(self.model.decoder.layers, \"6\").self_attn.q_proj(model_decoder_layers_6_self_attn_layer_norm)\n",
      "    mul_54 = model_decoder_layers_6_self_attn_q_proj * 0.125;  model_decoder_layers_6_self_attn_q_proj = None\n",
      "    model_decoder_layers_6_self_attn_k_proj = getattr(self.model.decoder.layers, \"6\").self_attn.k_proj(model_decoder_layers_6_self_attn_layer_norm)\n",
      "    view_97 = model_decoder_layers_6_self_attn_k_proj.view(getitem_101, -1, 12, 64);  model_decoder_layers_6_self_attn_k_proj = None\n",
      "    transpose_48 = view_97.transpose(1, 2);  view_97 = None\n",
      "    contiguous_24 = transpose_48.contiguous();  transpose_48 = None\n",
      "    model_decoder_layers_6_self_attn_v_proj = getattr(self.model.decoder.layers, \"6\").self_attn.v_proj(model_decoder_layers_6_self_attn_layer_norm);  model_decoder_layers_6_self_attn_layer_norm = None\n",
      "    view_98 = model_decoder_layers_6_self_attn_v_proj.view(getitem_101, -1, 12, 64);  model_decoder_layers_6_self_attn_v_proj = None\n",
      "    transpose_49 = view_98.transpose(1, 2);  view_98 = None\n",
      "    contiguous_25 = transpose_49.contiguous();  transpose_49 = None\n",
      "    getitem_104 = getitem_100[0]\n",
      "    cat_12 = torch.cat([getitem_104, contiguous_24], dim = 2);  getitem_104 = contiguous_24 = None\n",
      "    getitem_105 = getitem_100[1];  getitem_100 = None\n",
      "    cat_13 = torch.cat([getitem_105, contiguous_25], dim = 2);  getitem_105 = contiguous_25 = None\n",
      "    mul_55 = getitem_101 * 12\n",
      "    view_99 = mul_54.view(getitem_101, getitem_102, 12, 64);  mul_54 = None\n",
      "    transpose_50 = view_99.transpose(1, 2);  view_99 = None\n",
      "    contiguous_26 = transpose_50.contiguous();  transpose_50 = None\n",
      "    view_100 = contiguous_26.view(mul_55, -1, 64);  contiguous_26 = None\n",
      "    reshape_36 = cat_12.reshape(mul_55, -1, 64)\n",
      "    reshape_37 = cat_13.reshape(mul_55, -1, 64);  mul_55 = None\n",
      "    size_26 = reshape_36.size(1)\n",
      "    transpose_51 = reshape_36.transpose(1, 2);  reshape_36 = None\n",
      "    bmm_24 = torch.bmm(view_100, transpose_51);  view_100 = transpose_51 = None\n",
      "    view_101 = bmm_24.view(getitem_101, 12, getitem_102, size_26);  bmm_24 = None\n",
      "    add_26 = view_101 + _prepare_decoder_attention_mask;  view_101 = None\n",
      "    mul_56 = getitem_101 * 12\n",
      "    view_102 = add_26.view(mul_56, getitem_102, size_26);  add_26 = mul_56 = None\n",
      "    softmax_12 = torch.nn.functional.softmax(view_102, dim = -1, _stacklevel = 3, dtype = None);  view_102 = None\n",
      "    view_103 = getitem_98.view(1, -1, 1, 1);  getitem_98 = None\n",
      "    view_104 = softmax_12.view(getitem_101, 12, getitem_102, size_26);  softmax_12 = None\n",
      "    mul_57 = view_103 * view_104;  view_103 = view_104 = None\n",
      "    mul_58 = getitem_101 * 12\n",
      "    view_105 = mul_57.view(mul_58, getitem_102, size_26);  mul_57 = mul_58 = size_26 = None\n",
      "    dropout_37 = torch.nn.functional.dropout(view_105, p = 0.0, training = False, inplace = False);  view_105 = None\n",
      "    bmm_25 = torch.bmm(dropout_37, reshape_37);  dropout_37 = reshape_37 = None\n",
      "    view_106 = bmm_25.view(getitem_101, 12, getitem_102, 64);  bmm_25 = None\n",
      "    transpose_52 = view_106.transpose(1, 2);  view_106 = None\n",
      "    reshape_38 = transpose_52.reshape(getitem_101, getitem_102, 768);  transpose_52 = getitem_101 = getitem_102 = None\n",
      "    model_decoder_layers_6_self_attn_out_proj = getattr(self.model.decoder.layers, \"6\").self_attn.out_proj(reshape_38);  reshape_38 = None\n",
      "    dropout_38 = torch.nn.functional.dropout(model_decoder_layers_6_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_6_self_attn_out_proj = None\n",
      "    add_27 = add_25 + dropout_38;  add_25 = dropout_38 = None\n",
      "    model_decoder_layers_6_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"6\").encoder_attn_layer_norm(add_27)\n",
      "    getitem_106 = getitem_97[slice(-2, None, None)];  getitem_97 = None\n",
      "    size_27 = model_decoder_layers_6_encoder_attn_layer_norm.size()\n",
      "    getitem_107 = size_27[0]\n",
      "    getitem_108 = size_27[1]\n",
      "    getitem_109 = size_27[2];  size_27 = None\n",
      "    model_decoder_layers_6_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"6\").encoder_attn.q_proj(model_decoder_layers_6_encoder_attn_layer_norm);  model_decoder_layers_6_encoder_attn_layer_norm = None\n",
      "    mul_59 = model_decoder_layers_6_encoder_attn_q_proj * 0.125;  model_decoder_layers_6_encoder_attn_q_proj = None\n",
      "    getitem_110 = getitem_106[0]\n",
      "    getitem_111 = getitem_106[1];  getitem_106 = None\n",
      "    mul_60 = getitem_107 * 12\n",
      "    view_107 = mul_59.view(getitem_107, getitem_108, 12, 64);  mul_59 = None\n",
      "    transpose_53 = view_107.transpose(1, 2);  view_107 = None\n",
      "    contiguous_27 = transpose_53.contiguous();  transpose_53 = None\n",
      "    view_108 = contiguous_27.view(mul_60, -1, 64);  contiguous_27 = None\n",
      "    reshape_39 = getitem_110.reshape(mul_60, -1, 64)\n",
      "    reshape_40 = getitem_111.reshape(mul_60, -1, 64);  mul_60 = None\n",
      "    size_28 = reshape_39.size(1)\n",
      "    transpose_54 = reshape_39.transpose(1, 2);  reshape_39 = None\n",
      "    bmm_26 = torch.bmm(view_108, transpose_54);  view_108 = transpose_54 = None\n",
      "    softmax_13 = torch.nn.functional.softmax(bmm_26, dim = -1, _stacklevel = 3, dtype = None);  bmm_26 = None\n",
      "    view_109 = getitem_99.view(1, -1, 1, 1);  getitem_99 = None\n",
      "    view_110 = softmax_13.view(getitem_107, 12, getitem_108, size_28);  softmax_13 = None\n",
      "    mul_61 = view_109 * view_110;  view_109 = view_110 = None\n",
      "    mul_62 = getitem_107 * 12\n",
      "    view_111 = mul_61.view(mul_62, getitem_108, size_28);  mul_61 = mul_62 = size_28 = None\n",
      "    dropout_39 = torch.nn.functional.dropout(view_111, p = 0.0, training = False, inplace = False);  view_111 = None\n",
      "    bmm_27 = torch.bmm(dropout_39, reshape_40);  dropout_39 = reshape_40 = None\n",
      "    view_112 = bmm_27.view(getitem_107, 12, getitem_108, 64);  bmm_27 = None\n",
      "    transpose_55 = view_112.transpose(1, 2);  view_112 = None\n",
      "    reshape_41 = transpose_55.reshape(getitem_107, getitem_108, 768);  transpose_55 = getitem_107 = getitem_108 = None\n",
      "    model_decoder_layers_6_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"6\").encoder_attn.out_proj(reshape_41);  reshape_41 = None\n",
      "    dropout_40 = torch.nn.functional.dropout(model_decoder_layers_6_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_6_encoder_attn_out_proj = None\n",
      "    add_28 = add_27 + dropout_40;  add_27 = dropout_40 = None\n",
      "    model_decoder_layers_6_final_layer_norm = getattr(self.model.decoder.layers, \"6\").final_layer_norm(add_28)\n",
      "    model_decoder_layers_6_fc1 = getattr(self.model.decoder.layers, \"6\").fc1(model_decoder_layers_6_final_layer_norm);  model_decoder_layers_6_final_layer_norm = None\n",
      "    gelu_6 = torch._C._nn.gelu(model_decoder_layers_6_fc1);  model_decoder_layers_6_fc1 = None\n",
      "    dropout_41 = torch.nn.functional.dropout(gelu_6, p = 0.0, training = False, inplace = False);  gelu_6 = None\n",
      "    model_decoder_layers_6_fc2 = getattr(self.model.decoder.layers, \"6\").fc2(dropout_41);  dropout_41 = None\n",
      "    dropout_42 = torch.nn.functional.dropout(model_decoder_layers_6_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_6_fc2 = None\n",
      "    add_29 = add_28 + dropout_42;  add_28 = dropout_42 = None\n",
      "    getitem_112 = past_key_values[7]\n",
      "    getitem_113 = decoder_head_mask[7]\n",
      "    getitem_114 = cross_attn_head_mask[7]\n",
      "    model_decoder_layers_7_self_attn_layer_norm = getattr(self.model.decoder.layers, \"7\").self_attn_layer_norm(add_29)\n",
      "    getitem_115 = getitem_112[slice(None, 2, None)]\n",
      "    size_29 = model_decoder_layers_7_self_attn_layer_norm.size()\n",
      "    getitem_116 = size_29[0]\n",
      "    getitem_117 = size_29[1]\n",
      "    getitem_118 = size_29[2];  size_29 = None\n",
      "    model_decoder_layers_7_self_attn_q_proj = getattr(self.model.decoder.layers, \"7\").self_attn.q_proj(model_decoder_layers_7_self_attn_layer_norm)\n",
      "    mul_63 = model_decoder_layers_7_self_attn_q_proj * 0.125;  model_decoder_layers_7_self_attn_q_proj = None\n",
      "    model_decoder_layers_7_self_attn_k_proj = getattr(self.model.decoder.layers, \"7\").self_attn.k_proj(model_decoder_layers_7_self_attn_layer_norm)\n",
      "    view_113 = model_decoder_layers_7_self_attn_k_proj.view(getitem_116, -1, 12, 64);  model_decoder_layers_7_self_attn_k_proj = None\n",
      "    transpose_56 = view_113.transpose(1, 2);  view_113 = None\n",
      "    contiguous_28 = transpose_56.contiguous();  transpose_56 = None\n",
      "    model_decoder_layers_7_self_attn_v_proj = getattr(self.model.decoder.layers, \"7\").self_attn.v_proj(model_decoder_layers_7_self_attn_layer_norm);  model_decoder_layers_7_self_attn_layer_norm = None\n",
      "    view_114 = model_decoder_layers_7_self_attn_v_proj.view(getitem_116, -1, 12, 64);  model_decoder_layers_7_self_attn_v_proj = None\n",
      "    transpose_57 = view_114.transpose(1, 2);  view_114 = None\n",
      "    contiguous_29 = transpose_57.contiguous();  transpose_57 = None\n",
      "    getitem_119 = getitem_115[0]\n",
      "    cat_14 = torch.cat([getitem_119, contiguous_28], dim = 2);  getitem_119 = contiguous_28 = None\n",
      "    getitem_120 = getitem_115[1];  getitem_115 = None\n",
      "    cat_15 = torch.cat([getitem_120, contiguous_29], dim = 2);  getitem_120 = contiguous_29 = None\n",
      "    mul_64 = getitem_116 * 12\n",
      "    view_115 = mul_63.view(getitem_116, getitem_117, 12, 64);  mul_63 = None\n",
      "    transpose_58 = view_115.transpose(1, 2);  view_115 = None\n",
      "    contiguous_30 = transpose_58.contiguous();  transpose_58 = None\n",
      "    view_116 = contiguous_30.view(mul_64, -1, 64);  contiguous_30 = None\n",
      "    reshape_42 = cat_14.reshape(mul_64, -1, 64)\n",
      "    reshape_43 = cat_15.reshape(mul_64, -1, 64);  mul_64 = None\n",
      "    size_30 = reshape_42.size(1)\n",
      "    transpose_59 = reshape_42.transpose(1, 2);  reshape_42 = None\n",
      "    bmm_28 = torch.bmm(view_116, transpose_59);  view_116 = transpose_59 = None\n",
      "    view_117 = bmm_28.view(getitem_116, 12, getitem_117, size_30);  bmm_28 = None\n",
      "    add_30 = view_117 + _prepare_decoder_attention_mask;  view_117 = None\n",
      "    mul_65 = getitem_116 * 12\n",
      "    view_118 = add_30.view(mul_65, getitem_117, size_30);  add_30 = mul_65 = None\n",
      "    softmax_14 = torch.nn.functional.softmax(view_118, dim = -1, _stacklevel = 3, dtype = None);  view_118 = None\n",
      "    view_119 = getitem_113.view(1, -1, 1, 1);  getitem_113 = None\n",
      "    view_120 = softmax_14.view(getitem_116, 12, getitem_117, size_30);  softmax_14 = None\n",
      "    mul_66 = view_119 * view_120;  view_119 = view_120 = None\n",
      "    mul_67 = getitem_116 * 12\n",
      "    view_121 = mul_66.view(mul_67, getitem_117, size_30);  mul_66 = mul_67 = size_30 = None\n",
      "    dropout_43 = torch.nn.functional.dropout(view_121, p = 0.0, training = False, inplace = False);  view_121 = None\n",
      "    bmm_29 = torch.bmm(dropout_43, reshape_43);  dropout_43 = reshape_43 = None\n",
      "    view_122 = bmm_29.view(getitem_116, 12, getitem_117, 64);  bmm_29 = None\n",
      "    transpose_60 = view_122.transpose(1, 2);  view_122 = None\n",
      "    reshape_44 = transpose_60.reshape(getitem_116, getitem_117, 768);  transpose_60 = getitem_116 = getitem_117 = None\n",
      "    model_decoder_layers_7_self_attn_out_proj = getattr(self.model.decoder.layers, \"7\").self_attn.out_proj(reshape_44);  reshape_44 = None\n",
      "    dropout_44 = torch.nn.functional.dropout(model_decoder_layers_7_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_7_self_attn_out_proj = None\n",
      "    add_31 = add_29 + dropout_44;  add_29 = dropout_44 = None\n",
      "    model_decoder_layers_7_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"7\").encoder_attn_layer_norm(add_31)\n",
      "    getitem_121 = getitem_112[slice(-2, None, None)];  getitem_112 = None\n",
      "    size_31 = model_decoder_layers_7_encoder_attn_layer_norm.size()\n",
      "    getitem_122 = size_31[0]\n",
      "    getitem_123 = size_31[1]\n",
      "    getitem_124 = size_31[2];  size_31 = None\n",
      "    model_decoder_layers_7_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"7\").encoder_attn.q_proj(model_decoder_layers_7_encoder_attn_layer_norm);  model_decoder_layers_7_encoder_attn_layer_norm = None\n",
      "    mul_68 = model_decoder_layers_7_encoder_attn_q_proj * 0.125;  model_decoder_layers_7_encoder_attn_q_proj = None\n",
      "    getitem_125 = getitem_121[0]\n",
      "    getitem_126 = getitem_121[1];  getitem_121 = None\n",
      "    mul_69 = getitem_122 * 12\n",
      "    view_123 = mul_68.view(getitem_122, getitem_123, 12, 64);  mul_68 = None\n",
      "    transpose_61 = view_123.transpose(1, 2);  view_123 = None\n",
      "    contiguous_31 = transpose_61.contiguous();  transpose_61 = None\n",
      "    view_124 = contiguous_31.view(mul_69, -1, 64);  contiguous_31 = None\n",
      "    reshape_45 = getitem_125.reshape(mul_69, -1, 64)\n",
      "    reshape_46 = getitem_126.reshape(mul_69, -1, 64);  mul_69 = None\n",
      "    size_32 = reshape_45.size(1)\n",
      "    transpose_62 = reshape_45.transpose(1, 2);  reshape_45 = None\n",
      "    bmm_30 = torch.bmm(view_124, transpose_62);  view_124 = transpose_62 = None\n",
      "    softmax_15 = torch.nn.functional.softmax(bmm_30, dim = -1, _stacklevel = 3, dtype = None);  bmm_30 = None\n",
      "    view_125 = getitem_114.view(1, -1, 1, 1);  getitem_114 = None\n",
      "    view_126 = softmax_15.view(getitem_122, 12, getitem_123, size_32);  softmax_15 = None\n",
      "    mul_70 = view_125 * view_126;  view_125 = view_126 = None\n",
      "    mul_71 = getitem_122 * 12\n",
      "    view_127 = mul_70.view(mul_71, getitem_123, size_32);  mul_70 = mul_71 = size_32 = None\n",
      "    dropout_45 = torch.nn.functional.dropout(view_127, p = 0.0, training = False, inplace = False);  view_127 = None\n",
      "    bmm_31 = torch.bmm(dropout_45, reshape_46);  dropout_45 = reshape_46 = None\n",
      "    view_128 = bmm_31.view(getitem_122, 12, getitem_123, 64);  bmm_31 = None\n",
      "    transpose_63 = view_128.transpose(1, 2);  view_128 = None\n",
      "    reshape_47 = transpose_63.reshape(getitem_122, getitem_123, 768);  transpose_63 = getitem_122 = getitem_123 = None\n",
      "    model_decoder_layers_7_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"7\").encoder_attn.out_proj(reshape_47);  reshape_47 = None\n",
      "    dropout_46 = torch.nn.functional.dropout(model_decoder_layers_7_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_7_encoder_attn_out_proj = None\n",
      "    add_32 = add_31 + dropout_46;  add_31 = dropout_46 = None\n",
      "    model_decoder_layers_7_final_layer_norm = getattr(self.model.decoder.layers, \"7\").final_layer_norm(add_32)\n",
      "    model_decoder_layers_7_fc1 = getattr(self.model.decoder.layers, \"7\").fc1(model_decoder_layers_7_final_layer_norm);  model_decoder_layers_7_final_layer_norm = None\n",
      "    gelu_7 = torch._C._nn.gelu(model_decoder_layers_7_fc1);  model_decoder_layers_7_fc1 = None\n",
      "    dropout_47 = torch.nn.functional.dropout(gelu_7, p = 0.0, training = False, inplace = False);  gelu_7 = None\n",
      "    model_decoder_layers_7_fc2 = getattr(self.model.decoder.layers, \"7\").fc2(dropout_47);  dropout_47 = None\n",
      "    dropout_48 = torch.nn.functional.dropout(model_decoder_layers_7_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_7_fc2 = None\n",
      "    add_33 = add_32 + dropout_48;  add_32 = dropout_48 = None\n",
      "    getitem_127 = past_key_values[8]\n",
      "    getitem_128 = decoder_head_mask[8]\n",
      "    getitem_129 = cross_attn_head_mask[8]\n",
      "    model_decoder_layers_8_self_attn_layer_norm = getattr(self.model.decoder.layers, \"8\").self_attn_layer_norm(add_33)\n",
      "    getitem_130 = getitem_127[slice(None, 2, None)]\n",
      "    size_33 = model_decoder_layers_8_self_attn_layer_norm.size()\n",
      "    getitem_131 = size_33[0]\n",
      "    getitem_132 = size_33[1]\n",
      "    getitem_133 = size_33[2];  size_33 = None\n",
      "    model_decoder_layers_8_self_attn_q_proj = getattr(self.model.decoder.layers, \"8\").self_attn.q_proj(model_decoder_layers_8_self_attn_layer_norm)\n",
      "    mul_72 = model_decoder_layers_8_self_attn_q_proj * 0.125;  model_decoder_layers_8_self_attn_q_proj = None\n",
      "    model_decoder_layers_8_self_attn_k_proj = getattr(self.model.decoder.layers, \"8\").self_attn.k_proj(model_decoder_layers_8_self_attn_layer_norm)\n",
      "    view_129 = model_decoder_layers_8_self_attn_k_proj.view(getitem_131, -1, 12, 64);  model_decoder_layers_8_self_attn_k_proj = None\n",
      "    transpose_64 = view_129.transpose(1, 2);  view_129 = None\n",
      "    contiguous_32 = transpose_64.contiguous();  transpose_64 = None\n",
      "    model_decoder_layers_8_self_attn_v_proj = getattr(self.model.decoder.layers, \"8\").self_attn.v_proj(model_decoder_layers_8_self_attn_layer_norm);  model_decoder_layers_8_self_attn_layer_norm = None\n",
      "    view_130 = model_decoder_layers_8_self_attn_v_proj.view(getitem_131, -1, 12, 64);  model_decoder_layers_8_self_attn_v_proj = None\n",
      "    transpose_65 = view_130.transpose(1, 2);  view_130 = None\n",
      "    contiguous_33 = transpose_65.contiguous();  transpose_65 = None\n",
      "    getitem_134 = getitem_130[0]\n",
      "    cat_16 = torch.cat([getitem_134, contiguous_32], dim = 2);  getitem_134 = contiguous_32 = None\n",
      "    getitem_135 = getitem_130[1];  getitem_130 = None\n",
      "    cat_17 = torch.cat([getitem_135, contiguous_33], dim = 2);  getitem_135 = contiguous_33 = None\n",
      "    mul_73 = getitem_131 * 12\n",
      "    view_131 = mul_72.view(getitem_131, getitem_132, 12, 64);  mul_72 = None\n",
      "    transpose_66 = view_131.transpose(1, 2);  view_131 = None\n",
      "    contiguous_34 = transpose_66.contiguous();  transpose_66 = None\n",
      "    view_132 = contiguous_34.view(mul_73, -1, 64);  contiguous_34 = None\n",
      "    reshape_48 = cat_16.reshape(mul_73, -1, 64)\n",
      "    reshape_49 = cat_17.reshape(mul_73, -1, 64);  mul_73 = None\n",
      "    size_34 = reshape_48.size(1)\n",
      "    transpose_67 = reshape_48.transpose(1, 2);  reshape_48 = None\n",
      "    bmm_32 = torch.bmm(view_132, transpose_67);  view_132 = transpose_67 = None\n",
      "    view_133 = bmm_32.view(getitem_131, 12, getitem_132, size_34);  bmm_32 = None\n",
      "    add_34 = view_133 + _prepare_decoder_attention_mask;  view_133 = None\n",
      "    mul_74 = getitem_131 * 12\n",
      "    view_134 = add_34.view(mul_74, getitem_132, size_34);  add_34 = mul_74 = None\n",
      "    softmax_16 = torch.nn.functional.softmax(view_134, dim = -1, _stacklevel = 3, dtype = None);  view_134 = None\n",
      "    view_135 = getitem_128.view(1, -1, 1, 1);  getitem_128 = None\n",
      "    view_136 = softmax_16.view(getitem_131, 12, getitem_132, size_34);  softmax_16 = None\n",
      "    mul_75 = view_135 * view_136;  view_135 = view_136 = None\n",
      "    mul_76 = getitem_131 * 12\n",
      "    view_137 = mul_75.view(mul_76, getitem_132, size_34);  mul_75 = mul_76 = size_34 = None\n",
      "    dropout_49 = torch.nn.functional.dropout(view_137, p = 0.0, training = False, inplace = False);  view_137 = None\n",
      "    bmm_33 = torch.bmm(dropout_49, reshape_49);  dropout_49 = reshape_49 = None\n",
      "    view_138 = bmm_33.view(getitem_131, 12, getitem_132, 64);  bmm_33 = None\n",
      "    transpose_68 = view_138.transpose(1, 2);  view_138 = None\n",
      "    reshape_50 = transpose_68.reshape(getitem_131, getitem_132, 768);  transpose_68 = getitem_131 = getitem_132 = None\n",
      "    model_decoder_layers_8_self_attn_out_proj = getattr(self.model.decoder.layers, \"8\").self_attn.out_proj(reshape_50);  reshape_50 = None\n",
      "    dropout_50 = torch.nn.functional.dropout(model_decoder_layers_8_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_8_self_attn_out_proj = None\n",
      "    add_35 = add_33 + dropout_50;  add_33 = dropout_50 = None\n",
      "    model_decoder_layers_8_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"8\").encoder_attn_layer_norm(add_35)\n",
      "    getitem_136 = getitem_127[slice(-2, None, None)];  getitem_127 = None\n",
      "    size_35 = model_decoder_layers_8_encoder_attn_layer_norm.size()\n",
      "    getitem_137 = size_35[0]\n",
      "    getitem_138 = size_35[1]\n",
      "    getitem_139 = size_35[2];  size_35 = None\n",
      "    model_decoder_layers_8_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"8\").encoder_attn.q_proj(model_decoder_layers_8_encoder_attn_layer_norm);  model_decoder_layers_8_encoder_attn_layer_norm = None\n",
      "    mul_77 = model_decoder_layers_8_encoder_attn_q_proj * 0.125;  model_decoder_layers_8_encoder_attn_q_proj = None\n",
      "    getitem_140 = getitem_136[0]\n",
      "    getitem_141 = getitem_136[1];  getitem_136 = None\n",
      "    mul_78 = getitem_137 * 12\n",
      "    view_139 = mul_77.view(getitem_137, getitem_138, 12, 64);  mul_77 = None\n",
      "    transpose_69 = view_139.transpose(1, 2);  view_139 = None\n",
      "    contiguous_35 = transpose_69.contiguous();  transpose_69 = None\n",
      "    view_140 = contiguous_35.view(mul_78, -1, 64);  contiguous_35 = None\n",
      "    reshape_51 = getitem_140.reshape(mul_78, -1, 64)\n",
      "    reshape_52 = getitem_141.reshape(mul_78, -1, 64);  mul_78 = None\n",
      "    size_36 = reshape_51.size(1)\n",
      "    transpose_70 = reshape_51.transpose(1, 2);  reshape_51 = None\n",
      "    bmm_34 = torch.bmm(view_140, transpose_70);  view_140 = transpose_70 = None\n",
      "    softmax_17 = torch.nn.functional.softmax(bmm_34, dim = -1, _stacklevel = 3, dtype = None);  bmm_34 = None\n",
      "    view_141 = getitem_129.view(1, -1, 1, 1);  getitem_129 = None\n",
      "    view_142 = softmax_17.view(getitem_137, 12, getitem_138, size_36);  softmax_17 = None\n",
      "    mul_79 = view_141 * view_142;  view_141 = view_142 = None\n",
      "    mul_80 = getitem_137 * 12\n",
      "    view_143 = mul_79.view(mul_80, getitem_138, size_36);  mul_79 = mul_80 = size_36 = None\n",
      "    dropout_51 = torch.nn.functional.dropout(view_143, p = 0.0, training = False, inplace = False);  view_143 = None\n",
      "    bmm_35 = torch.bmm(dropout_51, reshape_52);  dropout_51 = reshape_52 = None\n",
      "    view_144 = bmm_35.view(getitem_137, 12, getitem_138, 64);  bmm_35 = None\n",
      "    transpose_71 = view_144.transpose(1, 2);  view_144 = None\n",
      "    reshape_53 = transpose_71.reshape(getitem_137, getitem_138, 768);  transpose_71 = getitem_137 = getitem_138 = None\n",
      "    model_decoder_layers_8_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"8\").encoder_attn.out_proj(reshape_53);  reshape_53 = None\n",
      "    dropout_52 = torch.nn.functional.dropout(model_decoder_layers_8_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_8_encoder_attn_out_proj = None\n",
      "    add_36 = add_35 + dropout_52;  add_35 = dropout_52 = None\n",
      "    model_decoder_layers_8_final_layer_norm = getattr(self.model.decoder.layers, \"8\").final_layer_norm(add_36)\n",
      "    model_decoder_layers_8_fc1 = getattr(self.model.decoder.layers, \"8\").fc1(model_decoder_layers_8_final_layer_norm);  model_decoder_layers_8_final_layer_norm = None\n",
      "    gelu_8 = torch._C._nn.gelu(model_decoder_layers_8_fc1);  model_decoder_layers_8_fc1 = None\n",
      "    dropout_53 = torch.nn.functional.dropout(gelu_8, p = 0.0, training = False, inplace = False);  gelu_8 = None\n",
      "    model_decoder_layers_8_fc2 = getattr(self.model.decoder.layers, \"8\").fc2(dropout_53);  dropout_53 = None\n",
      "    dropout_54 = torch.nn.functional.dropout(model_decoder_layers_8_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_8_fc2 = None\n",
      "    add_37 = add_36 + dropout_54;  add_36 = dropout_54 = None\n",
      "    getitem_142 = past_key_values[9]\n",
      "    getitem_143 = decoder_head_mask[9]\n",
      "    getitem_144 = cross_attn_head_mask[9]\n",
      "    model_decoder_layers_9_self_attn_layer_norm = getattr(self.model.decoder.layers, \"9\").self_attn_layer_norm(add_37)\n",
      "    getitem_145 = getitem_142[slice(None, 2, None)]\n",
      "    size_37 = model_decoder_layers_9_self_attn_layer_norm.size()\n",
      "    getitem_146 = size_37[0]\n",
      "    getitem_147 = size_37[1]\n",
      "    getitem_148 = size_37[2];  size_37 = None\n",
      "    model_decoder_layers_9_self_attn_q_proj = getattr(self.model.decoder.layers, \"9\").self_attn.q_proj(model_decoder_layers_9_self_attn_layer_norm)\n",
      "    mul_81 = model_decoder_layers_9_self_attn_q_proj * 0.125;  model_decoder_layers_9_self_attn_q_proj = None\n",
      "    model_decoder_layers_9_self_attn_k_proj = getattr(self.model.decoder.layers, \"9\").self_attn.k_proj(model_decoder_layers_9_self_attn_layer_norm)\n",
      "    view_145 = model_decoder_layers_9_self_attn_k_proj.view(getitem_146, -1, 12, 64);  model_decoder_layers_9_self_attn_k_proj = None\n",
      "    transpose_72 = view_145.transpose(1, 2);  view_145 = None\n",
      "    contiguous_36 = transpose_72.contiguous();  transpose_72 = None\n",
      "    model_decoder_layers_9_self_attn_v_proj = getattr(self.model.decoder.layers, \"9\").self_attn.v_proj(model_decoder_layers_9_self_attn_layer_norm);  model_decoder_layers_9_self_attn_layer_norm = None\n",
      "    view_146 = model_decoder_layers_9_self_attn_v_proj.view(getitem_146, -1, 12, 64);  model_decoder_layers_9_self_attn_v_proj = None\n",
      "    transpose_73 = view_146.transpose(1, 2);  view_146 = None\n",
      "    contiguous_37 = transpose_73.contiguous();  transpose_73 = None\n",
      "    getitem_149 = getitem_145[0]\n",
      "    cat_18 = torch.cat([getitem_149, contiguous_36], dim = 2);  getitem_149 = contiguous_36 = None\n",
      "    getitem_150 = getitem_145[1];  getitem_145 = None\n",
      "    cat_19 = torch.cat([getitem_150, contiguous_37], dim = 2);  getitem_150 = contiguous_37 = None\n",
      "    mul_82 = getitem_146 * 12\n",
      "    view_147 = mul_81.view(getitem_146, getitem_147, 12, 64);  mul_81 = None\n",
      "    transpose_74 = view_147.transpose(1, 2);  view_147 = None\n",
      "    contiguous_38 = transpose_74.contiguous();  transpose_74 = None\n",
      "    view_148 = contiguous_38.view(mul_82, -1, 64);  contiguous_38 = None\n",
      "    reshape_54 = cat_18.reshape(mul_82, -1, 64)\n",
      "    reshape_55 = cat_19.reshape(mul_82, -1, 64);  mul_82 = None\n",
      "    size_38 = reshape_54.size(1)\n",
      "    transpose_75 = reshape_54.transpose(1, 2);  reshape_54 = None\n",
      "    bmm_36 = torch.bmm(view_148, transpose_75);  view_148 = transpose_75 = None\n",
      "    view_149 = bmm_36.view(getitem_146, 12, getitem_147, size_38);  bmm_36 = None\n",
      "    add_38 = view_149 + _prepare_decoder_attention_mask;  view_149 = None\n",
      "    mul_83 = getitem_146 * 12\n",
      "    view_150 = add_38.view(mul_83, getitem_147, size_38);  add_38 = mul_83 = None\n",
      "    softmax_18 = torch.nn.functional.softmax(view_150, dim = -1, _stacklevel = 3, dtype = None);  view_150 = None\n",
      "    view_151 = getitem_143.view(1, -1, 1, 1);  getitem_143 = None\n",
      "    view_152 = softmax_18.view(getitem_146, 12, getitem_147, size_38);  softmax_18 = None\n",
      "    mul_84 = view_151 * view_152;  view_151 = view_152 = None\n",
      "    mul_85 = getitem_146 * 12\n",
      "    view_153 = mul_84.view(mul_85, getitem_147, size_38);  mul_84 = mul_85 = size_38 = None\n",
      "    dropout_55 = torch.nn.functional.dropout(view_153, p = 0.0, training = False, inplace = False);  view_153 = None\n",
      "    bmm_37 = torch.bmm(dropout_55, reshape_55);  dropout_55 = reshape_55 = None\n",
      "    view_154 = bmm_37.view(getitem_146, 12, getitem_147, 64);  bmm_37 = None\n",
      "    transpose_76 = view_154.transpose(1, 2);  view_154 = None\n",
      "    reshape_56 = transpose_76.reshape(getitem_146, getitem_147, 768);  transpose_76 = getitem_146 = getitem_147 = None\n",
      "    model_decoder_layers_9_self_attn_out_proj = getattr(self.model.decoder.layers, \"9\").self_attn.out_proj(reshape_56);  reshape_56 = None\n",
      "    dropout_56 = torch.nn.functional.dropout(model_decoder_layers_9_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_9_self_attn_out_proj = None\n",
      "    add_39 = add_37 + dropout_56;  add_37 = dropout_56 = None\n",
      "    model_decoder_layers_9_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"9\").encoder_attn_layer_norm(add_39)\n",
      "    getitem_151 = getitem_142[slice(-2, None, None)];  getitem_142 = None\n",
      "    size_39 = model_decoder_layers_9_encoder_attn_layer_norm.size()\n",
      "    getitem_152 = size_39[0]\n",
      "    getitem_153 = size_39[1]\n",
      "    getitem_154 = size_39[2];  size_39 = None\n",
      "    model_decoder_layers_9_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"9\").encoder_attn.q_proj(model_decoder_layers_9_encoder_attn_layer_norm);  model_decoder_layers_9_encoder_attn_layer_norm = None\n",
      "    mul_86 = model_decoder_layers_9_encoder_attn_q_proj * 0.125;  model_decoder_layers_9_encoder_attn_q_proj = None\n",
      "    getitem_155 = getitem_151[0]\n",
      "    getitem_156 = getitem_151[1];  getitem_151 = None\n",
      "    mul_87 = getitem_152 * 12\n",
      "    view_155 = mul_86.view(getitem_152, getitem_153, 12, 64);  mul_86 = None\n",
      "    transpose_77 = view_155.transpose(1, 2);  view_155 = None\n",
      "    contiguous_39 = transpose_77.contiguous();  transpose_77 = None\n",
      "    view_156 = contiguous_39.view(mul_87, -1, 64);  contiguous_39 = None\n",
      "    reshape_57 = getitem_155.reshape(mul_87, -1, 64)\n",
      "    reshape_58 = getitem_156.reshape(mul_87, -1, 64);  mul_87 = None\n",
      "    size_40 = reshape_57.size(1)\n",
      "    transpose_78 = reshape_57.transpose(1, 2);  reshape_57 = None\n",
      "    bmm_38 = torch.bmm(view_156, transpose_78);  view_156 = transpose_78 = None\n",
      "    softmax_19 = torch.nn.functional.softmax(bmm_38, dim = -1, _stacklevel = 3, dtype = None);  bmm_38 = None\n",
      "    view_157 = getitem_144.view(1, -1, 1, 1);  getitem_144 = None\n",
      "    view_158 = softmax_19.view(getitem_152, 12, getitem_153, size_40);  softmax_19 = None\n",
      "    mul_88 = view_157 * view_158;  view_157 = view_158 = None\n",
      "    mul_89 = getitem_152 * 12\n",
      "    view_159 = mul_88.view(mul_89, getitem_153, size_40);  mul_88 = mul_89 = size_40 = None\n",
      "    dropout_57 = torch.nn.functional.dropout(view_159, p = 0.0, training = False, inplace = False);  view_159 = None\n",
      "    bmm_39 = torch.bmm(dropout_57, reshape_58);  dropout_57 = reshape_58 = None\n",
      "    view_160 = bmm_39.view(getitem_152, 12, getitem_153, 64);  bmm_39 = None\n",
      "    transpose_79 = view_160.transpose(1, 2);  view_160 = None\n",
      "    reshape_59 = transpose_79.reshape(getitem_152, getitem_153, 768);  transpose_79 = getitem_152 = getitem_153 = None\n",
      "    model_decoder_layers_9_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"9\").encoder_attn.out_proj(reshape_59);  reshape_59 = None\n",
      "    dropout_58 = torch.nn.functional.dropout(model_decoder_layers_9_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_9_encoder_attn_out_proj = None\n",
      "    add_40 = add_39 + dropout_58;  add_39 = dropout_58 = None\n",
      "    model_decoder_layers_9_final_layer_norm = getattr(self.model.decoder.layers, \"9\").final_layer_norm(add_40)\n",
      "    model_decoder_layers_9_fc1 = getattr(self.model.decoder.layers, \"9\").fc1(model_decoder_layers_9_final_layer_norm);  model_decoder_layers_9_final_layer_norm = None\n",
      "    gelu_9 = torch._C._nn.gelu(model_decoder_layers_9_fc1);  model_decoder_layers_9_fc1 = None\n",
      "    dropout_59 = torch.nn.functional.dropout(gelu_9, p = 0.0, training = False, inplace = False);  gelu_9 = None\n",
      "    model_decoder_layers_9_fc2 = getattr(self.model.decoder.layers, \"9\").fc2(dropout_59);  dropout_59 = None\n",
      "    dropout_60 = torch.nn.functional.dropout(model_decoder_layers_9_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_9_fc2 = None\n",
      "    add_41 = add_40 + dropout_60;  add_40 = dropout_60 = None\n",
      "    getitem_157 = past_key_values[10]\n",
      "    getitem_158 = decoder_head_mask[10]\n",
      "    getitem_159 = cross_attn_head_mask[10]\n",
      "    model_decoder_layers_10_self_attn_layer_norm = getattr(self.model.decoder.layers, \"10\").self_attn_layer_norm(add_41)\n",
      "    getitem_160 = getitem_157[slice(None, 2, None)]\n",
      "    size_41 = model_decoder_layers_10_self_attn_layer_norm.size()\n",
      "    getitem_161 = size_41[0]\n",
      "    getitem_162 = size_41[1]\n",
      "    getitem_163 = size_41[2];  size_41 = None\n",
      "    model_decoder_layers_10_self_attn_q_proj = getattr(self.model.decoder.layers, \"10\").self_attn.q_proj(model_decoder_layers_10_self_attn_layer_norm)\n",
      "    mul_90 = model_decoder_layers_10_self_attn_q_proj * 0.125;  model_decoder_layers_10_self_attn_q_proj = None\n",
      "    model_decoder_layers_10_self_attn_k_proj = getattr(self.model.decoder.layers, \"10\").self_attn.k_proj(model_decoder_layers_10_self_attn_layer_norm)\n",
      "    view_161 = model_decoder_layers_10_self_attn_k_proj.view(getitem_161, -1, 12, 64);  model_decoder_layers_10_self_attn_k_proj = None\n",
      "    transpose_80 = view_161.transpose(1, 2);  view_161 = None\n",
      "    contiguous_40 = transpose_80.contiguous();  transpose_80 = None\n",
      "    model_decoder_layers_10_self_attn_v_proj = getattr(self.model.decoder.layers, \"10\").self_attn.v_proj(model_decoder_layers_10_self_attn_layer_norm);  model_decoder_layers_10_self_attn_layer_norm = None\n",
      "    view_162 = model_decoder_layers_10_self_attn_v_proj.view(getitem_161, -1, 12, 64);  model_decoder_layers_10_self_attn_v_proj = None\n",
      "    transpose_81 = view_162.transpose(1, 2);  view_162 = None\n",
      "    contiguous_41 = transpose_81.contiguous();  transpose_81 = None\n",
      "    getitem_164 = getitem_160[0]\n",
      "    cat_20 = torch.cat([getitem_164, contiguous_40], dim = 2);  getitem_164 = contiguous_40 = None\n",
      "    getitem_165 = getitem_160[1];  getitem_160 = None\n",
      "    cat_21 = torch.cat([getitem_165, contiguous_41], dim = 2);  getitem_165 = contiguous_41 = None\n",
      "    mul_91 = getitem_161 * 12\n",
      "    view_163 = mul_90.view(getitem_161, getitem_162, 12, 64);  mul_90 = None\n",
      "    transpose_82 = view_163.transpose(1, 2);  view_163 = None\n",
      "    contiguous_42 = transpose_82.contiguous();  transpose_82 = None\n",
      "    view_164 = contiguous_42.view(mul_91, -1, 64);  contiguous_42 = None\n",
      "    reshape_60 = cat_20.reshape(mul_91, -1, 64)\n",
      "    reshape_61 = cat_21.reshape(mul_91, -1, 64);  mul_91 = None\n",
      "    size_42 = reshape_60.size(1)\n",
      "    transpose_83 = reshape_60.transpose(1, 2);  reshape_60 = None\n",
      "    bmm_40 = torch.bmm(view_164, transpose_83);  view_164 = transpose_83 = None\n",
      "    view_165 = bmm_40.view(getitem_161, 12, getitem_162, size_42);  bmm_40 = None\n",
      "    add_42 = view_165 + _prepare_decoder_attention_mask;  view_165 = None\n",
      "    mul_92 = getitem_161 * 12\n",
      "    view_166 = add_42.view(mul_92, getitem_162, size_42);  add_42 = mul_92 = None\n",
      "    softmax_20 = torch.nn.functional.softmax(view_166, dim = -1, _stacklevel = 3, dtype = None);  view_166 = None\n",
      "    view_167 = getitem_158.view(1, -1, 1, 1);  getitem_158 = None\n",
      "    view_168 = softmax_20.view(getitem_161, 12, getitem_162, size_42);  softmax_20 = None\n",
      "    mul_93 = view_167 * view_168;  view_167 = view_168 = None\n",
      "    mul_94 = getitem_161 * 12\n",
      "    view_169 = mul_93.view(mul_94, getitem_162, size_42);  mul_93 = mul_94 = size_42 = None\n",
      "    dropout_61 = torch.nn.functional.dropout(view_169, p = 0.0, training = False, inplace = False);  view_169 = None\n",
      "    bmm_41 = torch.bmm(dropout_61, reshape_61);  dropout_61 = reshape_61 = None\n",
      "    view_170 = bmm_41.view(getitem_161, 12, getitem_162, 64);  bmm_41 = None\n",
      "    transpose_84 = view_170.transpose(1, 2);  view_170 = None\n",
      "    reshape_62 = transpose_84.reshape(getitem_161, getitem_162, 768);  transpose_84 = getitem_161 = getitem_162 = None\n",
      "    model_decoder_layers_10_self_attn_out_proj = getattr(self.model.decoder.layers, \"10\").self_attn.out_proj(reshape_62);  reshape_62 = None\n",
      "    dropout_62 = torch.nn.functional.dropout(model_decoder_layers_10_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_10_self_attn_out_proj = None\n",
      "    add_43 = add_41 + dropout_62;  add_41 = dropout_62 = None\n",
      "    model_decoder_layers_10_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"10\").encoder_attn_layer_norm(add_43)\n",
      "    getitem_166 = getitem_157[slice(-2, None, None)];  getitem_157 = None\n",
      "    size_43 = model_decoder_layers_10_encoder_attn_layer_norm.size()\n",
      "    getitem_167 = size_43[0]\n",
      "    getitem_168 = size_43[1]\n",
      "    getitem_169 = size_43[2];  size_43 = None\n",
      "    model_decoder_layers_10_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"10\").encoder_attn.q_proj(model_decoder_layers_10_encoder_attn_layer_norm);  model_decoder_layers_10_encoder_attn_layer_norm = None\n",
      "    mul_95 = model_decoder_layers_10_encoder_attn_q_proj * 0.125;  model_decoder_layers_10_encoder_attn_q_proj = None\n",
      "    getitem_170 = getitem_166[0]\n",
      "    getitem_171 = getitem_166[1];  getitem_166 = None\n",
      "    mul_96 = getitem_167 * 12\n",
      "    view_171 = mul_95.view(getitem_167, getitem_168, 12, 64);  mul_95 = None\n",
      "    transpose_85 = view_171.transpose(1, 2);  view_171 = None\n",
      "    contiguous_43 = transpose_85.contiguous();  transpose_85 = None\n",
      "    view_172 = contiguous_43.view(mul_96, -1, 64);  contiguous_43 = None\n",
      "    reshape_63 = getitem_170.reshape(mul_96, -1, 64)\n",
      "    reshape_64 = getitem_171.reshape(mul_96, -1, 64);  mul_96 = None\n",
      "    size_44 = reshape_63.size(1)\n",
      "    transpose_86 = reshape_63.transpose(1, 2);  reshape_63 = None\n",
      "    bmm_42 = torch.bmm(view_172, transpose_86);  view_172 = transpose_86 = None\n",
      "    softmax_21 = torch.nn.functional.softmax(bmm_42, dim = -1, _stacklevel = 3, dtype = None);  bmm_42 = None\n",
      "    view_173 = getitem_159.view(1, -1, 1, 1);  getitem_159 = None\n",
      "    view_174 = softmax_21.view(getitem_167, 12, getitem_168, size_44);  softmax_21 = None\n",
      "    mul_97 = view_173 * view_174;  view_173 = view_174 = None\n",
      "    mul_98 = getitem_167 * 12\n",
      "    view_175 = mul_97.view(mul_98, getitem_168, size_44);  mul_97 = mul_98 = size_44 = None\n",
      "    dropout_63 = torch.nn.functional.dropout(view_175, p = 0.0, training = False, inplace = False);  view_175 = None\n",
      "    bmm_43 = torch.bmm(dropout_63, reshape_64);  dropout_63 = reshape_64 = None\n",
      "    view_176 = bmm_43.view(getitem_167, 12, getitem_168, 64);  bmm_43 = None\n",
      "    transpose_87 = view_176.transpose(1, 2);  view_176 = None\n",
      "    reshape_65 = transpose_87.reshape(getitem_167, getitem_168, 768);  transpose_87 = getitem_167 = getitem_168 = None\n",
      "    model_decoder_layers_10_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"10\").encoder_attn.out_proj(reshape_65);  reshape_65 = None\n",
      "    dropout_64 = torch.nn.functional.dropout(model_decoder_layers_10_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_10_encoder_attn_out_proj = None\n",
      "    add_44 = add_43 + dropout_64;  add_43 = dropout_64 = None\n",
      "    model_decoder_layers_10_final_layer_norm = getattr(self.model.decoder.layers, \"10\").final_layer_norm(add_44)\n",
      "    model_decoder_layers_10_fc1 = getattr(self.model.decoder.layers, \"10\").fc1(model_decoder_layers_10_final_layer_norm);  model_decoder_layers_10_final_layer_norm = None\n",
      "    gelu_10 = torch._C._nn.gelu(model_decoder_layers_10_fc1);  model_decoder_layers_10_fc1 = None\n",
      "    dropout_65 = torch.nn.functional.dropout(gelu_10, p = 0.0, training = False, inplace = False);  gelu_10 = None\n",
      "    model_decoder_layers_10_fc2 = getattr(self.model.decoder.layers, \"10\").fc2(dropout_65);  dropout_65 = None\n",
      "    dropout_66 = torch.nn.functional.dropout(model_decoder_layers_10_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_10_fc2 = None\n",
      "    add_45 = add_44 + dropout_66;  add_44 = dropout_66 = None\n",
      "    getitem_172 = past_key_values[11];  past_key_values = None\n",
      "    getitem_173 = decoder_head_mask[11];  decoder_head_mask = None\n",
      "    getitem_174 = cross_attn_head_mask[11];  cross_attn_head_mask = None\n",
      "    model_decoder_layers_11_self_attn_layer_norm = getattr(self.model.decoder.layers, \"11\").self_attn_layer_norm(add_45)\n",
      "    getitem_175 = getitem_172[slice(None, 2, None)]\n",
      "    size_45 = model_decoder_layers_11_self_attn_layer_norm.size()\n",
      "    getitem_176 = size_45[0]\n",
      "    getitem_177 = size_45[1]\n",
      "    getitem_178 = size_45[2];  size_45 = None\n",
      "    model_decoder_layers_11_self_attn_q_proj = getattr(self.model.decoder.layers, \"11\").self_attn.q_proj(model_decoder_layers_11_self_attn_layer_norm)\n",
      "    mul_99 = model_decoder_layers_11_self_attn_q_proj * 0.125;  model_decoder_layers_11_self_attn_q_proj = None\n",
      "    model_decoder_layers_11_self_attn_k_proj = getattr(self.model.decoder.layers, \"11\").self_attn.k_proj(model_decoder_layers_11_self_attn_layer_norm)\n",
      "    view_177 = model_decoder_layers_11_self_attn_k_proj.view(getitem_176, -1, 12, 64);  model_decoder_layers_11_self_attn_k_proj = None\n",
      "    transpose_88 = view_177.transpose(1, 2);  view_177 = None\n",
      "    contiguous_44 = transpose_88.contiguous();  transpose_88 = None\n",
      "    model_decoder_layers_11_self_attn_v_proj = getattr(self.model.decoder.layers, \"11\").self_attn.v_proj(model_decoder_layers_11_self_attn_layer_norm);  model_decoder_layers_11_self_attn_layer_norm = None\n",
      "    view_178 = model_decoder_layers_11_self_attn_v_proj.view(getitem_176, -1, 12, 64);  model_decoder_layers_11_self_attn_v_proj = None\n",
      "    transpose_89 = view_178.transpose(1, 2);  view_178 = None\n",
      "    contiguous_45 = transpose_89.contiguous();  transpose_89 = None\n",
      "    getitem_179 = getitem_175[0]\n",
      "    cat_22 = torch.cat([getitem_179, contiguous_44], dim = 2);  getitem_179 = contiguous_44 = None\n",
      "    getitem_180 = getitem_175[1];  getitem_175 = None\n",
      "    cat_23 = torch.cat([getitem_180, contiguous_45], dim = 2);  getitem_180 = contiguous_45 = None\n",
      "    mul_100 = getitem_176 * 12\n",
      "    view_179 = mul_99.view(getitem_176, getitem_177, 12, 64);  mul_99 = None\n",
      "    transpose_90 = view_179.transpose(1, 2);  view_179 = None\n",
      "    contiguous_46 = transpose_90.contiguous();  transpose_90 = None\n",
      "    view_180 = contiguous_46.view(mul_100, -1, 64);  contiguous_46 = None\n",
      "    reshape_66 = cat_22.reshape(mul_100, -1, 64)\n",
      "    reshape_67 = cat_23.reshape(mul_100, -1, 64);  mul_100 = None\n",
      "    size_46 = reshape_66.size(1)\n",
      "    transpose_91 = reshape_66.transpose(1, 2);  reshape_66 = None\n",
      "    bmm_44 = torch.bmm(view_180, transpose_91);  view_180 = transpose_91 = None\n",
      "    view_181 = bmm_44.view(getitem_176, 12, getitem_177, size_46);  bmm_44 = None\n",
      "    add_46 = view_181 + _prepare_decoder_attention_mask;  view_181 = _prepare_decoder_attention_mask = None\n",
      "    mul_101 = getitem_176 * 12\n",
      "    view_182 = add_46.view(mul_101, getitem_177, size_46);  add_46 = mul_101 = None\n",
      "    softmax_22 = torch.nn.functional.softmax(view_182, dim = -1, _stacklevel = 3, dtype = None);  view_182 = None\n",
      "    view_183 = getitem_173.view(1, -1, 1, 1);  getitem_173 = None\n",
      "    view_184 = softmax_22.view(getitem_176, 12, getitem_177, size_46);  softmax_22 = None\n",
      "    mul_102 = view_183 * view_184;  view_183 = view_184 = None\n",
      "    mul_103 = getitem_176 * 12\n",
      "    view_185 = mul_102.view(mul_103, getitem_177, size_46);  mul_102 = mul_103 = size_46 = None\n",
      "    dropout_67 = torch.nn.functional.dropout(view_185, p = 0.0, training = False, inplace = False);  view_185 = None\n",
      "    bmm_45 = torch.bmm(dropout_67, reshape_67);  dropout_67 = reshape_67 = None\n",
      "    view_186 = bmm_45.view(getitem_176, 12, getitem_177, 64);  bmm_45 = None\n",
      "    transpose_92 = view_186.transpose(1, 2);  view_186 = None\n",
      "    reshape_68 = transpose_92.reshape(getitem_176, getitem_177, 768);  transpose_92 = getitem_176 = getitem_177 = None\n",
      "    model_decoder_layers_11_self_attn_out_proj = getattr(self.model.decoder.layers, \"11\").self_attn.out_proj(reshape_68);  reshape_68 = None\n",
      "    dropout_68 = torch.nn.functional.dropout(model_decoder_layers_11_self_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_11_self_attn_out_proj = None\n",
      "    add_47 = add_45 + dropout_68;  add_45 = dropout_68 = None\n",
      "    model_decoder_layers_11_encoder_attn_layer_norm = getattr(self.model.decoder.layers, \"11\").encoder_attn_layer_norm(add_47)\n",
      "    getitem_181 = getitem_172[slice(-2, None, None)];  getitem_172 = None\n",
      "    size_47 = model_decoder_layers_11_encoder_attn_layer_norm.size()\n",
      "    getitem_182 = size_47[0]\n",
      "    getitem_183 = size_47[1]\n",
      "    getitem_184 = size_47[2];  size_47 = None\n",
      "    model_decoder_layers_11_encoder_attn_q_proj = getattr(self.model.decoder.layers, \"11\").encoder_attn.q_proj(model_decoder_layers_11_encoder_attn_layer_norm);  model_decoder_layers_11_encoder_attn_layer_norm = None\n",
      "    mul_104 = model_decoder_layers_11_encoder_attn_q_proj * 0.125;  model_decoder_layers_11_encoder_attn_q_proj = None\n",
      "    getitem_185 = getitem_181[0]\n",
      "    getitem_186 = getitem_181[1];  getitem_181 = None\n",
      "    mul_105 = getitem_182 * 12\n",
      "    view_187 = mul_104.view(getitem_182, getitem_183, 12, 64);  mul_104 = None\n",
      "    transpose_93 = view_187.transpose(1, 2);  view_187 = None\n",
      "    contiguous_47 = transpose_93.contiguous();  transpose_93 = None\n",
      "    view_188 = contiguous_47.view(mul_105, -1, 64);  contiguous_47 = None\n",
      "    reshape_69 = getitem_185.reshape(mul_105, -1, 64)\n",
      "    reshape_70 = getitem_186.reshape(mul_105, -1, 64);  mul_105 = None\n",
      "    size_48 = reshape_69.size(1)\n",
      "    transpose_94 = reshape_69.transpose(1, 2);  reshape_69 = None\n",
      "    bmm_46 = torch.bmm(view_188, transpose_94);  view_188 = transpose_94 = None\n",
      "    softmax_23 = torch.nn.functional.softmax(bmm_46, dim = -1, _stacklevel = 3, dtype = None);  bmm_46 = None\n",
      "    view_189 = getitem_174.view(1, -1, 1, 1);  getitem_174 = None\n",
      "    view_190 = softmax_23.view(getitem_182, 12, getitem_183, size_48);  softmax_23 = None\n",
      "    mul_106 = view_189 * view_190;  view_189 = view_190 = None\n",
      "    mul_107 = getitem_182 * 12\n",
      "    view_191 = mul_106.view(mul_107, getitem_183, size_48);  mul_106 = mul_107 = size_48 = None\n",
      "    dropout_69 = torch.nn.functional.dropout(view_191, p = 0.0, training = False, inplace = False);  view_191 = None\n",
      "    bmm_47 = torch.bmm(dropout_69, reshape_70);  dropout_69 = reshape_70 = None\n",
      "    view_192 = bmm_47.view(getitem_182, 12, getitem_183, 64);  bmm_47 = None\n",
      "    transpose_95 = view_192.transpose(1, 2);  view_192 = None\n",
      "    reshape_71 = transpose_95.reshape(getitem_182, getitem_183, 768);  transpose_95 = getitem_182 = getitem_183 = None\n",
      "    model_decoder_layers_11_encoder_attn_out_proj = getattr(self.model.decoder.layers, \"11\").encoder_attn.out_proj(reshape_71);  reshape_71 = None\n",
      "    dropout_70 = torch.nn.functional.dropout(model_decoder_layers_11_encoder_attn_out_proj, p = 0.0, training = False, inplace = False);  model_decoder_layers_11_encoder_attn_out_proj = None\n",
      "    add_48 = add_47 + dropout_70;  add_47 = dropout_70 = None\n",
      "    model_decoder_layers_11_final_layer_norm = getattr(self.model.decoder.layers, \"11\").final_layer_norm(add_48)\n",
      "    model_decoder_layers_11_fc1 = getattr(self.model.decoder.layers, \"11\").fc1(model_decoder_layers_11_final_layer_norm);  model_decoder_layers_11_final_layer_norm = None\n",
      "    gelu_11 = torch._C._nn.gelu(model_decoder_layers_11_fc1);  model_decoder_layers_11_fc1 = None\n",
      "    dropout_71 = torch.nn.functional.dropout(gelu_11, p = 0.0, training = False, inplace = False);  gelu_11 = None\n",
      "    model_decoder_layers_11_fc2 = getattr(self.model.decoder.layers, \"11\").fc2(dropout_71);  dropout_71 = None\n",
      "    dropout_72 = torch.nn.functional.dropout(model_decoder_layers_11_fc2, p = 0.0, training = False, inplace = False);  model_decoder_layers_11_fc2 = None\n",
      "    add_49 = add_48 + dropout_72;  add_48 = dropout_72 = None\n",
      "    model_decoder_layer_norm = self.model.decoder.layer_norm(add_49);  add_49 = None\n",
      "    proj_out = self.proj_out(model_decoder_layer_norm);  model_decoder_layer_norm = None\n",
      "    getattr_3 = proj_out.device\n",
      "    to = labels.to(getattr_3);  labels = getattr_3 = None\n",
      "    view_193 = proj_out.view(-1, 51865)\n",
      "    reshape_72 = to.reshape(-1);  to = None\n",
      "    loss_fct = self.loss_fct(view_193, reshape_72);  view_193 = reshape_72 = None\n",
      "    getattr_4 = encoder_outputs.last_hidden_state\n",
      "    getattr_5 = encoder_outputs.hidden_states\n",
      "    getattr_6 = encoder_outputs.attentions;  encoder_outputs = None\n",
      "    return {'loss': loss_fct, 'logits': proj_out, 'past_key_values': ((cat, cat_1, getitem_20, getitem_21), (cat_2, cat_3, getitem_35, getitem_36), (cat_4, cat_5, getitem_50, getitem_51), (cat_6, cat_7, getitem_65, getitem_66), (cat_8, cat_9, getitem_80, getitem_81), (cat_10, cat_11, getitem_95, getitem_96), (cat_12, cat_13, getitem_110, getitem_111), (cat_14, cat_15, getitem_125, getitem_126), (cat_16, cat_17, getitem_140, getitem_141), (cat_18, cat_19, getitem_155, getitem_156), (cat_20, cat_21, getitem_170, getitem_171), (cat_22, cat_23, getitem_185, getitem_186)), 'encoder_last_hidden_state': getattr_4, 'encoder_hidden_states': getattr_5, 'encoder_attentions': getattr_6}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(symbolic_traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b6e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
