{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd662fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/ujan/anaconda3/envs/asr/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda112.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/ujan/anaconda3/envs/asr/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 112\n",
      "CUDA SETUP: Loading binary /home/ujan/anaconda3/envs/asr/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n"
     ]
    }
   ],
   "source": [
    "#from transformers.utils.fx import symbolic_trace\n",
    "from transformers import AutoConfig, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "from modeling_whisper_traceable import WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.fx as fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1f6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#from transformers.utils.fx import symbolic_trace\n",
    "from transformers import AutoConfig, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "#from whisper_traceable_masked import MaskedWhisperForConditionalGeneration\n",
    "from modeling_whisper import SparseWhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "model_name_or_path = 'openai/whisper-small'\n",
    "data_dir = 'mozilla-foundation/common_voice_11_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from mozilla-foundation/common_voice_11_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Reading metadata...: 10581it [00:00, 18936.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "print('loading dataset from {}'.format(data_dir))\n",
    "\n",
    "raw_datasets = load_dataset(data_dir, \"zh-CN\", split=\"test\", streaming=True)\n",
    "text_column_name = 'sentence'\n",
    "\n",
    "\n",
    "# model, tokenizer, feature extractor, processor\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "model_config.update({\"forced_decoder_ids\": [], \"suppress_tokens\": []})\n",
    "\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #use_fast=model_args.use_fast_tokenizer,\n",
    "    #revision=model_args.model_revision,\n",
    "    #use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "tokenizer.set_prefix_tokens(language='chinese', task='transcribe')\n",
    "\n",
    "\n",
    "model = SparseWhisperForConditionalGeneration.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #config=model_config,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "if model.config.decoder_start_token_id is None:\n",
    "    raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
    "    \n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path)\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='chinese', task='transcribe')\n",
    "\n",
    "\n",
    "dataset = raw_datasets\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "\n",
    "\n",
    "inputs = processor(\n",
    "    sample['audio'][\"array\"],\n",
    "    sampling_rate=feature_extractor.sampling_rate,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\")\n",
    "                \n",
    "input_features = inputs.input_features\n",
    "attention_mask = inputs.attention_mask\n",
    "decoder_input_ids = torch.tensor([model.config.decoder_start_token_id]).reshape(1, -1)\n",
    "labels = tokenizer(sample['sentence'], return_tensors='pt').input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85eef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 1, 64])\n",
      "value : torch.Size([12, 1, 64])\n",
      "attn : torch.Size([12, 1, 1])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 2, 64])\n",
      "value : torch.Size([12, 2, 64])\n",
      "attn : torch.Size([12, 1, 2])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 3, 64])\n",
      "value : torch.Size([12, 3, 64])\n",
      "attn : torch.Size([12, 1, 3])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 4, 64])\n",
      "value : torch.Size([12, 4, 64])\n",
      "attn : torch.Size([12, 1, 4])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 5, 64])\n",
      "value : torch.Size([12, 5, 64])\n",
      "attn : torch.Size([12, 1, 5])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 1, 6])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 7, 64])\n",
      "value : torch.Size([12, 7, 64])\n",
      "attn : torch.Size([12, 1, 7])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 8, 64])\n",
      "value : torch.Size([12, 8, 64])\n",
      "attn : torch.Size([12, 1, 8])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 9, 64])\n",
      "value : torch.Size([12, 9, 64])\n",
      "attn : torch.Size([12, 1, 9])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 10, 64])\n",
      "value : torch.Size([12, 10, 64])\n",
      "attn : torch.Size([12, 1, 10])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 11, 64])\n",
      "value : torch.Size([12, 11, 64])\n",
      "attn : torch.Size([12, 1, 11])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 12, 64])\n",
      "value : torch.Size([12, 12, 64])\n",
      "attn : torch.Size([12, 1, 12])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n",
      "key : torch.Size([12, 13, 64])\n",
      "value : torch.Size([12, 13, 64])\n",
      "attn : torch.Size([12, 1, 13])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50260, 50359, 50363, 22381, 40211,  2322,  7732,    95,  2347,\n",
       "           108, 19976,   227, 50257]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n",
      "key : torch.Size([12, 6, 64])\n",
      "value : torch.Size([12, 6, 64])\n",
      "attn : torch.Size([12, 6, 6])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "_ = model(input_features=input_features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe6c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e0714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8dc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers = model.config.encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a7a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained('/users/ujan/speech-processing/models/whisper/pasted_checkpoint-5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b2b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=448) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.83 s ± 494 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit output_ids = model.generate(input_features)\n",
    "#_ = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1949eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model.prune_heads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceca0a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_ids = model.generate(input_features)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/IPython/core/magics/execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 206\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/IPython/core/magics/execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_pt_prune.py:1962\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, return_token_timestamps, **kwargs)\u001b[0m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1960\u001b[0m         generation_config\u001b[38;5;241m.\u001b[39mnum_frames \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1962\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_token_timestamps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1973\u001b[0m     num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/generation/utils.py:1596\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1580\u001b[0m         input_ids,\n\u001b[1;32m   1581\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1593\u001b[0m     )\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/generation/utils.py:2444\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2441\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2444\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2445\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2447\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2448\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2449\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_pt_prune.py:1679\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1675\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1676\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1677\u001b[0m         )\n\u001b[0;32m-> 1679\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1697\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_pt_prune.py:1498\u001b[0m, in \u001b[0;36mWhisperModel.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1492\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1493\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1494\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1495\u001b[0m     )\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1498\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_pt_prune.py:1315\u001b[0m, in \u001b[0;36mWhisperDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1305\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1306\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# past_key_value\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m     )\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1315\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_pt_prune.py:773\u001b[0m, in \u001b[0;36mWhisperDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    771\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    772\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(hidden_states)\n\u001b[0;32m--> 773\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    774\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    775\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit output_ids = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0b6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization import get_default_qconfig\n",
    "from quantize_fx import prepare_fx, convert_fx\n",
    "from torch.ao.quantization import QConfigMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229c0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconfig = get_default_qconfig(\"x86\")\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d020617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = (input_features, attention_mask, decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c310d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/asr/lib/python3.10/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (activation_post_process_0): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_1): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (model): Module(\n",
       "    (decoder): Module(\n",
       "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
       "      (embed_positions): Module()\n",
       "      (layers): Module(\n",
       "        (0): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (1): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (2): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (3): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (4): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (5): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (6): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (7): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (8): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (9): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (10): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (11): Module(\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Module(\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_2): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_30): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_3): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_4): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_5): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_33): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_59): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_6): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_7): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_8): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_9): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_10): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_11): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_12): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_13): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_14): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_15): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_16): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_17): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_18): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_19): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_20): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_21): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_22): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_23): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_24): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_25): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_26): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_27): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_28): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_29): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_31): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_32): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_35): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_34): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_36): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_37): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_38): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_39): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_40): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_41): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_42): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_43): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_44): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_45): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_46): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_47): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_48): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_49): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_54): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_56): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_50): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_51): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_52): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_53): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_55): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_57): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_58): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_61): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_60): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_62): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_63): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_64): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_65): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_66): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_67): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_68): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_69): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_70): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_71): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_72): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_73): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_74): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_75): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_76): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_77): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_78): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_79): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_106): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_132): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_80): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_81): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_82): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_83): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_84): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_85): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_86): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_87): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_88): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_89): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_90): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_91): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_92): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_93): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_94): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_95): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_96): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_97): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_98): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_99): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_100): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_101): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_102): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_103): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_104): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_105): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_108): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_107): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_109): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_110): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_111): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_112): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_113): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_114): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_115): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_116): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_117): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_118): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_119): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_120): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_121): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_122): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_127): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_129): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_123): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_124): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_125): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_126): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_128): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_130): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_131): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_134): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_133): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_135): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_136): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_137): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_138): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_139): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_140): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_141): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_142): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_143): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_144): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_145): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_146): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_147): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_148): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_149): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_150): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_151): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_152): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_179): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_205): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_153): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_154): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_155): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_156): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_157): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_158): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_159): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_160): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_161): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_162): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_163): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_164): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_165): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_166): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_167): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_168): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_169): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_170): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_171): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_172): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_173): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_174): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_175): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_176): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_177): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_178): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_181): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_180): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_182): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_183): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_184): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_185): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_186): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_187): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_188): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_189): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_190): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_191): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_192): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_193): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_194): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_195): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_200): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_202): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_196): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_197): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_198): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_199): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_201): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_203): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_204): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_207): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_206): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_208): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_209): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_210): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_211): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_212): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_213): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_214): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_215): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_216): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_217): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_218): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_219): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_220): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_221): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_222): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_223): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_224): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_225): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_252): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_278): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_226): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_227): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_228): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_229): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_230): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_231): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_232): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_233): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_234): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_235): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_236): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_237): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_238): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_239): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_240): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_241): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_242): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_243): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_244): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_245): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_246): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_247): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_248): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_249): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_250): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_251): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_254): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_253): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_255): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_256): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_257): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_258): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_259): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_260): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_261): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_262): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_263): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_264): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_265): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_266): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_267): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_268): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_273): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_275): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_269): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_270): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_271): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_272): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_274): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_276): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_277): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_280): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_279): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_281): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_282): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_283): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_284): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_285): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_286): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_287): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_288): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_289): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_290): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_291): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_292): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_293): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_294): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_295): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_296): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_297): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_298): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_325): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_351): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_299): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_300): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_301): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_302): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_303): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_304): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_305): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_306): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_307): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_308): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_309): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_310): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_311): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_312): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_313): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_314): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_315): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_316): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_317): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_318): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_319): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_320): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_321): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_322): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_323): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_324): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_327): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_326): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_328): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_329): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_330): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_331): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_332): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_333): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_334): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_335): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_336): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_337): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_338): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_339): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_340): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_341): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_346): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_348): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_342): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_343): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_344): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_345): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_347): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_349): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_350): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_353): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_352): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_354): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_355): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_356): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_357): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_358): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_359): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_360): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_361): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_362): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_363): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_364): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_365): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_366): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_367): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_368): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_369): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_370): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_371): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_398): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_424): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_372): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_373): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_374): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_375): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_376): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_377): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_378): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_379): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_380): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_381): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_382): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_383): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_384): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_385): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_386): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_387): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_388): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_389): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_390): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_391): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_392): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_393): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_394): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_395): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_396): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_397): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_400): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_399): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_401): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_402): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_403): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_404): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_405): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_406): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_407): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_408): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_409): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_410): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_411): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_412): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_413): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_414): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_419): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_421): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_415): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_416): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_417): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_418): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_420): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_422): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_423): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_426): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_425): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_427): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_428): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_429): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_430): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_431): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_432): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_433): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_434): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_435): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_436): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_437): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_438): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_439): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_440): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_441): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_442): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_443): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_444): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_471): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_497): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_445): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_446): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_447): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_448): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_449): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_450): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_451): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_452): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_453): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_454): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_455): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_456): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_457): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_458): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_459): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_460): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_461): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_462): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_463): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_464): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_465): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_466): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_467): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_468): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_469): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_470): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_473): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_472): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_474): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_475): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_476): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_477): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_478): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_479): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_480): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_481): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_482): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_483): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_484): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_485): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_486): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_487): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_492): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_494): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_488): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_489): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_490): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_491): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_493): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_495): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_496): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_499): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_498): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_500): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_501): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_502): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_503): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_504): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_505): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_506): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_507): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_508): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_509): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_510): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_511): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_512): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_513): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_514): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_515): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_516): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_517): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_544): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_570): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_518): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_519): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_520): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_521): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_522): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_523): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_524): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_525): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_526): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_527): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_528): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_529): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_530): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_531): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_532): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_533): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_534): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_535): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_536): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_537): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_538): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_539): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_540): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_541): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_542): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_543): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_546): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_545): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_547): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_548): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_549): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_550): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_551): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_552): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_553): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_554): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_555): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_556): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_557): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_558): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_559): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_560): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_565): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_567): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_561): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_562): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_563): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_564): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_566): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_568): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_569): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_572): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_571): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_573): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_574): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_575): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_576): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_577): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_578): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_579): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_580): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_581): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_582): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_583): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_584): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_585): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_586): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_587): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_588): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_589): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_590): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_617): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_643): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_591): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_592): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_593): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_594): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_595): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_596): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_597): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_598): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_599): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_600): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_601): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_602): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_603): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_604): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_605): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_606): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_607): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_608): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_609): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_610): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_611): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_612): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_613): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_614): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_615): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_616): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_619): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_618): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_620): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_621): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_622): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_623): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_624): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_625): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_626): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_627): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_628): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_629): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_630): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_631): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_632): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_633): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_638): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_640): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_634): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_635): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_636): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_637): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_639): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_641): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_642): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_645): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_644): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_646): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_647): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_648): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_649): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_650): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_651): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_652): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_653): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_654): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_655): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_656): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_657): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_658): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_659): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_660): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_661): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_662): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_663): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_690): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_716): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_664): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_665): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_666): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_667): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_668): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_669): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_670): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_671): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_672): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_673): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_674): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_675): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_676): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_677): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_678): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_679): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_680): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_681): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_682): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_683): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_684): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_685): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_686): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_687): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_688): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_689): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_692): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_691): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_693): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_694): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_695): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_696): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_697): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_698): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_699): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_700): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_701): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_702): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_703): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_704): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_705): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_706): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_711): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_713): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_707): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_708): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_709): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_710): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_712): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_714): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_715): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_718): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_717): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_719): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_720): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_721): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_722): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_723): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_724): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_725): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_726): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_727): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_728): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_729): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_730): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_731): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_732): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_733): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_734): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_735): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_736): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_763): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_789): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_737): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_738): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_739): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_740): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_741): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_742): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_743): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_744): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_745): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_746): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_747): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_748): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_749): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_750): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_751): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_752): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_753): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_754): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_755): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_756): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_757): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_758): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_759): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_760): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_761): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_762): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_765): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_764): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_766): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_767): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_768): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_769): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_770): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_771): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_772): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_773): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_774): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_775): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_776): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_777): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_778): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_779): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_784): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_786): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_780): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_781): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_782): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_783): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_785): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_787): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_788): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_791): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_790): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_792): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_793): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_794): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_795): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_796): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_797): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_798): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_799): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_800): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_801): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_802): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_803): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_804): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_805): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_806): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_807): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_808): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_809): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_836): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_862): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_810): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_811): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_812): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_813): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_814): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_815): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_816): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_817): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_818): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_819): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_820): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_821): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_822): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_823): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_824): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_825): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_826): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_827): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_828): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_829): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_830): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_831): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_832): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_833): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_834): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_835): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_838): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_837): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_839): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_840): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_841): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_842): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_843): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_844): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_845): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_846): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_847): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_848): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_849): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_850): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_851): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_852): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_857): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_859): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_853): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_854): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_855): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_856): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_858): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_860): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_861): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_864): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_863): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_865): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_866): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_867): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_868): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_869): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_870): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_871): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_872): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_873): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_874): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_875): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_876): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_877): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_878): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_879): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_880): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_881): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_882): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_883): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
       "  (activation_post_process_884): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_886): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_885): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_887): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_fx(model, qconfig_mapping, example_inputs, concrete_args=decoder_concrete_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3c91ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31443de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3670, 0.9916, 0.8972, 0.7970, 0.3965, 0.5842, 0.2741, 0.5255],\n",
       "        [0.6296, 0.4956, 0.1430, 0.8266, 0.5940, 0.7007, 0.2518, 0.1667],\n",
       "        [0.7255, 0.0080, 0.9489, 0.1894, 0.5512, 0.5293, 0.2753, 0.0508],\n",
       "        [0.0584, 0.3933, 0.1139, 0.7904, 0.3747, 0.3514, 0.7094, 0.1210],\n",
       "        [0.2017, 0.0492, 0.1117, 0.2658, 0.8969, 0.0542, 0.2911, 0.9022],\n",
       "        [0.3773, 0.9827, 0.1489, 0.0572, 0.9670, 0.2209, 0.4054, 0.3755],\n",
       "        [0.8901, 0.5765, 0.0042, 0.6808, 0.5876, 0.0787, 0.9588, 0.2276],\n",
       "        [0.7936, 0.0282, 0.0572, 0.2471, 0.8485, 0.9265, 0.1902, 0.8694]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.rand(8,8)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb5ae0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8**2) / (2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9179b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 8\n",
    "cols = 8\n",
    "block_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700f58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for b in range(rows//block_size):\n",
    "    print(b*block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a993ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = [b*block_size for b in range(rows//block_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68426c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ids = [b*block_size for b in range(cols//block_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce90261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a94fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_starts = list(itertools.product(row_ids, col_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c73c8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79cf59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5500, 0.6808],\n",
      "        [0.8853, 0.0787]])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for starts in block_starts:\n",
    "    block = mask[starts[0]:starts[0]+block_size, starts[1]:starts[1]+block_size]\n",
    "    print(block)\n",
    "    print(block.numel())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fc1a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d07f0f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5500, 0.6808, 0.0000, 0.0000, 0.3190, 0.4696, 0.1576, 0.5488],\n",
       "        [0.8853, 0.0787, 0.0000, 0.0000, 0.0588, 0.3720, 0.8529, 0.5314],\n",
       "        [0.5348, 0.5938, 0.3496, 0.1799, 0.9819, 0.6040, 0.5582, 0.3997],\n",
       "        [0.4339, 0.7161, 0.8938, 0.2811, 0.3184, 0.5575, 0.6046, 0.9316],\n",
       "        [0.0519, 0.7054, 0.1441, 0.0785, 0.2620, 0.7403, 0.8035, 0.4934],\n",
       "        [0.6501, 0.0503, 0.0231, 0.4434, 0.7548, 0.2351, 0.0118, 0.4432],\n",
       "        [0.6796, 0.2638, 0.6830, 0.9232, 0.9234, 0.0189, 0.7614, 0.2667],\n",
       "        [0.7023, 0.5816, 0.4335, 0.0157, 0.0692, 0.3074, 0.8151, 0.9757]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "545a9f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0046, 0.6940, 0.1306, 0.8281],\n",
       "        [0.0148, 0.0548, 0.3951, 0.5808],\n",
       "        [0.3264, 0.6692, 0.2732, 0.4666],\n",
       "        [0.0983, 0.0590, 0.1664, 0.3158]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((4,4), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58817836",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.var(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51d3f25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0705, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b22dec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0417,  0.0502, -0.0249,  0.0681],\n",
       "        [-0.0403, -0.0350,  0.0104,  0.0351],\n",
       "        [ 0.0012,  0.0469, -0.0059,  0.0199],\n",
       "        [-0.0292, -0.0344, -0.0201, -0.0002]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625b2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 2\n",
    "out_features = 8\n",
    "in_features = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49787659",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = [b*block_size for b in range(out_features//block_size)]\n",
    "# column indices where a block starts\n",
    "col_ids = [b*block_size for b in range(in_features//block_size)]\n",
    "    # cartesian product\n",
    "# each element is a tuple containing the top left position of each block\n",
    "block_starts = list(itertools.product(row_ids, col_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0137cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (0, 4),\n",
       " (0, 6),\n",
       " (2, 0),\n",
       " (2, 2),\n",
       " (2, 4),\n",
       " (2, 6),\n",
       " (4, 0),\n",
       " (4, 2),\n",
       " (4, 4),\n",
       " (4, 6),\n",
       " (6, 0),\n",
       " (6, 2),\n",
       " (6, 4),\n",
       " (6, 6)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b024a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for starts in block_starts:\n",
    "    # get a block\n",
    "    block = mask[starts[0]:starts[0]+block_size, starts[1]:starts[1]+block_size]\n",
    "    mask[starts[0]:starts[0]+block_size, starts[1]:starts[1]+block_size] = 0\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fe312e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.8972, 0.7970, 0.3965, 0.5842, 0.2741, 0.5255],\n",
       "        [0.0000, 0.0000, 0.1430, 0.8266, 0.5940, 0.7007, 0.2518, 0.1667],\n",
       "        [0.7255, 0.0080, 0.9489, 0.1894, 0.5512, 0.5293, 0.2753, 0.0508],\n",
       "        [0.0584, 0.3933, 0.1139, 0.7904, 0.3747, 0.3514, 0.7094, 0.1210],\n",
       "        [0.2017, 0.0492, 0.1117, 0.2658, 0.8969, 0.0542, 0.2911, 0.9022],\n",
       "        [0.3773, 0.9827, 0.1489, 0.0572, 0.9670, 0.2209, 0.4054, 0.3755],\n",
       "        [0.8901, 0.5765, 0.0042, 0.6808, 0.5876, 0.0787, 0.9588, 0.2276],\n",
       "        [0.7936, 0.0282, 0.0572, 0.2471, 0.8485, 0.9265, 0.1902, 0.8694]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11cecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e7c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained('/home/ujan/speech-processing/models/whisper/whisper-small-common_voice_13_0-sigmoied_threshold-pruned/pasted_checkpoint-5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40aeebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab1f4801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0000,  0.0000,  0.0000,  ..., -0.0388, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0231, -0.0000],\n",
       "        [-0.0249, -0.0000,  0.0000,  ..., -0.0173, -0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[7].self_attn.k_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95adb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoFeatureExtractor, AutoTokenizer, AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "from modeling_whisper_traceable import WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "model_name_or_path = 'openai/whisper-small'\n",
    "data_dir = 'mozilla-foundation/common_voice_11_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7965501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from mozilla-foundation/common_voice_11_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 10581it [00:00, 23742.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "print('loading dataset from {}'.format(data_dir))\n",
    "\n",
    "raw_datasets = load_dataset(data_dir, \"zh-CN\", split=\"test\", streaming=True)\n",
    "text_column_name = 'sentence'\n",
    "\n",
    "\n",
    "# model, tokenizer, feature extractor, processor\n",
    "\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #revision=args.model_revision,\n",
    "    #use_auth_token=True if args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    #cache_dir=args.cache_dir,\n",
    "    #use_fast=model_args.use_fast_tokenizer,\n",
    "    #revision=model_args.model_revision,\n",
    "    #use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "\n",
    "tokenizer.set_prefix_tokens(language='chinese', task='transcribe')\n",
    "\n",
    "\n",
    "    \n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path)\n",
    "\n",
    "\n",
    "dataset = raw_datasets\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "\n",
    "\n",
    "inputs = processor(\n",
    "    sample['audio'][\"array\"],\n",
    "    sampling_rate=feature_extractor.sampling_rate,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\")\n",
    "                \n",
    "input_features = inputs.input_features\n",
    "attention_mask = inputs.attention_mask\n",
    "decoder_input_ids = torch.tensor([model.config.decoder_start_token_id]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit output_ids = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92e58da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546 ms ± 85.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit output_ids = model_old.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "550bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 10581it [00:00, 11039.05it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(dataset))\n",
    "\n",
    "\n",
    "inputs = processor(\n",
    "    sample['audio'][\"array\"],\n",
    "    sampling_rate=feature_extractor.sampling_rate,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\")\n",
    "                \n",
    "input_features = inputs.input_features\n",
    "attention_mask = inputs.attention_mask\n",
    "decoder_input_ids = torch.tensor([model.config.decoder_start_token_id]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40e7502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824 ms ± 8.85 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit output_ids = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11d46b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791 ms ± 27.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit output_ids = model_old.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ad651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ca344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8965e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08956e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "from whisper_traceable_masked import MaskedWhisperForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86f1aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6415: UserWarning: disabled check : \n",
      "                attn_weights.size() == (bsz * self.num_heads, tgt_len, src_len) \n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6420: UserWarning: disabled check :\n",
      "                attn_output.size() == (bsz * self.num_heads, tgt_len, self.head_dim)\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6425: UserWarning: if passing in a tuple for encoder_outputs, wrap it in a BaseModelOutput when return_dict=True\n",
      "                before passing through model. As :\n",
      "                    encoder_outputs = BaseModelOutput(\n",
      "                    last_hidden_state=encoder_outputs[0],\n",
      "                    hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
      "                    attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
      "            )\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6434: UserWarning: clamping disabled in WhisperEncoderLayer.forward\n",
      "  warnings.warn('clamping disabled in WhisperEncoderLayer.forward')\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6435: UserWarning: disabled check : \n",
      "                if head_mask/cross_attn_head_mask has a correct number of layers specified\n",
      "            in WhisperDecoder.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6440: UserWarning: disabled check : \n",
      "                attention_mask.size() == (bsz, 1, tgt_len, src_len))\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6445: UserWarning: disabled check : \n",
      "                layer_head_mask.size() != (self.num_heads,)\n",
      "            in WhisperAttention.forward\n",
      "  warnings.warn(\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6450: UserWarning: prefix tuning disabled in WhisperAttention.forward\n",
      "  warnings.warn('prefix tuning disabled in WhisperAttention.forward')\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6451: UserWarning: _prepare_decoder_attention_mask wraped\n",
      "  warnings.warn('_prepare_decoder_attention_mask wraped')\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6452: UserWarning: gradient checkpointing not supported\n",
      "  warnings.warn('gradient checkpointing not supported')\n",
      "/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:6453: UserWarning: only greedy search supported for now\n",
      "  warnings.warn('only greedy search supported for now')\n",
      "Some weights of MaskedWhisperForConditionalGeneration were not initialized from the model checkpoint at /users/ujan/speech-processing/models/whisper/pasted_checkpoint-5000 and are newly initialized: ['model.encoder.layers.1.fc1.mask_scores', 'model.decoder.layers.9.fc2.mask_scores', 'model.decoder.layers.8.fc1.mask_scores', 'model.decoder.layers.8.self_attn.q_proj.mask_scores', 'model.encoder.layers.10.self_attn.out_proj.mask_scores', 'model.decoder.layers.8.fc2.mask_scores', 'model.encoder.layers.9.self_attn.k_proj.mask_scores', 'model.encoder.layers.11.self_attn.k_proj.mask_scores', 'model.encoder.layers.7.self_attn.out_proj.mask_scores', 'model.decoder.layers.0.fc1.mask_scores', 'model.decoder.layers.0.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.1.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.11.fc2.mask_scores', 'model.decoder.layers.6.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.2.encoder_attn.q_proj.mask_scores', 'model.encoder.layers.5.self_attn.k_proj.mask_scores', 'model.decoder.layers.7.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.7.self_attn.k_proj.mask_scores', 'model.decoder.layers.5.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.10.fc2.mask_scores', 'model.decoder.layers.8.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.5.self_attn.q_proj.mask_scores', 'model.encoder.layers.9.self_attn.out_proj.mask_scores', 'model.decoder.layers.2.self_attn.q_proj.mask_scores', 'model.encoder.layers.0.self_attn.q_proj.mask_scores', 'model.decoder.layers.11.self_attn.out_proj.mask_scores', 'model.decoder.layers.7.self_attn.q_proj.mask_scores', 'model.encoder.layers.4.self_attn.v_proj.mask_scores', 'model.decoder.layers.6.self_attn.out_proj.mask_scores', 'model.decoder.layers.7.self_attn.out_proj.mask_scores', 'model.encoder.layers.1.fc2.mask_scores', 'model.encoder.layers.6.self_attn.q_proj.mask_scores', 'model.decoder.layers.3.self_attn.out_proj.mask_scores', 'model.decoder.layers.9.fc1.mask_scores', 'model.decoder.layers.2.self_attn.out_proj.mask_scores', 'model.decoder.layers.10.self_attn.out_proj.mask_scores', 'model.encoder.layers.10.self_attn.v_proj.mask_scores', 'model.decoder.layers.7.encoder_attn.v_proj.mask_scores', 'model.encoder.layers.1.self_attn.out_proj.mask_scores', 'model.encoder.layers.8.self_attn.q_proj.mask_scores', 'model.encoder.layers.10.fc1.mask_scores', 'model.decoder.layers.2.encoder_attn.out_proj.mask_scores', 'model.decoder.layers.7.encoder_attn.out_proj.mask_scores', 'model.decoder.layers.3.self_attn.q_proj.mask_scores', 'model.decoder.layers.11.self_attn.q_proj.mask_scores', 'model.decoder.layers.9.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.3.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.2.self_attn.q_proj.mask_scores', 'model.encoder.layers.7.self_attn.k_proj.mask_scores', 'model.decoder.layers.3.encoder_attn.v_proj.mask_scores', 'model.encoder.layers.2.self_attn.out_proj.mask_scores', 'model.decoder.layers.11.fc1.mask_scores', 'model.decoder.layers.8.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.11.self_attn.k_proj.mask_scores', 'model.encoder.layers.8.fc1.mask_scores', 'model.encoder.layers.11.self_attn.v_proj.mask_scores', 'model.encoder.layers.0.self_attn.k_proj.mask_scores', 'model.decoder.layers.0.encoder_attn.k_proj.mask_scores', 'model.encoder.layers.3.self_attn.k_proj.mask_scores', 'model.decoder.layers.11.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.4.self_attn.out_proj.mask_scores', 'model.encoder.layers.10.self_attn.q_proj.mask_scores', 'model.decoder.layers.7.self_attn.v_proj.mask_scores', 'model.decoder.layers.0.self_attn.k_proj.mask_scores', 'model.encoder.layers.2.self_attn.k_proj.mask_scores', 'model.decoder.layers.8.self_attn.k_proj.mask_scores', 'model.decoder.layers.4.fc1.mask_scores', 'model.decoder.layers.11.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.9.self_attn.q_proj.mask_scores', 'model.encoder.layers.3.self_attn.q_proj.mask_scores', 'model.decoder.layers.10.self_attn.v_proj.mask_scores', 'model.decoder.layers.5.fc1.mask_scores', 'model.decoder.layers.0.fc2.mask_scores', 'model.decoder.layers.4.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.9.encoder_attn.k_proj.mask_scores', 'model.encoder.layers.11.fc1.mask_scores', 'model.decoder.layers.6.fc2.mask_scores', 'model.decoder.layers.7.fc1.mask_scores', 'model.decoder.layers.0.self_attn.q_proj.mask_scores', 'model.decoder.layers.4.self_attn.k_proj.mask_scores', 'model.encoder.layers.1.self_attn.v_proj.mask_scores', 'model.encoder.layers.11.self_attn.out_proj.mask_scores', 'model.decoder.layers.5.encoder_attn.v_proj.mask_scores', 'model.encoder.layers.9.fc2.mask_scores', 'model.decoder.layers.3.fc1.mask_scores', 'model.decoder.layers.10.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.4.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.3.self_attn.k_proj.mask_scores', 'model.decoder.layers.10.fc2.mask_scores', 'model.decoder.layers.8.encoder_attn.v_proj.mask_scores', 'model.encoder.layers.0.self_attn.out_proj.mask_scores', 'model.decoder.layers.5.fc2.mask_scores', 'model.decoder.layers.5.self_attn.out_proj.mask_scores', 'model.encoder.layers.3.self_attn.out_proj.mask_scores', 'model.encoder.layers.6.self_attn.k_proj.mask_scores', 'model.encoder.layers.3.fc2.mask_scores', 'model.encoder.layers.8.self_attn.k_proj.mask_scores', 'model.decoder.layers.9.self_attn.v_proj.mask_scores', 'model.decoder.layers.2.self_attn.v_proj.mask_scores', 'model.decoder.layers.6.self_attn.k_proj.mask_scores', 'model.decoder.layers.4.encoder_attn.q_proj.mask_scores', 'model.encoder.layers.6.fc1.mask_scores', 'model.encoder.layers.10.self_attn.k_proj.mask_scores', 'model.decoder.layers.1.self_attn.out_proj.mask_scores', 'model.decoder.layers.0.self_attn.out_proj.mask_scores', 'model.decoder.layers.4.self_attn.q_proj.mask_scores', 'model.encoder.layers.4.self_attn.k_proj.mask_scores', 'model.encoder.layers.1.self_attn.q_proj.mask_scores', 'model.encoder.layers.3.fc1.mask_scores', 'model.encoder.layers.0.fc1.mask_scores', 'model.decoder.layers.3.self_attn.v_proj.mask_scores', 'model.decoder.layers.5.self_attn.v_proj.mask_scores', 'model.encoder.layers.5.self_attn.q_proj.mask_scores', 'model.encoder.layers.7.self_attn.v_proj.mask_scores', 'model.encoder.layers.7.fc1.mask_scores', 'model.encoder.layers.6.self_attn.v_proj.mask_scores', 'model.decoder.layers.2.fc2.mask_scores', 'model.decoder.layers.6.encoder_attn.q_proj.mask_scores', 'model.encoder.layers.11.self_attn.q_proj.mask_scores', 'model.decoder.layers.1.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.2.fc1.mask_scores', 'model.decoder.layers.9.self_attn.k_proj.mask_scores', 'model.decoder.layers.5.self_attn.k_proj.mask_scores', 'model.decoder.layers.0.self_attn.v_proj.mask_scores', 'model.decoder.layers.3.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.11.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.11.self_attn.v_proj.mask_scores', 'model.encoder.layers.0.fc2.mask_scores', 'model.encoder.layers.8.self_attn.v_proj.mask_scores', 'model.decoder.layers.1.fc2.mask_scores', 'model.decoder.layers.5.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.10.encoder_attn.k_proj.mask_scores', 'model.encoder.layers.9.self_attn.q_proj.mask_scores', 'model.decoder.layers.1.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.0.encoder_attn.out_proj.mask_scores', 'model.decoder.layers.9.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.6.fc2.mask_scores', 'model.decoder.layers.1.self_attn.v_proj.mask_scores', 'model.encoder.layers.8.fc2.mask_scores', 'model.encoder.layers.5.self_attn.out_proj.mask_scores', 'model.decoder.layers.3.fc2.mask_scores', 'model.decoder.layers.10.self_attn.k_proj.mask_scores', 'model.encoder.layers.6.self_attn.out_proj.mask_scores', 'model.decoder.layers.6.self_attn.v_proj.mask_scores', 'model.decoder.layers.10.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.8.encoder_attn.out_proj.mask_scores', 'model.decoder.layers.6.encoder_attn.k_proj.mask_scores', 'model.encoder.layers.4.fc2.mask_scores', 'model.encoder.layers.5.fc1.mask_scores', 'model.encoder.layers.9.fc1.mask_scores', 'model.decoder.layers.1.self_attn.q_proj.mask_scores', 'model.encoder.layers.0.self_attn.v_proj.mask_scores', 'model.decoder.layers.6.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.2.self_attn.v_proj.mask_scores', 'model.decoder.layers.4.self_attn.v_proj.mask_scores', 'model.decoder.layers.8.self_attn.out_proj.mask_scores', 'model.decoder.layers.5.encoder_attn.k_proj.mask_scores', 'model.decoder.layers.1.self_attn.k_proj.mask_scores', 'model.decoder.layers.6.self_attn.q_proj.mask_scores', 'model.decoder.layers.4.encoder_attn.out_proj.mask_scores', 'model.decoder.layers.10.fc1.mask_scores', 'model.decoder.layers.9.self_attn.out_proj.mask_scores', 'model.encoder.layers.4.fc1.mask_scores', 'model.encoder.layers.5.fc2.mask_scores', 'model.decoder.layers.8.self_attn.v_proj.mask_scores', 'model.decoder.layers.10.self_attn.q_proj.mask_scores', 'model.decoder.layers.10.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.2.fc1.mask_scores', 'model.decoder.layers.11.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.7.encoder_attn.q_proj.mask_scores', 'model.decoder.layers.4.self_attn.out_proj.mask_scores', 'model.decoder.layers.1.fc1.mask_scores', 'model.decoder.layers.9.encoder_attn.v_proj.mask_scores', 'model.encoder.layers.9.self_attn.v_proj.mask_scores', 'model.encoder.layers.3.self_attn.v_proj.mask_scores', 'model.decoder.layers.0.encoder_attn.q_proj.mask_scores', 'model.encoder.layers.7.self_attn.q_proj.mask_scores', 'model.encoder.layers.1.self_attn.k_proj.mask_scores', 'model.encoder.layers.2.fc2.mask_scores', 'model.encoder.layers.7.fc2.mask_scores', 'model.encoder.layers.8.self_attn.out_proj.mask_scores', 'model.decoder.layers.7.fc2.mask_scores', 'model.decoder.layers.3.encoder_attn.q_proj.mask_scores', 'model.encoder.layers.4.self_attn.q_proj.mask_scores', 'model.decoder.layers.2.encoder_attn.v_proj.mask_scores', 'model.decoder.layers.6.fc1.mask_scores', 'model.decoder.layers.2.encoder_attn.k_proj.mask_scores', 'model.encoder.layers.5.self_attn.v_proj.mask_scores', 'model.decoder.layers.4.fc2.mask_scores', 'model.decoder.layers.1.encoder_attn.out_proj.mask_scores', 'model.encoder.layers.11.fc2.mask_scores', 'model.decoder.layers.2.self_attn.k_proj.mask_scores']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MaskedWhisperForConditionalGeneration.from_pretrained('/users/ujan/speech-processing/models/whisper/pasted_checkpoint-5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d485ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = model.config.encoder_layers\n",
    "\n",
    "for layer in n_layers:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff80b1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperAttention(\n",
       "  (k_proj): MaskedLinear(in_features=768, out_features=768, bias=False)\n",
       "  (v_proj): MaskedLinear(in_features=768, out_features=768, bias=True)\n",
       "  (q_proj): MaskedLinear(in_features=768, out_features=768, bias=True)\n",
       "  (out_proj): MaskedLinear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6533c94c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencoder\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mself_attn\u001b[39m.\u001b[39;49mprune_heads()\n",
      "File \u001b[0;32m/Users/ujan/speech-processing/experiments/notebooks/whisper_traceable_masked.py:1076\u001b[0m, in \u001b[0;36mWhisperAttention.prune_heads\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprune_linear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_index(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj, heads))\n\u001b[1;32m   1075\u001b[0m \u001b[39m# add to pruned_heads\u001b[39;00m\n\u001b[0;32m-> 1076\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprune_heads\u001b[39m.\u001b[39;49mupdate(heads)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "model.model.encoder.layers[0].self_attn.prune_heads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba648da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9039afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feb95f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([576, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].self_attn.q_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f60ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[1].self_attn.q_proj.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ac312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[1].self_attn.k_proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82bd51f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3454,  0.2567, -0.0577, -0.0531,  0.2629, -0.2770,  0.1651,  0.2354],\n",
       "        [ 0.0246,  0.1383, -0.1844,  0.2265,  0.2167,  0.1436, -0.2143,  0.2890],\n",
       "        [-0.1389,  0.1298, -0.1271,  0.3178,  0.2265,  0.2532,  0.2212,  0.1376],\n",
       "        [-0.0266, -0.1038,  0.1442,  0.0910,  0.1162,  0.2033,  0.1470,  0.2200],\n",
       "        [-0.0706, -0.0356,  0.1770, -0.3168,  0.0240, -0.2727,  0.1274,  0.1433],\n",
       "        [-0.2800, -0.2679, -0.3011, -0.1833,  0.1450, -0.1462,  0.3520, -0.1301],\n",
       "        [ 0.0195, -0.0116,  0.2186, -0.2406,  0.2759,  0.2960,  0.1356, -0.1104],\n",
       "        [ 0.0513,  0.2382,  0.2592, -0.0341, -0.1410,  0.0554,  0.3369, -0.0965]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(8,8)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fa43909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "num_heads = 4\n",
    "head_dim = 2\n",
    "to_prune = set()\n",
    "\n",
    "mask = torch.ones(num_heads, head_dim)\n",
    "heads = set([h for h in range(num_heads)])\n",
    "        \n",
    "for h in heads:\n",
    "    head = linear.weight[h*head_dim:(h+1)*head_dim, :]\n",
    "    if h in to_prune:\n",
    "        mask[h] = 0\n",
    "mask = mask.view(-1).contiguous().eq(1)\n",
    "index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d230bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d1e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_layer1 = model.model.encoder.layers[1].self_attn.k_proj.weight\n",
    "q_layer1 = model.model.encoder.layers[1].self_attn.q_proj.weight\n",
    "v_layer1 = model.model.encoder.layers[1].self_attn.v_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce86772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7455)\n",
      "tensor(0.9654)\n",
      "tensor(0.9864)\n",
      "tensor(1.)\n",
      "tensor(0.8030)\n",
      "tensor(1.)\n",
      "tensor(0.9452)\n",
      "tensor(0.8397)\n",
      "tensor(0.7087)\n",
      "tensor(0.6654)\n",
      "tensor(0.8525)\n",
      "tensor(0.7038)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7362)\n",
      "tensor(0.9858)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.4410)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7257)\n",
      "tensor(1.)\n",
      "tensor(0.6535)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7759)\n",
      "tensor(1.)\n",
      "tensor(0.6208)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.4448)\n",
      "tensor(0.9890)\n",
      "tensor(1.)\n",
      "tensor(0.9978)\n",
      "tensor(0.8692)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.6554)\n",
      "tensor(1.)\n",
      "tensor(0.7717)\n",
      "tensor(1.)\n",
      "tensor(0.5163)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7433)\n",
      "tensor(1.)\n",
      "tensor(0.6294)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.6755)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.6428)\n",
      "tensor(0.8654)\n",
      "tensor(0.7953)\n",
      "tensor(1.)\n",
      "tensor(0.8784)\n",
      "tensor(0.8297)\n",
      "tensor(1.)\n",
      "tensor(0.9419)\n",
      "tensor(1.)\n",
      "tensor(0.6383)\n",
      "tensor(0.8304)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.8135)\n",
      "tensor(0.9977)\n",
      "tensor(0.9318)\n",
      "tensor(0.3383)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7586)\n",
      "tensor(0.7920)\n",
      "tensor(1.)\n",
      "tensor(0.6876)\n",
      "tensor(0.8316)\n",
      "tensor(0.6417)\n",
      "tensor(0.4347)\n",
      "tensor(0.9956)\n",
      "tensor(0.6779)\n",
      "tensor(0.6284)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.6094)\n",
      "tensor(1.)\n",
      "tensor(0.8250)\n",
      "tensor(1.)\n",
      "tensor(0.6144)\n",
      "tensor(1.)\n",
      "tensor(0.9165)\n",
      "tensor(1.)\n",
      "tensor(0.7810)\n",
      "tensor(1.)\n",
      "tensor(0.6867)\n",
      "tensor(0.5583)\n",
      "tensor(0.8609)\n",
      "tensor(0.7999)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.8517)\n",
      "tensor(0.9936)\n",
      "tensor(0.9166)\n",
      "tensor(1.)\n",
      "tensor(0.7632)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.8344)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12\n",
    "head_size = 64\n",
    "already_pruned_heads = set()\n",
    "\n",
    "for l in range(n_layers):\n",
    "    k_layer = model.model.decoder.layers[l].self_attn.k_proj.weight\n",
    "    for i in range(n_heads):\n",
    "        head = k_layer[i*head_size:(i+1)*head_size, :]\n",
    "        total = head.numel()\n",
    "        zeros = total - torch.count_nonzero(head)\n",
    "        sparsity = zeros/total\n",
    "        print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a137bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0\n",
      "tensor(0.9714)\n",
      "tensor(0.9603)\n",
      "tensor(0.8516)\n",
      "tensor(1.)\n",
      "tensor(0.9751)\n",
      "tensor(0.9912)\n",
      "tensor(0.9149)\n",
      "tensor(0.9273)\n",
      "tensor(1.)\n",
      "tensor(0.9689)\n",
      "tensor(1.)\n",
      "tensor(0.9643)\n",
      "layer : 1\n",
      "tensor(0.7510)\n",
      "tensor(0.9695)\n",
      "tensor(0.8671)\n",
      "tensor(0.8711)\n",
      "tensor(1.)\n",
      "tensor(0.6916)\n",
      "tensor(0.9636)\n",
      "tensor(0.7287)\n",
      "tensor(1.)\n",
      "tensor(0.7927)\n",
      "tensor(0.9893)\n",
      "tensor(0.9953)\n",
      "layer : 2\n",
      "tensor(0.8669)\n",
      "tensor(0.8287)\n",
      "tensor(1.)\n",
      "tensor(0.9455)\n",
      "tensor(0.9921)\n",
      "tensor(0.7903)\n",
      "tensor(0.9809)\n",
      "tensor(0.9854)\n",
      "tensor(0.9890)\n",
      "tensor(1.)\n",
      "tensor(0.7553)\n",
      "tensor(0.8355)\n",
      "layer : 3\n",
      "tensor(0.6078)\n",
      "tensor(1.)\n",
      "tensor(0.9950)\n",
      "tensor(1.)\n",
      "tensor(0.8508)\n",
      "tensor(1.)\n",
      "tensor(0.7106)\n",
      "tensor(0.7519)\n",
      "tensor(0.6570)\n",
      "tensor(0.8331)\n",
      "tensor(0.9931)\n",
      "tensor(0.9432)\n",
      "layer : 4\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.7614)\n",
      "tensor(1.)\n",
      "tensor(0.5511)\n",
      "tensor(0.5278)\n",
      "tensor(0.6949)\n",
      "tensor(1.)\n",
      "tensor(0.9240)\n",
      "tensor(0.4983)\n",
      "tensor(0.5682)\n",
      "tensor(0.6837)\n",
      "layer : 5\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.8177)\n",
      "tensor(0.6369)\n",
      "tensor(0.6723)\n",
      "tensor(1.)\n",
      "tensor(0.8766)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(0.8345)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "layer : 6\n",
      "tensor(1.)\n",
      "tensor(0.8228)\n",
      "tensor(0.7293)\n",
      "tensor(0.7039)\n",
      "tensor(0.9908)\n",
      "tensor(0.7575)\n",
      "tensor(0.4220)\n",
      "tensor(0.8871)\n",
      "tensor(0.8705)\n",
      "tensor(0.5867)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "layer : 7\n",
      "tensor(0.8130)\n",
      "tensor(0.5890)\n",
      "tensor(0.7473)\n",
      "tensor(0.8309)\n",
      "tensor(0.9909)\n",
      "tensor(1.)\n",
      "tensor(0.6680)\n",
      "tensor(0.7936)\n",
      "tensor(0.7942)\n",
      "tensor(1.)\n",
      "tensor(0.6106)\n",
      "tensor(1.)\n",
      "layer : 8\n",
      "tensor(0.5691)\n",
      "tensor(0.7509)\n",
      "tensor(1.)\n",
      "tensor(0.7449)\n",
      "tensor(0.8974)\n",
      "tensor(0.5091)\n",
      "tensor(0.6912)\n",
      "tensor(0.5469)\n",
      "tensor(0.6064)\n",
      "tensor(0.6243)\n",
      "tensor(0.9976)\n",
      "tensor(0.9771)\n",
      "layer : 9\n",
      "tensor(0.4999)\n",
      "tensor(0.5130)\n",
      "tensor(0.6741)\n",
      "tensor(0.5895)\n",
      "tensor(0.9022)\n",
      "tensor(0.6666)\n",
      "tensor(0.7118)\n",
      "tensor(0.8116)\n",
      "tensor(0.8801)\n",
      "tensor(0.7242)\n",
      "tensor(0.5946)\n",
      "tensor(0.9612)\n",
      "layer : 10\n",
      "tensor(0.8899)\n",
      "tensor(0.5824)\n",
      "tensor(0.8266)\n",
      "tensor(0.5424)\n",
      "tensor(0.5663)\n",
      "tensor(0.7864)\n",
      "tensor(0.5569)\n",
      "tensor(0.9470)\n",
      "tensor(0.8055)\n",
      "tensor(0.4797)\n",
      "tensor(0.8277)\n",
      "tensor(0.5929)\n",
      "layer : 11\n",
      "tensor(0.7325)\n",
      "tensor(0.7517)\n",
      "tensor(0.6318)\n",
      "tensor(0.8698)\n",
      "tensor(0.4954)\n",
      "tensor(0.5175)\n",
      "tensor(0.6130)\n",
      "tensor(0.6103)\n",
      "tensor(0.7309)\n",
      "tensor(0.5653)\n",
      "tensor(0.8565)\n",
      "tensor(0.7969)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12\n",
    "head_size = 64\n",
    "already_pruned_heads = set()\n",
    "\n",
    "for l in range(n_layers):\n",
    "    print('layer : {}'.format(l))\n",
    "    q_layer = model.model.encoder.layers[l].self_attn.q_proj.weight\n",
    "    for i in range(n_heads):\n",
    "        head = q_layer[i*head_size:(i+1)*head_size, :]\n",
    "        total = head.numel()\n",
    "        zeros = total - torch.count_nonzero(head)\n",
    "        sparsity = zeros/total\n",
    "        print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24df19cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4625)\n",
      "tensor(0.4472)\n",
      "tensor(0.4431)\n",
      "tensor(0.8786)\n",
      "tensor(0.7661)\n",
      "tensor(0.8391)\n",
      "tensor(0.6809)\n",
      "tensor(0.4908)\n",
      "tensor(0.9108)\n",
      "tensor(0.6605)\n",
      "tensor(0.8629)\n",
      "tensor(0.6276)\n",
      "tensor(0.3697)\n",
      "tensor(0.5136)\n",
      "tensor(0.8359)\n",
      "tensor(0.7241)\n",
      "tensor(0.7291)\n",
      "tensor(0.5412)\n",
      "tensor(0.4911)\n",
      "tensor(0.4878)\n",
      "tensor(0.7707)\n",
      "tensor(0.7071)\n",
      "tensor(0.6876)\n",
      "tensor(0.7410)\n",
      "tensor(0.3993)\n",
      "tensor(0.6327)\n",
      "tensor(0.8552)\n",
      "tensor(0.6821)\n",
      "tensor(0.5311)\n",
      "tensor(0.3423)\n",
      "tensor(0.5159)\n",
      "tensor(0.7433)\n",
      "tensor(0.5492)\n",
      "tensor(0.7879)\n",
      "tensor(0.5088)\n",
      "tensor(0.5048)\n",
      "tensor(0.5351)\n",
      "tensor(0.6059)\n",
      "tensor(0.5570)\n",
      "tensor(0.7144)\n",
      "tensor(0.5277)\n",
      "tensor(0.6843)\n",
      "tensor(0.3028)\n",
      "tensor(0.3588)\n",
      "tensor(0.5780)\n",
      "tensor(0.4945)\n",
      "tensor(0.6114)\n",
      "tensor(0.5747)\n",
      "tensor(0.6831)\n",
      "tensor(0.6459)\n",
      "tensor(0.5558)\n",
      "tensor(0.6756)\n",
      "tensor(0.2450)\n",
      "tensor(0.4767)\n",
      "tensor(0.2567)\n",
      "tensor(0.6924)\n",
      "tensor(0.6011)\n",
      "tensor(0.4140)\n",
      "tensor(0.3891)\n",
      "tensor(0.6047)\n",
      "tensor(0.6923)\n",
      "tensor(0.7292)\n",
      "tensor(0.2492)\n",
      "tensor(0.2012)\n",
      "tensor(0.2346)\n",
      "tensor(0.7342)\n",
      "tensor(0.3638)\n",
      "tensor(0.7467)\n",
      "tensor(0.7087)\n",
      "tensor(0.4589)\n",
      "tensor(0.7386)\n",
      "tensor(0.7067)\n",
      "tensor(0.6356)\n",
      "tensor(0.5446)\n",
      "tensor(0.4708)\n",
      "tensor(0.4093)\n",
      "tensor(0.6586)\n",
      "tensor(0.5698)\n",
      "tensor(0.3084)\n",
      "tensor(0.6343)\n",
      "tensor(0.4923)\n",
      "tensor(0.5088)\n",
      "tensor(0.6068)\n",
      "tensor(0.7272)\n",
      "tensor(0.2398)\n",
      "tensor(0.1821)\n",
      "tensor(0.2995)\n",
      "tensor(0.5869)\n",
      "tensor(0.6924)\n",
      "tensor(0.7639)\n",
      "tensor(0.2043)\n",
      "tensor(0.3081)\n",
      "tensor(0.6129)\n",
      "tensor(0.8566)\n",
      "tensor(0.1764)\n",
      "tensor(0.8691)\n",
      "tensor(0.2316)\n",
      "tensor(0.6609)\n",
      "tensor(0.8706)\n",
      "tensor(0.2496)\n",
      "tensor(0.8362)\n",
      "tensor(0.3604)\n",
      "tensor(0.5339)\n",
      "tensor(0.3052)\n",
      "tensor(0.2138)\n",
      "tensor(0.5895)\n",
      "tensor(0.8837)\n",
      "tensor(0.7770)\n",
      "tensor(0.2093)\n",
      "tensor(0.2581)\n",
      "tensor(0.3507)\n",
      "tensor(0.2476)\n",
      "tensor(0.5224)\n",
      "tensor(0.4492)\n",
      "tensor(0.4379)\n",
      "tensor(0.8136)\n",
      "tensor(0.4820)\n",
      "tensor(0.6877)\n",
      "tensor(0.3258)\n",
      "tensor(0.7258)\n",
      "tensor(0.6525)\n",
      "tensor(0.5516)\n",
      "tensor(0.8164)\n",
      "tensor(0.2225)\n",
      "tensor(0.3895)\n",
      "tensor(0.5227)\n",
      "tensor(0.5434)\n",
      "tensor(0.7921)\n",
      "tensor(0.5552)\n",
      "tensor(0.2259)\n",
      "tensor(0.8139)\n",
      "tensor(0.2871)\n",
      "tensor(0.5726)\n",
      "tensor(0.6874)\n",
      "tensor(0.5472)\n",
      "tensor(0.7878)\n",
      "tensor(0.2211)\n",
      "tensor(0.1937)\n",
      "tensor(0.2582)\n",
      "tensor(0.3549)\n",
      "tensor(0.4246)\n",
      "tensor(0.2377)\n",
      "tensor(0.7738)\n",
      "tensor(0.5494)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12\n",
    "head_size = 64\n",
    "already_pruned_heads = set()\n",
    "\n",
    "for l in range(n_layers):\n",
    "    v_layer = model.model.encoder.layers[l].self_attn.v_proj.weight\n",
    "    for i in range(n_heads):\n",
    "        head = v_layer[i*head_size:(i+1)*head_size, :]\n",
    "        total = head.numel()\n",
    "        zeros = total - torch.count_nonzero(head)\n",
    "        sparsity = zeros/total\n",
    "        print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "231d837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8086)\n",
      "tensor(0.6119)\n",
      "tensor(0.4512)\n",
      "tensor(0.4485)\n",
      "tensor(0.4539)\n",
      "tensor(0.4476)\n",
      "tensor(0.8197)\n",
      "tensor(0.6311)\n",
      "tensor(0.4425)\n",
      "tensor(0.4436)\n",
      "tensor(0.4609)\n",
      "tensor(0.4526)\n",
      "tensor(0.9095)\n",
      "tensor(0.6590)\n",
      "tensor(0.4678)\n",
      "tensor(0.4511)\n",
      "tensor(0.4526)\n",
      "tensor(0.4417)\n",
      "tensor(0.9384)\n",
      "tensor(0.6940)\n",
      "tensor(0.4548)\n",
      "tensor(0.4651)\n",
      "tensor(0.4572)\n",
      "tensor(0.4412)\n",
      "tensor(0.9299)\n",
      "tensor(0.5874)\n",
      "tensor(0.4279)\n",
      "tensor(0.4069)\n",
      "tensor(0.4068)\n",
      "tensor(0.4001)\n",
      "tensor(0.9325)\n",
      "tensor(0.6125)\n",
      "tensor(0.4133)\n",
      "tensor(0.4331)\n",
      "tensor(0.4149)\n",
      "tensor(0.3923)\n",
      "tensor(0.9012)\n",
      "tensor(0.5565)\n",
      "tensor(0.4042)\n",
      "tensor(0.3927)\n",
      "tensor(0.3915)\n",
      "tensor(0.3901)\n",
      "tensor(0.9177)\n",
      "tensor(0.5742)\n",
      "tensor(0.3948)\n",
      "tensor(0.4167)\n",
      "tensor(0.4022)\n",
      "tensor(0.3781)\n",
      "tensor(0.8282)\n",
      "tensor(0.5499)\n",
      "tensor(0.4147)\n",
      "tensor(0.4138)\n",
      "tensor(0.4132)\n",
      "tensor(0.4114)\n",
      "tensor(0.8232)\n",
      "tensor(0.5596)\n",
      "tensor(0.4136)\n",
      "tensor(0.4392)\n",
      "tensor(0.4216)\n",
      "tensor(0.4023)\n",
      "tensor(0.8116)\n",
      "tensor(0.5459)\n",
      "tensor(0.4593)\n",
      "tensor(0.4552)\n",
      "tensor(0.4488)\n",
      "tensor(0.4414)\n",
      "tensor(0.8241)\n",
      "tensor(0.5478)\n",
      "tensor(0.4561)\n",
      "tensor(0.4710)\n",
      "tensor(0.4520)\n",
      "tensor(0.4409)\n",
      "tensor(0.8485)\n",
      "tensor(0.5695)\n",
      "tensor(0.4453)\n",
      "tensor(0.4503)\n",
      "tensor(0.4400)\n",
      "tensor(0.4406)\n",
      "tensor(0.8550)\n",
      "tensor(0.5775)\n",
      "tensor(0.4523)\n",
      "tensor(0.4676)\n",
      "tensor(0.4460)\n",
      "tensor(0.4385)\n",
      "tensor(0.5453)\n",
      "tensor(0.4830)\n",
      "tensor(0.4535)\n",
      "tensor(0.4483)\n",
      "tensor(0.4487)\n",
      "tensor(0.4519)\n",
      "tensor(0.5538)\n",
      "tensor(0.4893)\n",
      "tensor(0.4566)\n",
      "tensor(0.4634)\n",
      "tensor(0.4464)\n",
      "tensor(0.4456)\n",
      "tensor(0.5954)\n",
      "tensor(0.5318)\n",
      "tensor(0.5049)\n",
      "tensor(0.5091)\n",
      "tensor(0.5070)\n",
      "tensor(0.5072)\n",
      "tensor(0.6108)\n",
      "tensor(0.5440)\n",
      "tensor(0.5127)\n",
      "tensor(0.5181)\n",
      "tensor(0.5016)\n",
      "tensor(0.5084)\n",
      "tensor(0.4295)\n",
      "tensor(0.3933)\n",
      "tensor(0.3709)\n",
      "tensor(0.3730)\n",
      "tensor(0.3722)\n",
      "tensor(0.3732)\n",
      "tensor(0.4290)\n",
      "tensor(0.4016)\n",
      "tensor(0.3813)\n",
      "tensor(0.4046)\n",
      "tensor(0.3691)\n",
      "tensor(0.3713)\n",
      "tensor(0.5005)\n",
      "tensor(0.4713)\n",
      "tensor(0.4628)\n",
      "tensor(0.4536)\n",
      "tensor(0.4625)\n",
      "tensor(0.4548)\n",
      "tensor(0.5082)\n",
      "tensor(0.4843)\n",
      "tensor(0.4634)\n",
      "tensor(0.4756)\n",
      "tensor(0.4523)\n",
      "tensor(0.4573)\n",
      "tensor(0.4145)\n",
      "tensor(0.3826)\n",
      "tensor(0.3966)\n",
      "tensor(0.3841)\n",
      "tensor(0.3945)\n",
      "tensor(0.3916)\n",
      "tensor(0.4233)\n",
      "tensor(0.4073)\n",
      "tensor(0.3976)\n",
      "tensor(0.4019)\n",
      "tensor(0.3851)\n",
      "tensor(0.3919)\n"
     ]
    }
   ],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12\n",
    "head_size = 64\n",
    "already_pruned_heads = set()\n",
    "\n",
    "for l in range(n_layers):\n",
    "    out_layer = model.model.encoder.layers[l].self_attn.out_proj.weight\n",
    "    for i in range(n_heads):\n",
    "        head = out_layer[i*head_size:(i+1)*head_size, :]\n",
    "        total = head.numel()\n",
    "        zeros = total - torch.count_nonzero(head)\n",
    "        sparsity = zeros/total\n",
    "        print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda3930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb0e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 256, 257, 258, 259,\n",
      "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
      "        274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
      "        288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
      "        302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "        316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "        330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
      "        344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
      "        358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371,\n",
      "        372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
      "        386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399,\n",
      "        400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n",
      "        414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427,\n",
      "        428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
      "        456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
      "        470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
      "        484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "        498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "        576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
      "        590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "        604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617,\n",
      "        618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
      "        632, 633, 634, 635, 636, 637, 638, 639, 704, 705, 706, 707, 708, 709,\n",
      "        710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723,\n",
      "        724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737,\n",
      "        738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751,\n",
      "        752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765,\n",
      "        766, 767])\n"
     ]
    }
   ],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12\n",
    "head_size = 64\n",
    "\n",
    "for l in range(n_layers):\n",
    "    mask = torch.ones(n_heads, head_size)\n",
    "    k_layer = model.model.encoder.layers[l].self_attn.k_proj.weight\n",
    "    for i in range(n_heads):\n",
    "        head = k_layer[i*head_size:(i+1)*head_size, :]\n",
    "        total = head.numel()\n",
    "        zeros = total - torch.count_nonzero(head)\n",
    "        sparsity = zeros/total\n",
    "        if sparsity == 1:\n",
    "            mask[i] = 0\n",
    "        \n",
    "    mask = mask.view(-1).contiguous().eq(1)\n",
    "    index: torch.LongTensor = torch.arange(len(mask))[mask].long()\n",
    "    print(index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24667906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.Softmax(dim=1)\n",
    "#input = torch.randn(2, 3)\n",
    "input = torch.zeros(2, 4)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda25e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 3, 4, 6, 7, 8, 9, 10, 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_pruned_heads = set([2,5])\n",
    "heads = set([h for h in range(12)]) - already_pruned_heads\n",
    "heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde070dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for head in heads:\n",
    "    # Compute how many pruned heads are before the head and move the index accordingly\n",
    "    head = head - sum(1 if h < head else 0 for h in already_pruned_heads)\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504ba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20168b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "def prune_linear_layer(layer: nn.Linear, index: torch.LongTensor, dim: int = 0) -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Prune a linear layer to keep only entries in index.\n",
    "\n",
    "    Used to remove heads.\n",
    "\n",
    "    Args:\n",
    "        layer (`torch.nn.Linear`): The layer to prune.\n",
    "        index (`torch.LongTensor`): The indices to keep in the layer.\n",
    "        dim (`int`, *optional*, defaults to 0): The dimension on which to keep the indices.\n",
    "\n",
    "    Returns:\n",
    "        `torch.nn.Linear`: The pruned layer as a new layer with `requires_grad=True`.\n",
    "    \"\"\"\n",
    "    index = index.to(layer.weight.device)\n",
    "    W = layer.weight.index_select(dim, index).clone().detach()\n",
    "    if layer.bias is not None:\n",
    "        if dim == 1:\n",
    "            b = layer.bias.clone().detach()\n",
    "        else:\n",
    "            b = layer.bias[index].clone().detach()\n",
    "    new_size = list(layer.weight.size())\n",
    "    new_size[dim] = len(index)\n",
    "    new_layer = nn.Linear(new_size[1], new_size[0], bias=layer.bias is not None).to(layer.weight.device)\n",
    "    new_layer.weight.requires_grad = False\n",
    "    new_layer.weight.copy_(W.contiguous())\n",
    "    new_layer.weight.requires_grad = True\n",
    "    if layer.bias is not None:\n",
    "        new_layer.bias.requires_grad = False\n",
    "        new_layer.bias.copy_(b.contiguous())\n",
    "        new_layer.bias.requires_grad = True\n",
    "    return new_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43170f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ddc547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640f600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8dd43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a2a2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = torch.rand(10000)\n",
    "a_dist = m(a)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(a_dist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb77daf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8044, 0.8632, 0.5470,  ..., 0.4942, 0.9625, 0.3417],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.rand(10000))\n",
    "w1 = Variable(p, requires_grad=True)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9d494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_dist = m(p)\n",
    "plt.plot(p_dist.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c60f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e5\n",
    "for t in range(150):\n",
    "    \n",
    "    input = F.log_softmax(w1, dim=0)\n",
    "    log_target = F.log_softmax(a, dim=0)\n",
    "\n",
    "    loss = -kl_loss(input, log_target)\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "\n",
    "    #print(w1.data)\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f62677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_dist = m(p)\n",
    "plt.plot(p_dist.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb6049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e915c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee1103bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "from re import L\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from transformers.utils import logging\n",
    "\n",
    "limit_a, limit_b, epsilon = -.1, 1.1, 1e-6\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "class L0Module(Module):\n",
    "    def __init__(self,\n",
    "                 config, \n",
    "                 droprate_init=0.5,\n",
    "                 temperature=2./3.,\n",
    "                 lagrangian_warmup=0,\n",
    "                 start_sparsity=0.0,\n",
    "                 target_sparsity=0.0,\n",
    "                 pruning_type=\"structured_heads+structured_mlp+hidden+layer\",\n",
    "                 magical_number=0.8, # from Wang et al. 2020\n",
    "                 ):\n",
    "        super(L0Module, self).__init__()\n",
    "        self.all_types = [\"hidden_z\", \"intermediate_z\", \"mlp_z\", \"head_layer_z\", \"head_z\"]\n",
    "        self.pruning_type = pruning_type\n",
    "        \n",
    "        # model parameters\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.d_model = config.d_model  # hidden_size\n",
    "        self.encoder_layers = config.encoder_layers\n",
    "        self.encoder_attention_heads = config.encoder_attention_heads  # num_attention_heads\n",
    "        self.decoder_layers = config.decoder_layers\n",
    "        self.decoder_attention_heads = config.decoder_attention_heads  # num_attention_heads\n",
    "        self.decoder_ffn_dim = config.decoder_ffn_dim  # intermediate_size\n",
    "        self.encoder_ffn_dim = config.encoder_ffn_dim  # intermediate_size\n",
    "        self.num_hidden_layers = config.encoder_layers\n",
    "        self.mlp_num_per_layer = 1  # linear -> activation -> linear\n",
    "        self.dim_per_encoder_head = self.d_model // self.encoder_attention_heads\n",
    "        self.dim_per_decoder_head = self.d_model // self.decoder_attention_heads\n",
    "\n",
    "        # same number of heads, head size for encoder, decoder \n",
    "        self.params_per_head_layer = self.d_model * self.d_model * 4  # + self.d_model * 4\n",
    "        self.params_per_head =  self.params_per_head_layer // self.encoder_attention_heads\n",
    "        \n",
    "        # same intermediate size for encoder, decoder\n",
    "        self.params_per_mlp_layer = self.d_model * config.encoder_ffn_dim * 2  # + self.d_model + self.d_model * 4\n",
    "        self.params_per_encoder_ffn_dim = self.params_per_mlp_layer // self.encoder_ffn_dim\n",
    "\n",
    "        # we ignore the parameters in normalization layers (it takes a very small amount)\n",
    "        self.full_model_size = (self.params_per_head_layer + self.params_per_mlp_layer) * self.num_hidden_layers\n",
    "        self.prunable_model_size = 0 \n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.droprate_init = droprate_init if droprate_init != 0. else 0.5\n",
    "        \n",
    "        self.types = []\n",
    "        self.z_logas = {}\n",
    "        self.parameters_per_dim = {}\n",
    "        self.sizes = {}\n",
    "        self.shapes = {}\n",
    "\n",
    "        self.hidden_loga = None\n",
    "        self.hidden_type = None\n",
    "\n",
    "        types = self.pruning_type.split(\"+\")\n",
    "        for type in types:\n",
    "            if type != \"layer\":\n",
    "                self.initialize_one_module(type)\n",
    "        if \"layer\" in types:\n",
    "            self.initialize_one_module(\"layer\")\n",
    "\n",
    "        self.magical_number = magical_number\n",
    "\n",
    "        self.lambda_1 = torch.nn.Parameter(torch.tensor(0.0))\n",
    "        self.lambda_2 = torch.nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        self.lagrangian_warmup = lagrangian_warmup\n",
    "        self.start_sparsity = start_sparsity\n",
    "        self.target_sparsity = target_sparsity\n",
    "\n",
    "        logger.info(\"********** Initializing L0 Module **********\") \n",
    "        for type in self.types:\n",
    "            logger.info(f\"***** {type} *****\")\n",
    "            logger.info(f\"z.shape\", self.z_logas[type].shape)\n",
    "            logger.info(f\"size\", self.sizes[type])\n",
    "        logger.info(f\"prunable model size: {self.prunable_model_size}\")\n",
    "\n",
    "    def set_lagrangian_warmup_steps(self, lagrangian_warmup):\n",
    "        self.lagrangian_warmup = lagrangian_warmup\n",
    "\n",
    "    def initialize_one_module(self, module_name):\n",
    "        if module_name == \"structured_mlp\":\n",
    "            self.initialize_structured_mlp()\n",
    "        elif module_name == \"structured_heads\":\n",
    "            self.initialize_structured_head()\n",
    "        elif module_name == \"hidden\":\n",
    "            self.initialize_hidden()\n",
    "        elif module_name == \"layer\":\n",
    "            self.initialize_whole_mlp()\n",
    "            self.initialized_layer_structured_heads()\n",
    "            \n",
    "    def add_one_module(self, z_loga, type, parameter_per_dim, size, shape): #! init the z_logas\n",
    "        self.types.append(type)\n",
    "        self.z_logas[type] = z_loga\n",
    "        self.parameters_per_dim[type] = parameter_per_dim\n",
    "        self.sizes[type] = size\n",
    "        self.shapes[type] = shape\n",
    "\n",
    "    def initialize_parameters(self, size, num_layer=None):\n",
    "        if num_layer is not None:\n",
    "            return Parameter(torch.Tensor(num_layer, size))\n",
    "        else:\n",
    "            return Parameter(torch.Tensor(size))\n",
    "\n",
    "    def initialize_hidden(self):\n",
    "        self.hidden_loga = self.initialize_parameters(self.d_model)\n",
    "        self.add_one_module(self.hidden_loga, type=\"hidden\", \n",
    "                            parameter_per_dim=self.d_model * 4 + self.d_model* 4 * 2,\n",
    "                            size=self.d_model, shape=[self.d_model])\n",
    "        self.reset_loga(self.hidden_loga, mean=10)\n",
    "        logger.info(f\"Initialized hidden loga! Prunable_model_size = {self.prunable_model_size}\")\n",
    "\n",
    "    def initialize_structured_head(self, add_prunable_model_size=True):\n",
    "        self.head_loga = self.initialize_parameters(self.encoder_attention_heads, self.num_hidden_layers)\n",
    "        self.reset_loga(self.head_loga, mean=10)\n",
    "        self.add_one_module(self.head_loga, type=\"head\", \n",
    "                            parameter_per_dim=self.params_per_head, size=self.encoder_attention_heads,\n",
    "                            shape=[self.num_hidden_layers, 1, self.encoder_attention_heads, 1, 1])\n",
    "        if add_prunable_model_size:\n",
    "            self.prunable_model_size += self.params_per_head * self.num_hidden_layers * self.encoder_attention_heads\n",
    "        logger.info(f\"Initialized structured heads! Prunable_model_size = {self.prunable_model_size}\")\n",
    "\n",
    "    def initialized_layer_structured_heads(self):\n",
    "        n_layer = self.num_hidden_layers\n",
    "        self.headlayer_loga = self.initialize_parameters(n_layer)\n",
    "        self.reset_loga(self.headlayer_loga, mean=10)\n",
    "        self.add_one_module(self.headlayer_loga, type=\"head_layer\", \n",
    "                            parameter_per_dim=self.params_per_head * self.encoder_attention_heads, size=1,\n",
    "                            shape=[n_layer])\n",
    "        logger.info(f\"Initialized layerwise structured heads! Prunable_model_size = {self.prunable_model_size}\")\n",
    "\n",
    "    def initialize_structured_mlp(self):\n",
    "        self.int_loga = self.initialize_parameters(self.encoder_ffn_dim, self.num_hidden_layers)\n",
    "\n",
    "        self.add_one_module(self.int_loga, type=\"intermediate\", \n",
    "                            parameter_per_dim=self.params_per_encoder_ffn_dim, size=self.encoder_ffn_dim,\n",
    "                            shape=[self.num_hidden_layers, 1, 1, self.encoder_ffn_dim])\n",
    "        self.prunable_model_size += self.params_per_mlp_layer * self.num_hidden_layers\n",
    "        self.reset_loga(self.int_loga)\n",
    "        logger.info(f\"Initialized structured mlp! Prunable_model_size = {self.prunable_model_size}\")\n",
    "\n",
    "\n",
    "    def initialize_whole_mlp(self):\n",
    "        n_layer = self.num_hidden_layers\n",
    "        self.intlayer_loga = self.initialize_parameters(n_layer)\n",
    "        self.add_one_module(self.intlayer_loga, type=\"mlp\", \n",
    "                            parameter_per_dim=self.params_per_mlp_layer, size=self.mlp_num_per_layer,\n",
    "                            shape=[n_layer])\n",
    "        self.reset_loga(self.intlayer_loga, mean=10)\n",
    "        logger.info(f\"Initialized whole mlps! Prunable_model_size = {self.prunable_model_size}\")\n",
    "\n",
    "\n",
    "    def reset_loga(self, tensor, mean=None):\n",
    "        if mean is None:\n",
    "            mean = math.log(1 - self.droprate_init) - math.log(self.droprate_init)\n",
    "        tensor.data.normal_(mean, 1e-2)\n",
    "\n",
    "    def reset_qz_logas(self):\n",
    "        for key in self.z_logas:\n",
    "            if key in [\"head_layer\", \"mlp\", \"head\"]:\n",
    "                self.reset_loga(self.z_logas[key], 10)\n",
    "            else:\n",
    "                self.reset_loga(self.z_logas[key])\n",
    "\n",
    "    def constrain_parameters(self):\n",
    "        def _constrain(tensor):\n",
    "            tensor.data.clamp_(min=math.log(1e-2), max=math.log(1e2))\n",
    "        for key in self.z_logas:\n",
    "            _constrain(self.z_logas[key])\n",
    "\n",
    "    def cdf_qz(self, x, loga):\n",
    "        \"\"\"Implements the CDF of the 'stretched' concrete distribution\"\"\"\n",
    "        xn = (x - limit_a) / (limit_b - limit_a)\n",
    "        logits = math.log(xn) - math.log(1 - xn)\n",
    "        return torch.sigmoid(logits * self.temperature - loga).clamp(min=epsilon, max=1 - epsilon)\n",
    "\n",
    "    def quantile_concrete(self, x, loga):\n",
    "        y = torch.sigmoid((torch.log(x) - torch.log(1 - x) + loga) / self.temperature)\n",
    "        return y * (limit_b - limit_a) + limit_a\n",
    "\n",
    "    def get_num_parameters_for_one(self, loga, parameter_size):\n",
    "        return torch.sum(1 - self.cdf_qz(0, loga)) * parameter_size\n",
    "\n",
    "    def transform_scores_for_head(self):\n",
    "        assert \"head\" in self.types\n",
    "\n",
    "        if \"head_layer\" in self.types:\n",
    "            all_head_score = 1 - self.cdf_qz(0, self.headlayer_loga)\n",
    "        else:\n",
    "            all_head_score = None\n",
    "        head_score = 1 - self.cdf_qz(0, self.head_loga) # 12 * 12\n",
    "       \n",
    "        if all_head_score is not None:\n",
    "            all_head_score = all_head_score.view(-1, 1, 1) # 12 * 1 * 1\n",
    "        head_score = head_score.unsqueeze(-1)   # 12 * 12 * 1\n",
    "       \n",
    "        return all_head_score, head_score\n",
    "\n",
    "    def get_num_parameters_for_mlp(self):\n",
    "        intlayer_score = 1 - self.cdf_qz(0, self.intlayer_loga) # 12\n",
    "        int_score = 1 - self.cdf_qz(0, self.int_loga) # 12 * 3072\n",
    "        intlayer_score = intlayer_score.unsqueeze(-1)\n",
    "\n",
    "        num_parameters = torch.sum(intlayer_score * int_score) * self.parameters_per_dim[\"intermediate\"]\n",
    "        return num_parameters\n",
    "\n",
    "    def get_num_parameters_and_constraint_for_hidden(self): #! calculate the current parsity\n",
    "        num_parameters = 0\n",
    "       \n",
    "        # 12 * 1 * 1\n",
    "        # 12 * 12 * 1\n",
    "        all_head_score, head_score = self.transform_scores_for_head()\n",
    "        hidden_score = 1 - self.cdf_qz(0, self.hidden_loga) # 768\n",
    "\n",
    "        if all_head_score is not None:\n",
    "            head_score = (all_head_score * head_score).reshape(-1)\n",
    "        else:\n",
    "            head_score = head_score.reshape(-1)\n",
    "        num_parameters += \\\n",
    "            torch.sum(torch.outer(hidden_score, head_score)) * self.parameters_per_dim[\"head\"] / self.d_model\n",
    "\n",
    "        intlayer_score = 1 - self.cdf_qz(0, self.intlayer_loga)  # 12\n",
    "        int_score = 1 - self.cdf_qz(0, self.int_loga)  # 12 * 3072\n",
    "        intlayer_score = intlayer_score.unsqueeze(-1)\n",
    "\n",
    "        int_score = (intlayer_score * int_score).reshape(-1)\n",
    "        num_parameters += torch.sum(torch.outer(hidden_score, int_score)) * 2\n",
    "        return num_parameters\n",
    "\n",
    "\n",
    "    def get_num_parameters_and_constraint(self):\n",
    "        num_parameters = 0\n",
    "\n",
    "        all_head_score, head_score = self.transform_scores_for_head()\n",
    "        \n",
    "        head_score = head_score * all_head_score\n",
    "        num_parameters += torch.sum(head_score) * self.parameters_per_dim[\"head\"]\n",
    "\n",
    "        intlayer_score = 1 - self.cdf_qz(0, self.intlayer_loga)  # 12\n",
    "        int_score = 1 - self.cdf_qz(0, self.int_loga)  # 12 * 3072\n",
    "        intlayer_score = intlayer_score.unsqueeze(-1)\n",
    "\n",
    "        int_score = int_score * intlayer_score\n",
    "        num_parameters += torch.sum(int_score) * self.parameters_per_dim[\"intermediate\"]\n",
    "        return num_parameters\n",
    "\n",
    "\n",
    "    def get_target_sparsity(self, pruned_steps):\n",
    "        target_sparsity = (self.target_sparsity - self.start_sparsity) * min(1, pruned_steps / self.lagrangian_warmup) + self.start_sparsity\n",
    "        return target_sparsity\n",
    "\n",
    "\n",
    "    def lagrangian_regularization(self, pruned_steps):\n",
    "        target_sparsity = self.target_sparsity\n",
    "        if \"hidden\" in self.types:\n",
    "            expected_size = self.get_num_parameters_and_constraint_for_hidden() #! calculate \\bar s\n",
    "        else:\n",
    "            expected_size = self.get_num_parameters_and_constraint() #! calculate \\bar s\n",
    "        expected_sparsity = 1 - expected_size / self.prunable_model_size\n",
    "        if self.lagrangian_warmup > 0:\n",
    "            target_sparsity = self.get_target_sparsity(pruned_steps)\n",
    "        lagrangian_loss = ( #! see appendix\n",
    "                self.lambda_1 * (expected_sparsity - target_sparsity)\n",
    "                + self.lambda_2 * (expected_sparsity - target_sparsity) ** 2 #! where is the lambda 1 and lambda 2 from\n",
    "        )\n",
    "        return lagrangian_loss, expected_sparsity, target_sparsity\n",
    "\n",
    "    def get_eps(self, size):\n",
    "        \"\"\"Uniform random numbers for the concrete distribution\"\"\"\n",
    "        eps = torch.FloatTensor(size).uniform_(epsilon, 1-epsilon)\n",
    "        eps = Variable(eps)\n",
    "        return eps\n",
    "\n",
    "    # during training\n",
    "    def _sample_z(self, loga):\n",
    "        eps = self.get_eps(torch.FloatTensor(*loga.shape)).to(loga.device)\n",
    "        z = self.quantile_concrete(eps, loga)\n",
    "        z = F.hardtanh(z, min_val=0, max_val=1)\n",
    "        return z\n",
    "\n",
    "    # during inference\n",
    "    def _deterministic_z(self, size, loga):\n",
    "        # Following https://github.com/asappresearch/flop/blob/e80e47155de83abbe7d90190e00d30bfb85c18d5/flop/hardconcrete.py#L8 line 103\n",
    "        expected_num_nonzeros = torch.sum(1 - self.cdf_qz(0, loga))\n",
    "        expected_num_zeros = size - expected_num_nonzeros.item()\n",
    "        try:\n",
    "            num_zeros = round(expected_num_zeros)\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "        soft_mask = torch.sigmoid(loga / self.temperature * self.magical_number)\n",
    "        if num_zeros > 0:\n",
    "            if soft_mask.ndim == 0:\n",
    "                soft_mask = torch.tensor(0).to(loga.device)\n",
    "            else:\n",
    "                _, indices = torch.topk(soft_mask, k=num_zeros, largest=False)\n",
    "                soft_mask[indices] = 0.\n",
    "        return soft_mask\n",
    "\n",
    "    def get_z_from_zs(self, zs):\n",
    "        numpified_zs = {} \n",
    "        for type in self.all_types:\n",
    "            name = type[:-2]\n",
    "            z = zs.get(type, np.ones(self.shapes[name]))\n",
    "            if torch.is_tensor(z): \n",
    "                new_z = z.squeeze().detach().cpu().numpy() > 0\n",
    "            numpified_zs[name] = new_z\n",
    "        return numpified_zs\n",
    "\n",
    "    def calculate_model_size(self, zs):\n",
    "        numpified_zs = self.get_z_from_zs(zs)\n",
    "        hidden_z = numpified_zs[\"hidden\"]\n",
    "        intermediate_z = numpified_zs[\"intermediate\"]\n",
    "        mlp_z = numpified_zs[\"mlp\"].reshape(-1, 1)\n",
    "        head_z = numpified_zs[\"head\"]\n",
    "        head_layer_z = numpified_zs[\"head_layer\"].reshape(-1, 1)\n",
    "\n",
    "        remaining_hidden_dims = hidden_z.sum().item()\n",
    "        remaining_intermediate_nums = intermediate_z.reshape(self.num_hidden_layers, self.encoder_ffn_dim).sum(-1).tolist()\n",
    "        remaining_head_nums = head_z.reshape(self.num_hidden_layers, self.encoder_attention_heads).sum(-1).tolist()\n",
    "\n",
    "        head_nums = np.outer((head_z * head_layer_z).reshape(-1), hidden_z).sum().item()\n",
    "        intermediate_nums = np.outer((intermediate_z * mlp_z).reshape(-1), hidden_z).sum().item()\n",
    "\n",
    "        remaining_model_size = head_nums * self.dim_per_encoder_head * 4 + intermediate_nums * 2\n",
    "        pruned_model_size = self.prunable_model_size - remaining_model_size\n",
    "\n",
    "        results = {}\n",
    "        # Not multiplied with each other\n",
    "        results[\"head_layers\"] = head_layer_z.reshape(-1).astype(int).tolist()\n",
    "        results[\"mlp_layers\"] = mlp_z.reshape(-1).astype(int).tolist()\n",
    "        results[\"hidden_dims\"] = remaining_hidden_dims\n",
    "        results[\"intermediate_dims\"] = remaining_intermediate_nums\n",
    "        results[\"head_nums\"] = remaining_head_nums\n",
    "        results[\"pruned_params\"] = pruned_model_size\n",
    "        results[\"remaining_params\"] = remaining_model_size\n",
    "        results[\"pruned_model_sparsity\"] = pruned_model_size / self.prunable_model_size\n",
    "        \n",
    "        logger.info(f\"remaining_head_layers: {head_layer_z}\")\n",
    "        logger.info(f\"remaining_mlp_layers: {mlp_z}\")\n",
    "        logger.info(f\"remaining_hidden_dims: {remaining_hidden_dims}\")\n",
    "        logger.info(f\"remaining_intermediate_nums: {remaining_intermediate_nums}\")\n",
    "        logger.info(f\"remaining_head_nums: {remaining_head_nums}\")\n",
    "        logger.info(f\"pruned_model_size: {pruned_model_size}\")\n",
    "        logger.info(f\"remaining_model_size: {remaining_model_size}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, training=True,):\n",
    "        zs = {f\"{type}_z\": [] for type in self.types}\n",
    "\n",
    "        if training:\n",
    "            for i, type in enumerate(self.types):\n",
    "                loga = self.z_logas[type]\n",
    "                z = self._sample_z(loga)\n",
    "                zs[f\"{type}_z\"] = z.reshape(self.shapes[type])\n",
    "        else:\n",
    "            for i, type in enumerate(self.types):\n",
    "                if type != \"hidden\": # hidden is not a per layer sample\n",
    "                    loga_all_layers = self.z_logas[type]\n",
    "                    for layer in range(len(loga_all_layers)):\n",
    "                        loga = loga_all_layers[layer]\n",
    "                        size = self.sizes[type]\n",
    "                        z = self._deterministic_z(size, loga)\n",
    "                        zs[f\"{type}_z\"].append(z.reshape(self.shapes[type][1:]))\n",
    "                else:\n",
    "                    z = self._deterministic_z(self.sizes[type], self.hidden_loga)\n",
    "                    zs[f\"{type}_z\"] = z\n",
    "            for type in zs:\n",
    "                if type != \"hidden_z\":\n",
    "                    zs[type] = torch.stack(zs[type])\n",
    "        return zs \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76b29972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, WhisperForConditionalGeneration, BertModel\n",
    "    \n",
    "config = AutoConfig.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "l0_module = L0Module(config, lagrangian_warmup=200, target_sparsity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cfa50e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head', 'intermediate', 'hidden', 'mlp', 'head_layer']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a6ec928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['head', 'intermediate', 'hidden', 'mlp', 'head_layer'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "172941e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas['head'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61dab359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 3072])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas['intermediate'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ab7a742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas['hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f09e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas['mlp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "981efbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_module.z_logas['head_layer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ffbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24770788",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.types = []\n",
    "        self.z_logas = {}\n",
    "        self.parameters_per_dim = {}\n",
    "        self.sizes = {}\n",
    "        self.shapes = {}\n",
    "\n",
    "        self.hidden_loga = None\n",
    "        self.hidden_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d48dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 768])\n",
      "torch.Size([768, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(model.model.encoder.layers[3].fc1.weight.shape)\n",
    "print(model.model.encoder.layers[3].fc2.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "388ad2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.decoder_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2b78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params_per_head_layer\n",
    "config.d_model * config.d_model * 4 + config.d_model * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60fafa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperEncoderLayer(\n",
       "  (self_attn): WhisperAttention(\n",
       "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (activation_fn): GELUActivation()\n",
       "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76ef9281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "print(model.model.encoder.layers[3].self_attn.k_proj.weight.shape)\n",
    "print(model.model.encoder.layers[3].self_attn.v_proj.weight.shape)\n",
    "print(model.model.encoder.layers[3].self_attn.q_proj.weight.shape)\n",
    "print(model.model.encoder.layers[3].self_attn.out_proj.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45d4be04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperAttention(\n",
       "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[3].self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc3a5124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d1e635bb8343ce984952b0256e41ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3567c42a3e4f6ca7ed729d10dbd4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2714e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7102b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[2].intermediate.dense.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7d7f338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3072])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[2].output.dense.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c5c4154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.encoder_ffn_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8f59143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4722432"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self.params_per_mlp_layer\n",
    "config.d_model * config.encoder_ffn_dim * 2 + config.d_model + config.d_model * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95875f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperEncoderLayer(\n",
       "  (self_attn): WhisperAttention(\n",
       "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (activation_fn): GELUActivation()\n",
       "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "846daa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[3].fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746b18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c480b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e2803edf3a49269fcbd55918cc8e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8581711ef081454d888f2847c8ad7948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33f7ad5d3b24887a2f0f3a062f85116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "74410496"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MarianMTModel\n",
    "model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2c646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperConfig\n",
    "\n",
    "config = WhisperConfig.from_pretrained('openai/whisper-small')\n",
    "model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14557249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241734912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992afed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241734912"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7292332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperEncoder(\n",
       "  (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (embed_positions): Embedding(1500, 768)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x WhisperEncoderLayer(\n",
       "      (self_attn): WhisperAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): GELUActivation()\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "445518ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "\n",
    "num_params += model.model.encoder.conv1.weight.numel()\n",
    "num_params += model.model.encoder.conv1.bias.numel()\n",
    "num_params += model.model.encoder.conv2.weight.numel()\n",
    "num_params += model.model.encoder.conv2.bias.numel()\n",
    "\n",
    "num_params += model.model.encoder.embed_positions.weight.numel()\n",
    "\n",
    "attn = 0\n",
    "attn += model.model.encoder.layers[0].self_attn.k_proj.weight.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.v_proj.weight.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.v_proj.bias.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.q_proj.weight.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.q_proj.bias.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.out_proj.weight.numel()\n",
    "attn += model.model.encoder.layers[0].self_attn.out_proj.bias.numel()\n",
    "attn = attn*12\n",
    "\n",
    "layer_norm = 0\n",
    "layer_norm += model.model.encoder.layers[0].self_attn_layer_norm.weight.numel()\n",
    "layer_norm += model.model.encoder.layers[0].self_attn_layer_norm.bias.numel()\n",
    "layer_norm = layer_norm*12\n",
    "\n",
    "ffn = 0\n",
    "ffn += model.model.encoder.layers[0].fc1.weight.numel()\n",
    "ffn += model.model.encoder.layers[0].fc1.bias.numel()\n",
    "ffn += model.model.encoder.layers[0].fc2.weight.numel()\n",
    "ffn += model.model.encoder.layers[0].fc2.bias.numel()\n",
    "ffn = ffn*12\n",
    "\n",
    "final_layer_norm = 0\n",
    "final_layer_norm += model.model.encoder.layers[i].final_layer_norm.weight.numel()\n",
    "final_layer_norm += model.model.encoder.layers[i].final_layer_norm.bias.numel()\n",
    "final_layer_norm = final_layer_norm*12\n",
    "\n",
    "num_params += (attn + layer_norm + ffn + final_layer_norm)\n",
    "\n",
    "num_params += model.model.encoder.layer_norm.weight.numel()\n",
    "num_params += model.model.encoder.layer_norm.bias.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e07cec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88154112"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8002c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88154112"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0864eabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].self_attn.v_proj.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c970517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "698031b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 768])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93b087da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].fc1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f606568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3072])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bb1e3a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.layers[0].fc2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f76712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "70ee1ab45e8b937f09fa6841b13701829ac76ec7fe39d355982d785d83845075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
