{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfe8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.fx as fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a192d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.param = torch.nn.Parameter(torch.rand(3, 4))\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x + self.param).clamp(min=0.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2865f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33331d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_traced : torch.fx.GraphModule = symbolic_trace(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34be375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=1] = placeholder[target=x]\n",
      "    %param : [#users=1] = get_attr[target=param]\n",
      "    %add : [#users=1] = call_function[target=operator.add](args = (%x, %param), kwargs = {})\n",
      "    %linear : [#users=1] = call_module[target=linear](args = (%add,), kwargs = {})\n",
      "    %clamp : [#users=1] = call_method[target=clamp](args = (%linear,), kwargs = {min: 0.0, max: 1.0})\n",
      "    return clamp\n"
     ]
    }
   ],
   "source": [
    "print(symbolic_traced.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde07baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    param = self.param\n",
      "    add = x + param;  x = param = None\n",
      "    linear = self.linear(add);  add = None\n",
      "    clamp = linear.clamp(min = 0.0, max = 1.0);  linear = None\n",
      "    return clamp\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(symbolic_traced.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105435a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7e28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(m: nn.Module,\n",
    "              tracer_class : type = torch.fx.Tracer) -> torch.nn.Module:\n",
    "    # Step 1: Acquire a Graph representing the code in `m`\n",
    "\n",
    "    # NOTE: torch.fx.symbolic_trace is a wrapper around a call to\n",
    "    # fx.Tracer.trace and constructing a GraphModule. We'll\n",
    "    # split that out in our transform to allow the caller to\n",
    "    # customize tracing behavior.\n",
    "    graph : torch.fx.Graph = tracer_class().trace(m)\n",
    "\n",
    "    # Step 2: Modify this Graph or create a new one\n",
    "    graph = ...\n",
    "\n",
    "    # Step 3: Construct a Module to return\n",
    "    return torch.fx.GraphModule(m, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(m : nn.Module) -> nn.Module:\n",
    "    gm : torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n",
    "\n",
    "    # Modify gm.graph\n",
    "    # <...>\n",
    "\n",
    "    # Recompile the forward() method of `gm` from its Graph\n",
    "    gm.recompile()\n",
    "\n",
    "    return gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3a3aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name           target                                                   args                kwargs\n",
      "-------------  -------------  -------------------------------------------------------  ------------------  -----------\n",
      "placeholder    x              x                                                        ()                  {}\n",
      "get_attr       linear_weight  linear.weight                                            ()                  {}\n",
      "call_function  add            <built-in function add>                                  (x, linear_weight)  {}\n",
      "call_module    linear         linear                                                   (add,)              {}\n",
      "call_method    relu           relu                                                     (linear,)           {}\n",
      "call_function  sum_1          <built-in method sum of type object at 0x7f55f11bd540>   (relu,)             {'dim': -1}\n",
      "call_function  topk           <built-in method topk of type object at 0x7f55f11bd540>  (sum_1, 3)          {}\n",
      "output         output         output                                                   (topk,)             {}\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.param = torch.nn.Parameter(torch.rand(3, 4))\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.topk(torch.sum(\n",
    "            self.linear(x + self.linear.weight).relu(), dim=-1), 3)\n",
    "\n",
    "m = MyModule()\n",
    "gm = torch.fx.symbolic_trace(m)\n",
    "\n",
    "gm.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58937d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample module\n",
    "class M(torch.nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return torch.add(x, y)\n",
    "\n",
    "def transform(m: torch.nn.Module,\n",
    "              tracer_class : type = fx.Tracer) -> torch.nn.Module:\n",
    "    graph : fx.Graph = tracer_class().trace(m)\n",
    "    # FX represents its Graph as an ordered list of\n",
    "    # nodes, so we can iterate through them.\n",
    "    for node in graph.nodes:\n",
    "        # Checks if we're calling a function (i.e:\n",
    "        # torch.add)\n",
    "        if node.op == 'call_function':\n",
    "            # The target attribute is the function\n",
    "            # that call_function calls.\n",
    "            if node.target == torch.add:\n",
    "                node.target = torch.mul\n",
    "\n",
    "    graph.lint() # Does some checks to make sure the\n",
    "                 # Graph is well-formed.\n",
    "\n",
    "    return fx.GraphModule(m, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34395112",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e97340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "619f953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = transform(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6ac4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c5483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a5636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_traced : torch.fx.GraphModule = symbolic_trace(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba676c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88397f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32365b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f80688be110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  # This is all you need to use both PyTorch and TorchScript!\n",
    "print(torch.__version__)\n",
    "torch.manual_seed(191009)  # set the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881a14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523a1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.2155, -0.0853,  0.3186,  0.6389],\n",
      "        [ 0.5300,  0.5265,  0.6738,  0.5114],\n",
      "        [ 0.3993,  0.5134, -0.2223,  0.4750]], grad_fn=<TanhBackward0>), tensor([[ 0.2155, -0.0853,  0.3186,  0.6389],\n",
      "        [ 0.5300,  0.5265,  0.6738,  0.5114],\n",
      "        [ 0.3993,  0.5134, -0.2223,  0.4750]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fcc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
       "         [-0.2156,  0.7301,  0.3347,  0.3326],\n",
       "         [-0.2860, -0.1094,  0.4924,  0.5432]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
       "         [-0.2156,  0.7301,  0.3347,  0.3326],\n",
       "         [-0.2860, -0.1094,  0.4924,  0.5432]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc912fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /var/folders/by/rktr_w596p97pmt8_cbknvs80000gn/T/ipykernel_4017/260609686.py:7:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /var/folders/by/rktr_w596p97pmt8_cbknvs80000gn/T/ipykernel_4017/260609686.py:7:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /var/folders/by/rktr_w596p97pmt8_cbknvs80000gn/T/ipykernel_4017/260609686.py:7:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04c6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307edded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
      "        [-0.2156,  0.7301,  0.3347,  0.3326],\n",
      "        [-0.2860, -0.1094,  0.4924,  0.5432]], grad_fn=<TanhBackward0>), tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
      "        [-0.2156,  0.7301,  0.3347,  0.3326],\n",
      "        [-0.2860, -0.1094,  0.4924,  0.5432]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
      "        [-0.2156,  0.7301,  0.3347,  0.3326],\n",
      "        [-0.2860, -0.1094,  0.4924,  0.5432]],\n",
      "       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.0123,  0.0657,  0.7297,  0.6066],\n",
      "        [-0.2156,  0.7301,  0.3347,  0.3326],\n",
      "        [-0.2860, -0.1094,  0.4924,  0.5432]],\n",
      "       grad_fn=<DifferentiableGraphBackward>))\n"
     ]
    }
   ],
   "source": [
    "print(my_cell(x, h))\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1e6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  return torch.neg(argument_1)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/rktr_w596p97pmt8_cbknvs80000gn/T/ipykernel_4017/4234398751.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))  # control flow erased\n",
    "\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074587b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "print(scripted_gate.code)\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "413c482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.1185, 0.8707, 0.5898, 0.7261],\n",
      "        [0.4802, 0.2835, 0.4302, 0.9021],\n",
      "        [0.4490, 0.9199, 0.6838, 0.6419]], grad_fn=<TanhBackward0>), tensor([[0.1185, 0.8707, 0.5898, 0.7261],\n",
      "        [0.4802, 0.2835, 0.4302, 0.9021],\n",
      "        [0.4490, 0.9199, 0.6838, 0.6419]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# New inputs\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "print(scripted_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa02cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1377a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c669c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
