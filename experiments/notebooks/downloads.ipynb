{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f387fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, load_dataset\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"hi\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"hi\", split=\"test\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78160dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '0f018a99663f33afbb7d38aee281fb1afcfd07f9e7acd00383f604e1e17c38d6ed8adf1bd2ccbf927a52c5adefb8ac4b158ce27a7c2ed9581e71202eb302dfb3',\n",
       " 'path': '/users/ujan/.cache/huggingface/datasets/downloads/extracted/c97e32e2de32510be7c273dbcdc82db93cb021f851ff1f0751145082d83effd9/common_voice_hi_26010471.mp3',\n",
       " 'audio': {'path': '/users/ujan/.cache/huggingface/datasets/downloads/extracted/c97e32e2de32510be7c273dbcdc82db93cb021f851ff1f0751145082d83effd9/common_voice_hi_26010471.mp3',\n",
       "  'array': array([-2.13162821e-14,  1.40332190e-13,  2.23820962e-13, ...,\n",
       "          1.03580276e-03,  6.28637266e-04,  3.20890395e-04]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': 'तुम ने टॉम को कहाँ भेज दिया?',\n",
       " 'up_votes': 2,\n",
       " 'down_votes': 1,\n",
       " 'age': '',\n",
       " 'gender': '',\n",
       " 'accent': '',\n",
       " 'locale': 'hi',\n",
       " 'segment': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7de6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import FlaxWhisperForConditionalGeneration\n",
    "from transformers import WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55062a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.94k/1.94k [00:00<00:00, 2.14MB/s]\n",
      "Downloading flax_model.msgpack: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 151M/151M [02:18<00:00, 1.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "#feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "#tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"hindi\", task=\"transcribe\")\n",
    "# We only need to set the task id when the language is specified (i.e. in a multilingual setting)\n",
    "#tokenizer.set_prefix_tokens(language=\"hindi\", task=\"transcribe\")\n",
    "#processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"hindi\", task=\"transcribe\")\n",
    "\n",
    "# model\n",
    "model = FlaxWhisperForConditionalGeneration.from_pretrained(\n",
    "    \"openai/whisper-tiny\", # small\n",
    "    seed=42,\n",
    "    dtype=getattr(jnp, 'float16')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9944d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "#tokenizer.save_pretrained(\"/users/ujan/Downloads/whisper_en_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0a21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperConfig\n",
    "config = WhisperConfig.from_pretrained('openai/whisper-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06220909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-tiny\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 384,\n",
      "  \"decoder_attention_heads\": 6,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 6,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [\n",
      "    1,\n",
      "    2,\n",
      "    7,\n",
      "    8,\n",
      "    9,\n",
      "    10,\n",
      "    14,\n",
      "    25,\n",
      "    26,\n",
      "    27,\n",
      "    28,\n",
      "    29,\n",
      "    31,\n",
      "    58,\n",
      "    59,\n",
      "    60,\n",
      "    61,\n",
      "    62,\n",
      "    63,\n",
      "    90,\n",
      "    91,\n",
      "    92,\n",
      "    93,\n",
      "    359,\n",
      "    503,\n",
      "    522,\n",
      "    542,\n",
      "    873,\n",
      "    893,\n",
      "    902,\n",
      "    918,\n",
      "    922,\n",
      "    931,\n",
      "    1350,\n",
      "    1853,\n",
      "    1982,\n",
      "    2460,\n",
      "    2627,\n",
      "    3246,\n",
      "    3253,\n",
      "    3268,\n",
      "    3536,\n",
      "    3846,\n",
      "    3961,\n",
      "    4183,\n",
      "    4667,\n",
      "    6585,\n",
      "    6647,\n",
      "    7273,\n",
      "    9061,\n",
      "    9383,\n",
      "    10428,\n",
      "    10929,\n",
      "    11938,\n",
      "    12033,\n",
      "    12331,\n",
      "    12562,\n",
      "    13793,\n",
      "    14157,\n",
      "    14635,\n",
      "    15265,\n",
      "    15618,\n",
      "    16553,\n",
      "    16604,\n",
      "    18362,\n",
      "    18956,\n",
      "    20075,\n",
      "    21675,\n",
      "    22520,\n",
      "    26130,\n",
      "    26161,\n",
      "    26435,\n",
      "    28279,\n",
      "    29464,\n",
      "    31650,\n",
      "    32302,\n",
      "    32470,\n",
      "    36865,\n",
      "    42863,\n",
      "    47425,\n",
      "    49870,\n",
      "    50254,\n",
      "    50258,\n",
      "    50358,\n",
      "    50359,\n",
      "    50360,\n",
      "    50361,\n",
      "    50362\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n",
      "WhisperConfig {\n",
      "  \"_name_or_path\": \"openai/whisper-tiny\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"apply_spec_augment\": false,\n",
      "  \"architectures\": [\n",
      "    \"WhisperForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50257\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"d_model\": 384,\n",
      "  \"decoder_attention_heads\": 6,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 50258,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 6,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 4,\n",
      "  \"eos_token_id\": 50257,\n",
      "  \"forced_decoder_ids\": [\n",
      "    [\n",
      "      1,\n",
      "      50259\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      50359\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      50363\n",
      "    ]\n",
      "  ],\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"max_length\": 448,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50257,\n",
      "  \"scale_embedding\": false,\n",
      "  \"suppress_tokens\": [],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.29.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FlaxWhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n",
    "print(model.config)\n",
    "model.config.update({\"suppress_tokens\": []})\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4587f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')\n",
    "model.save_pretrained('/home/ujan/speech-processing/models/pretrained_models/whisper-large-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.encoder.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8851c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c2172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dba24d60b6106a525e22e48a87e1b86de85e85410d41403c99e9fde77685272c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
