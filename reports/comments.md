##### MOE

- neuron activations become less sparse with fine tuning
- ft with relu instead of relu first and then ft


##### CoFI

- dims and heads zeroing but not mha, ffns
	- check mha, ffn masks
	- check sparsity calculation
	- more expts with different settings
